[{"text": "All right. Hey, everyone. Welcome back.", "start": 3.53, "duration": 4.96}, {"text": "Um, so let's continue our discussion today of reinforcement learning and MDPs.", "start": 8.49, "duration": 7.515}, {"text": "And specifically, what I hope you learned from", "start": 16.005, "duration": 2.835}, {"text": "today is how to apply reinforcement learning,", "start": 18.84, "duration": 2.88}, {"text": "um, even to continuous state or infinite state MDPs.", "start": 21.72, "duration": 4.23}, {"text": "Um, so we'll talk about discretization, model-based RL,", "start": 25.95, "duration": 3.93}, {"text": "we'll talk about models/simulation and fitted value iteration is the main algorithm,", "start": 29.88, "duration": 4.65}, {"text": "um, I want to lead up to for today.", "start": 34.53, "duration": 3.09}, {"text": "Um, just to recap.", "start": 37.62, "duration": 1.47}, {"text": "Because we're gonna build on what we had learned, uh,", "start": 39.09, "duration": 2.61}, {"text": "in the last two lectures,", "start": 41.7, "duration": 1.41}, {"text": "I wanna make sure that you have the notation fresh in your mind.", "start": 43.11, "duration": 3.53}, {"text": "Um, MDP was states,", "start": 46.64, "duration": 2.61}, {"text": "actions, transition probabilities, discount factor reward. That was an example.", "start": 49.25, "duration": 4.155}, {"text": "Um, V Pi was the value function for a policy Pi which is the expected payoff.", "start": 53.405, "duration": 5.79}, {"text": "If you execute that policy starting from", "start": 59.195, "duration": 2.475}, {"text": "a state S and V star was the optimal value function.", "start": 61.67, "duration": 3.57}, {"text": "And last time, we figured out that if you know what is V star,", "start": 65.24, "duration": 3.915}, {"text": "then uh, Pi star,", "start": 69.155, "duration": 1.975}, {"text": "the optimal policy or the optimal action for a given state,", "start": 71.13, "duration": 3.68}, {"text": "can be computed as the argmax of that, right?", "start": 74.81, "duration": 3.825}, {"text": "Um, and, uh, one, one,", "start": 78.635, "duration": 1.995}, {"text": "one thing though we'll come back to later is,", "start": 80.63, "duration": 2.81}, {"text": "uh, an equivalent way of writing that formula,", "start": 83.44, "duration": 3.535}, {"text": "is that this is the expectation with respect to S prime drawn from", "start": 86.975, "duration": 6.09}, {"text": "P_sa of V star of S prime, right?", "start": 93.065, "duration": 6.505}, {"text": "So when we go to, uh, er, er,", "start": 99.57, "duration": 2.565}, {"text": "we've been, we have been working with discrete state MDPs with an 11 state MDP.", "start": 102.135, "duration": 4.97}, {"text": "So this is the sum over all the states S prime.", "start": 107.105, "duration": 2.625}, {"text": "But when we have- when we go to continuous state MDPs,", "start": 109.73, "duration": 3.63}, {"text": "the generalization of this or what this becomes-", "start": 113.36, "duration": 2.19}, {"text": "this is the expected value with respect to", "start": 115.55, "duration": 2.34}, {"text": "S prime drawn from the state transition probabilities here with- of,", "start": 117.89, "duration": 4.89}, {"text": "uh, index Pi_sa, covers state, covers that action of the value that you attain in the future.", "start": 122.78, "duration": 7.09}, {"text": "So V star of S prime.", "start": 129.87, "duration": 1.395}, {"text": "Okay? Um, and then we saw the value iteration algorithm.", "start": 131.265, "duration": 5.375}, {"text": "We're also- so we talked about valuation policy iteration.", "start": 136.64, "duration": 2.775}, {"text": "But today, uh, we're built on value iteration,", "start": 139.415, "duration": 2.895}, {"text": "but the value iteration algorithm uses Bellman's equations, uh,", "start": 142.31, "duration": 3.985}, {"text": "which says, take the left-hand side,", "start": 146.295, "duration": 3.045}, {"text": "set it to the right-hand side, right?", "start": 149.34, "duration": 1.56}, {"text": "And, uh, for, for V star,", "start": 150.9, "duration": 1.74}, {"text": "if V was equal to V star of the left-hand side is equal to the right-hand side,", "start": 152.64, "duration": 3.465}, {"text": "that was, um, oh, I'm sorry.", "start": 156.105, "duration": 2.325}, {"text": "It's missing a max there.", "start": 158.43, "duration": 2.235}, {"text": "Right? Um, for- if V was equal to V star,", "start": 160.665, "duration": 4.62}, {"text": "then the left-hand side and the right-hand side will be equal to each other.", "start": 165.285, "duration": 3.515}, {"text": "But, uh, what value iteration does is an algorithm that initializes V of S as", "start": 168.8, "duration": 4.56}, {"text": "0 and repeatedly carries its update until V converges to V star.", "start": 173.36, "duration": 5.01}, {"text": "And after that, you can then, um,", "start": 178.37, "duration": 2.55}, {"text": "compute Pi star or find for every state find,", "start": 180.92, "duration": 3.21}, {"text": "the optimal action A.", "start": 184.13, "duration": 2.29}, {"text": "Okay? So um, because we're gonna build on this notation and this set of ideas today,", "start": 186.42, "duration": 6.05}, {"text": "I just want to make sure all this makes sense, right?", "start": 192.47, "duration": 2.13}, {"text": "Any questions about that before we move on?", "start": 194.6, "duration": 6.39}, {"text": "No? Okay. Cool. All right.", "start": 200.99, "duration": 2.35}, {"text": "So, um, no?", "start": 203.34, "duration": 2.61}, {"text": "No. Okay. So everything we've done so far was built", "start": 205.95, "duration": 3.36}, {"text": "on the MDP having a finite set of states.", "start": 209.31, "duration": 3.93}, {"text": "Right? So with the 11 state MDP,", "start": 213.24, "duration": 1.46}, {"text": "S was a discrete set of states.", "start": 214.7, "duration": 1.935}, {"text": "Um, last time on Monday,", "start": 216.635, "duration": 2.315}, {"text": "I think somebody asked, \"Well,", "start": 218.95, "duration": 1.205}, {"text": "how do you deal with continuous states?\"", "start": 220.155, "duration": 1.695}, {"text": "So we'll, we'll, we'll work on that today.", "start": 221.85, "duration": 1.86}, {"text": "But, uh, let's say you want to build a, um,", "start": 223.71, "duration": 2.46}, {"text": "[NOISE] uh, let me draw a car.", "start": 226.17, "duration": 3.32}, {"text": "Right? Let's say you want to build a  ar,", "start": 229.49, "duration": 2.315}, {"text": "you know, maybe a self-driving car.", "start": 231.805, "duration": 1.655}, {"text": "Right? Um, ah, the state space of a car is, um, let's see.", "start": 233.46, "duration": 6.465}, {"text": "I'm gonna- well, instead of taking the- my artistic side view of the car,", "start": 239.925, "duration": 5.705}, {"text": "if you take a top-down view of a car.", "start": 245.63, "duration": 3.045}, {"text": "Right? So this is from the satellite imagery, you know,", "start": 248.675, "duration": 2.995}, {"text": "top-down view of a car where we have two views of the car heading this way.", "start": 251.67, "duration": 2.765}, {"text": "Um, how do you model the state of a car, right?", "start": 254.435, "duration": 3.265}, {"text": "Well, a common way to model the state of a car that's driving around on planet Earth,", "start": 257.7, "duration": 4.295}, {"text": "is that you need to know the position.", "start": 261.995, "duration": 3.03}, {"text": "Right? Um, and so that can be represented as x,", "start": 265.025, "duration": 4.02}, {"text": "y, uh, two numbers represent,", "start": 269.045, "duration": 2.155}, {"text": "you know, longitude or latitude or or something.", "start": 271.2, "duration": 2.61}, {"text": "Right? Um, you probably want to know the, uh,", "start": 273.81, "duration": 3.6}, {"text": "orientation of a car by maybe measured relative to North,", "start": 277.41, "duration": 5.76}, {"text": "you know, what's the orientation of [NOISE] the car?", "start": 283.17, "duration": 2.18}, {"text": "Um, and then it turns out if you're driving at very low speeds, this is fine.", "start": 285.35, "duration": 5.73}, {"text": "But if you're driving at anything other than very low speeds, then, um,", "start": 291.08, "duration": 4.05}, {"text": "[NOISE] we'll often include in the state-space,", "start": 295.13, "duration": 4.43}, {"text": "also the velocities and angular velocity.", "start": 299.56, "duration": 3.19}, {"text": "So x dot is the velocity in the x direction.", "start": 302.75, "duration": 2.925}, {"text": "So x dot is dx, dt.", "start": 305.675, "duration": 1.53}, {"text": "Right? Or it's the velocity and acceleration, y dot.", "start": 307.205, "duration": 2.7}, {"text": "So velocity in y direction and Theta dot is the angular velocity,", "start": 309.905, "duration": 3.045}, {"text": "the rate at which your car is turning.", "start": 312.95, "duration": 1.785}, {"text": "Okay? And it's sort of, um,", "start": 314.735, "duration": 1.83}, {"text": "up to you, how you want to model the car,", "start": 316.565, "duration": 3.06}, {"text": "is it important to model the current angle of the steering wheel,", "start": 319.625, "duration": 3.405}, {"text": "is it important to model how worn down is your front", "start": 323.03, "duration": 3.09}, {"text": "left tire as opposed to how worn down is your, your right tire.", "start": 326.12, "duration": 3.315}, {"text": "So depending on the application you are building,", "start": 329.435, "duration": 3.225}, {"text": "is up to you to decide what is the,", "start": 332.66, "duration": 2.555}, {"text": "um, state-based- state-space you want to use to model this car,", "start": 335.215, "duration": 3.97}, {"text": "um, and I guess- and, and if you are building a car to,", "start": 339.185, "duration": 2.67}, {"text": "to, to race in a racetrack,", "start": 341.855, "duration": 1.365}, {"text": "maybe it is important to model what is the temperature of the [NOISE] engine and how,", "start": 343.22, "duration": 4.005}, {"text": "you know, worn down is each of your four tires separately.", "start": 347.225, "duration": 2.625}, {"text": "But for a lot of normal driving, uh, this would be,", "start": 349.85, "duration": 3.015}, {"text": "uh, uh, you know, sufficient level of detail to model the state-space.", "start": 352.865, "duration": 3.745}, {"text": "Okay? Um, but so this is a, uh, six-dimensional,", "start": 356.61, "duration": 4.2}, {"text": "uh, um, so this is a,", "start": 360.81, "duration": 3.27}, {"text": "uh, six-dimensional state-space representation.", "start": 364.08, "duration": 3.435}, {"text": "Oh, and for those that work in robotics, uh,", "start": 367.515, "duration": 2.335}, {"text": "that would be called the kinematic model of the car,", "start": 369.85, "duration": 2.35}, {"text": "and that would be the dynamics model of the car.", "start": 372.2, "duration": 1.83}, {"text": "Right? If, if you want to model their velocities as well.", "start": 374.03, "duration": 2.99}, {"text": "Um, or let's see actually, all right.", "start": 377.02, "duration": 4.13}, {"text": "How about a helicopter?", "start": 381.15, "duration": 1.934}, {"text": "Right? I don't know.", "start": 383.084, "duration": 2.041}, {"text": "I hope this is a helicopter. All right.", "start": 385.125, "duration": 1.875}, {"text": "Ah, the states- how, how,", "start": 387.0, "duration": 1.515}, {"text": "how do you model a state-space of a helicopter?", "start": 388.515, "duration": 1.845}, {"text": "Helicopter flies around in 3D rather than drives around in 2D.", "start": 390.36, "duration": 3.225}, {"text": "And so common way to model the state-space helicopter would be to", "start": 393.585, "duration": 3.575}, {"text": "model it as-", "start": 397.16, "duration": 1.14}, {"text": "[NOISE]", "start": 398.3, "duration": 0.3}, {"text": "having a position x, y, z.", "start": 398.6, "duration": 1.83}, {"text": "Um, and then also, a 3D orientation of a helicopter is usually modeled with,", "start": 400.43, "duration": 8.25}, {"text": "uh, three numbers which we sometimes call the roll, pitch, and yaw.", "start": 408.68, "duration": 3.92}, {"text": "Right? So you're- if, if,", "start": 412.6, "duration": 1.535}, {"text": "if you're in an airplane roll  is that you are rolling to left or right,", "start": 414.135, "duration": 2.43}, {"text": "pitch is are you pitching up and down,", "start": 416.565, "duration": 1.56}, {"text": "and yaw is, you know, are you facing North,", "start": 418.125, "duration": 1.635}, {"text": "South, East or West, right?", "start": 419.76, "duration": 1.11}, {"text": "So there's one way to turn the three dimensional orientation", "start": 420.87, "duration": 3.44}, {"text": "of an object like an airplane or a helicopter into three numbers.", "start": 424.31, "duration": 3.67}, {"text": "So, so, uh, er,", "start": 427.98, "duration": 1.08}, {"text": "the, the details aren't important.", "start": 429.06, "duration": 1.22}, {"text": "And if you actually work on a helicopter, you would figure this out.", "start": 430.28, "duration": 2.37}, {"text": "But for today's purposes it's just- right, uh,", "start": 432.65, "duration": 2.07}, {"text": "I- I guess the [NOISE] roll, pitch, yaw.", "start": 434.72, "duration": 5.355}, {"text": "Right? But that, uh, um, to represent the, uh,", "start": 440.075, "duration": 2.93}, {"text": "orientation of a three-dimensional object flying around,", "start": 443.005, "duration": 3.055}, {"text": "this is conventionally represented with three numbers,", "start": 446.06, "duration": 2.52}, {"text": "uh, such as roll, pitch and yaw.", "start": 448.58, "duration": 1.17}, {"text": "Um, and then [NOISE] x dot, y dot,", "start": 449.75, "duration": 4.605}, {"text": "z dot, Phi dot,", "start": 454.355, "duration": 2.465}, {"text": "Theta dot, Psi dot.", "start": 456.82, "duration": 2.33}, {"text": "They're linear velocity and the, um, angular velocity.", "start": 459.15, "duration": 4.68}, {"text": "Okay? Um, [NOISE] maybe just one last example.", "start": 463.83, "duration": 5.99}, {"text": "So it turns out in, in,", "start": 469.82, "duration": 1.935}, {"text": "in reinforcement learning, uh,", "start": 471.755, "duration": 1.635}, {"text": "maybe early, early history of reinforcement learning,", "start": 473.39, "duration": 2.32}, {"text": "one of the problems that a lot of people just happened to work on, um,", "start": 475.71, "duration": 4.28}, {"text": "uh, and, and, and therefore,", "start": 479.99, "duration": 1.84}, {"text": "you'd see in a lot reinforcement learning textbooks,", "start": 481.83, "duration": 1.98}, {"text": "there's something called the inverted pendulum problem.", "start": 483.81, "duration": 2.525}, {"text": "But what that is, is a little toy, um,", "start": 486.335, "duration": 3.0}, {"text": "which is a little cart,", "start": 489.335, "duration": 1.605}, {"text": "that's on wheels, that's on a track, um,", "start": 490.94, "duration": 2.95}, {"text": "and you have a little pole that is attached to this cart and there's a", "start": 493.89, "duration": 6.29}, {"text": "free [NOISE] swivel there, right?", "start": 500.18, "duration": 6.97}, {"text": "Uh, and so this pole just flops over or", "start": 507.15, "duration": 2.55}, {"text": "this poll just swings freely and there's no motor,", "start": 509.7, "duration": 2.7}, {"text": "uh, there's no motor at this- at this little hinge there.", "start": 512.4, "duration": 3.45}, {"text": "[NOISE] And so the inverted pendulum problem is- see that I've prepared this.", "start": 515.85, "duration": 4.285}, {"text": "Right? Is- [LAUGHTER] no.", "start": 520.135, "duration": 2.215}, {"text": "I've always prepared this.. If, if, if you have, uh,", "start": 522.35, "duration": 2.23}, {"text": "if you have a free pole and if this is your cart moving left and right,", "start": 524.58, "duration": 3.14}, {"text": "the inverted pendulum problem is, you know,", "start": 527.72, "duration": 2.01}, {"text": "can you, if you see it swivel,", "start": 529.73, "duration": 1.32}, {"text": "can you kind of balance that, right?", "start": 531.05, "duration": 2.59}, {"text": "[LAUGHTER] Um, and so,", "start": 533.64, "duration": 5.299}, {"text": "uh, one of the- so common textbook examples of, uh,", "start": 538.939, "duration": 4.631}, {"text": "um, reinforcement learning is, uh,", "start": 543.57, "duration": 3.32}, {"text": "can you choose actions over time to move", "start": 546.89, "duration": 3.78}, {"text": "this left and right so as to keep the pole oriented upward?", "start": 550.67, "duration": 4.07}, {"text": "Right? And so for a problem like this, um,", "start": 554.74, "duration": 2.535}, {"text": "if you have a linear rail just a one-dimensional, you know,", "start": 557.275, "duration": 2.535}, {"text": "like a railway track that this cart is on,", "start": 559.81, "duration": 2.57}, {"text": "the state-space would be x which is the,", "start": 562.38, "duration": 2.53}, {"text": "uh, position of the cart.", "start": 564.91, "duration": 3.85}, {"text": "Um, [NOISE] Theta which is the, ah,", "start": 568.76, "duration": 3.975}, {"text": "orientation of the pole as was x dot and Theta dot.", "start": 572.735, "duration": 5.355}, {"text": "Right? So this would be a", "start": 578.09, "duration": 1.47}, {"text": "four-dimensional state-space for the- for the inverted pendulum if,", "start": 579.56, "duration": 3.54}, {"text": "if it's like running left and right on", "start": 583.1, "duration": 2.01}, {"text": "a railway track- on a one-dimensional railway track, right?", "start": 585.11, "duration": 3.945}, {"text": "Um, all right.", "start": 589.055, "duration": 2.925}, {"text": "Cool. So, uh,", "start": 591.98, "duration": 1.925}, {"text": "for all of these problems,", "start": 593.905, "duration": 1.235}, {"text": "if you want to build, you know,", "start": 595.14, "duration": 1.16}, {"text": "a self-driving car and have it do something or, um,", "start": 596.3, "duration": 3.08}, {"text": "build an autonomous helicopter [NOISE] and have it either hover stably or", "start": 599.38, "duration": 3.07}, {"text": "fly a trajectory or keep the pole upright in inverted pendulum.", "start": 602.45, "duration": 3.675}, {"text": "These are examples of robotics problems where you would", "start": 606.125, "duration": 2.835}, {"text": "model the state space as a continuous state-space.", "start": 608.96, "duration": 3.8}, {"text": "So what I wanna do today is focus on problems where the state-space [NOISE] is, um, R_n.", "start": 612.76, "duration": 7.64}, {"text": "So n-dimensional set of row numbers.", "start": 620.4, "duration": 1.8}, {"text": "And in these examples,", "start": 622.2, "duration": 1.38}, {"text": "I guess n would be 4 or 6 or 12.", "start": 623.58, "duration": 3.345}, {"text": "Right? Oh, and, uh, again,", "start": 626.925, "duration": 2.235}, {"text": "for the- for the mathematicians in this class, technically,", "start": 629.16, "duration": 2.809}, {"text": "uh, angles are not real numbers because they wrap around,", "start": 631.969, "duration": 3.196}, {"text": "and they only go to 360, and then they wrap around to 0.", "start": 635.165, "duration": 2.475}, {"text": "But I think for the purposes of today,", "start": 637.64, "duration": 1.68}, {"text": "uh, that's not important.", "start": 639.32, "duration": 1.77}, {"text": "So we just treat this as R_n.", "start": 641.09, "duration": 1.55}, {"text": "Oh, yeah. Okay. [NOISE].", "start": 642.64, "duration": 6.355}, {"text": "[NOISE] So [NOISE] all right.", "start": 648.995, "duration": 6.5}, {"text": "Um, so the most straight- straightforward way-", "start": 655.495, "duration": 3.495}, {"text": "[NOISE] the most straightforward way", "start": 658.99, "duration": 8.67}, {"text": "to work with a continuous state space is discretization where,", "start": 667.66, "duration": 4.935}, {"text": "um, you know, you might have in this example a two-dimensional state-space,", "start": 672.595, "duration": 5.505}, {"text": "maybe, ah, x and Theta for the inverted pendulum.", "start": 678.1, "duration": 3.375}, {"text": "And then you just lay down the cell or grid values, right?", "start": 681.475, "duration": 6.51}, {"text": "And discretize it back to a- a discrete state problem.", "start": 687.985, "duration": 3.735}, {"text": "Ah, and so, you know,", "start": 691.72, "duration": 1.635}, {"text": "so you can give the states a set of names, one, two, three, four,", "start": 693.355, "duration": 3.39}, {"text": "whatever and anywhere within that little square you just", "start": 696.745, "duration": 3.33}, {"text": "pretend that your MDP in the robot is in state number 1.", "start": 700.075, "duration": 3.405}, {"text": "So this takes a continuous state problem and turns it back to a discrete state problem.", "start": 703.48, "duration": 4.695}, {"text": "Um, this is such a simple straightforward way to do it.", "start": 708.175, "duration": 3.885}, {"text": "Ah, this is actually reasonable to do for small problems.", "start": 712.06, "duration": 3.015}, {"text": "Um, and if you have", "start": 715.075, "duration": 1.575}, {"text": "a relatively small low dimensional states MDP like an inverted pendulum problem,", "start": 716.65, "duration": 4.785}, {"text": "you know, four-dimensional, it's actually perfectly", "start": 721.435, "duration": 1.545}, {"text": "fine to discretize the state 3 and solve it this way.", "start": 722.98, "duration": 2.94}, {"text": "Ah, let me describe some disadvantages of discretization first.", "start": 725.92, "duration": 4.425}, {"text": "And then- and then we chat a little bit about when you should just", "start": 730.345, "duration": 2.775}, {"text": "use discretization because even though it's not the best algorithm,", "start": 733.12, "duration": 3.225}, {"text": "it works fine for smaller problems.", "start": 736.345, "duration": 3.0}, {"text": "But for bigger problems,", "start": 739.345, "duration": 1.425}, {"text": "we'll have to go to more sophisticated algorithms like fitted value iteration, okay?", "start": 740.77, "duration": 4.815}, {"text": "But, um, so what are the problems with discretization, right?", "start": 745.585, "duration": 5.155}, {"text": "Well first, actually this marker is-", "start": 751.47, "duration": 4.75}, {"text": "[NOISE] this is a very-", "start": 756.22, "duration": 8.025}, {"text": "you know there's kind of a naive representation,", "start": 764.245, "duration": 2.775}, {"text": "ah, for, ah, V_star,", "start": 767.02, "duration": 5.31}, {"text": "ah, and Pi_star, right?", "start": 772.33, "duration": 4.965}, {"text": "Which is- you know,", "start": 777.295, "duration": 1.89}, {"text": "remember the very first problem we talked about,", "start": 779.185, "duration": 3.225}, {"text": "ah, predicting housing crisis?", "start": 782.41, "duration": 2.37}, {"text": "Um, imagine if x was the size of a house,", "start": 784.78, "duration": 5.26}, {"text": "and the vertical axis was the price of a house, ah,", "start": 790.04, "duration": 3.895}, {"text": "and you have a dataset that looked like this, [NOISE] all right?", "start": 793.935, "duration": 5.645}, {"text": "Discretization is the- the- the discretization equivalent of trying", "start": 799.58, "duration": 4.1}, {"text": "to fit a function as data would be to look for the input feature and,", "start": 803.68, "duration": 4.59}, {"text": "um, you know let's discretize it into Phi values.", "start": 808.27, "duration": 4.635}, {"text": "And for each of these little buckets in- in each of these five intervals,", "start": 812.905, "duration": 3.765}, {"text": "let's fit a constant function,", "start": 816.67, "duration": 3.225}, {"text": "right, or something like that, right?", "start": 819.895, "duration": 2.91}, {"text": "So this staircase would be how,", "start": 822.805, "duration": 3.36}, {"text": "you know, discretization will represent the price of a house as a function of the size.", "start": 826.165, "duration": 5.805}, {"text": "Um, and the analogy is that what", "start": 831.97, "duration": 4.29}, {"text": "we're doing in reinforcement learning is we want to approximate the value function.", "start": 836.26, "duration": 4.485}, {"text": "And if you were to discretize it then,", "start": 840.745, "duration": 2.445}, {"text": "um, on the x-axis is maybe the state.", "start": 843.19, "duration": 3.06}, {"text": "And now, I'm down to one-dimensional state, right?", "start": 846.25, "duration": 2.07}, {"text": "Cause that's where I can plot.", "start": 848.32, "duration": 1.2}, {"text": "And you are saying that, well,", "start": 849.52, "duration": 1.935}, {"text": "let's approximate the value function, you know,", "start": 851.455, "duration": 2.775}, {"text": "as a- as a staircase function,", "start": 854.23, "duration": 2.61}, {"text": "as a function of the set of states, right?", "start": 856.84, "duration": 2.31}, {"text": "And you know- and this is not terrible.", "start": 859.15, "duration": 2.01}, {"text": "If you have a lot of data and very few input features,", "start": 861.16, "duration": 2.34}, {"text": "you can get away with this. This will work, okay?", "start": 863.5, "duration": 1.965}, {"text": "But, it- it- it- it doesn't,", "start": 865.465, "duration": 1.44}, {"text": "it doesn't seem to s- allow you to fit a smoother function, right?", "start": 866.905, "duration": 4.56}, {"text": "Um, so that's one downside.", "start": 871.465, "duration": 2.295}, {"text": "It's just not a very good representation.", "start": 873.76, "duration": 1.875}, {"text": "Um, and the second downside is the, ah, dimensionality.", "start": 875.635, "duration": 10.845}, {"text": "All right. Some- somewhat fancifully named cursive dimensionality,", "start": 886.48, "duration": 4.605}, {"text": "which is, ah, and Richard Bellman had given this name, and this is a cool sounding name.", "start": 891.085, "duration": 5.295}, {"text": "But, what it means is that if, um,", "start": 896.38, "duration": 2.385}, {"text": "the state space is in R_n, um, and discretize,", "start": 898.765, "duration": 6.145}, {"text": "you know, each dimension into k values,", "start": 905.37, "duration": 9.08}, {"text": "then you get k_n discrete states, right?", "start": 914.46, "duration": 8.35}, {"text": "So if we discretize, ah,", "start": 922.81, "duration": 2.685}, {"text": "position and orientation into 10 values which is quite small,", "start": 925.495, "duration": 3.63}, {"text": "then you end up with you know 10-n states which", "start": 929.125, "duration": 3.255}, {"text": "grows exponentially and in the dimensional state space n. So, um,", "start": 932.38, "duration": 3.495}, {"text": "discretization works fine if you have relatively low dimensional problems,", "start": 935.875, "duration": 4.29}, {"text": "like two-dimensions, no problem,", "start": 940.165, "duration": 1.905}, {"text": "four dimensions maybe it's okay.", "start": 942.07, "duration": 1.695}, {"text": "But they were very high-dimensional state spaces.", "start": 943.765, "duration": 2.34}, {"text": "Ah, this is- this is not a good- this is not a good representation, right?", "start": 946.105, "duration": 5.135}, {"text": "And, um, it turns out the cursive dimensionality- to take a slight aside", "start": 951.24, "duration": 5.835}, {"text": "from continuous state spaces because dimensionality also", "start": 957.075, "duration": 3.195}, {"text": "applies for very large discrete state MDPs.", "start": 960.27, "duration": 3.745}, {"text": "So for example, one of the places people have", "start": 964.015, "duration": 3.135}, {"text": "applied reinforcement learning is in factory optimization, right?", "start": 967.15, "duration": 3.3}, {"text": "So we have a factory with 100 machines in a factory", "start": 970.45, "duration": 3.84}, {"text": "and if every machine in the factory is doing something slightly different, um,", "start": 974.29, "duration": 4.875}, {"text": "then if you have 100 machines in a giant factory, ah,", "start": 979.165, "duration": 6.345}, {"text": "each- and each machine can be in k different states,", "start": 985.51, "duration": 5.25}, {"text": "then the total number of states of your factory is,", "start": 990.76, "duration": 3.84}, {"text": "um, k to the power of 100, right?", "start": 994.6, "duration": 3.975}, {"text": "And so even if- so- so cursive dimensionality also", "start": 998.575, "duration": 2.775}, {"text": "applies to very large discrete state spaces such as if you have a factory,", "start": 1001.35, "duration": 4.575}, {"text": "with 100 machines, and then your total state space becomes k to the 100.", "start": 1005.925, "duration": 3.975}, {"text": "Um, and it turns out that for this to have a discrete state space,", "start": 1009.9, "duration": 2.82}, {"text": "ah, fitted value iteration can be a much better algorithm as well.", "start": 1012.72, "duration": 4.38}, {"text": "We'll get to fitted evaluation in a little bit, okay?", "start": 1017.1, "duration": 3.315}, {"text": "So, um, let's see.", "start": 1020.415, "duration": 6.24}, {"text": "So some practical- so, ah,", "start": 1026.655, "duration": 4.815}, {"text": "now despite all this criticism of digitalization", "start": 1031.47, "duration": 3.195}, {"text": "if you have a small state space there's a simple method,", "start": 1034.665, "duration": 2.865}, {"text": "ah, to try to apply, you know.", "start": 1037.53, "duration": 2.175}, {"text": "And- and if- if you have a very small state space,", "start": 1039.705, "duration": 2.43}, {"text": "go ahead and discretize it if you want", "start": 1042.135, "duration": 1.485}, {"text": "quick things to try and just get something working.", "start": 1043.62, "duration": 2.37}, {"text": "Ah, so let me share with you some maybe guidelines.", "start": 1045.99, "duration": 3.45}, {"text": "Ah, this is- this is how I do it I guess, right?", "start": 1049.44, "duration": 2.655}, {"text": "If you have a, you know,", "start": 1052.095, "duration": 1.815}, {"text": "two-dimensional state space or", "start": 1053.91, "duration": 1.65}, {"text": "three dimensional state space, it's no problem, just discretize.", "start": 1055.56, "duration": 3.42}, {"text": "Of usually for a lot of problems,", "start": 1058.98, "duration": 1.74}, {"text": "uh, it's just fine.", "start": 1060.72, "duration": 1.935}, {"text": "Um, if you have maybe a 4-6 dimensional state space,", "start": 1062.655, "duration": 5.88}, {"text": "um, you know, I would think about it,", "start": 1068.535, "duration": 2.115}, {"text": "ah, and it will still often work.", "start": 1070.65, "duration": 2.115}, {"text": "So for the inverted pendulum which is four-dimensional state space,", "start": 1072.765, "duration": 2.625}, {"text": "it works just fine.", "start": 1075.39, "duration": 1.23}, {"text": "Um, I've had some friends work on, ah,", "start": 1076.62, "duration": 2.385}, {"text": "trying to, ah, drive a old bicycle, right?", "start": 1079.005, "duration": 3.645}, {"text": "Which you can model as a six-dimensional state space, ah,", "start": 1082.65, "duration": 2.565}, {"text": "and you know discretization it- it kind of", "start": 1085.215, "duration": 2.925}, {"text": "works as it- it- it works if you put some work into it.", "start": 1088.14, "duration": 3.315}, {"text": "Ah, one of the tricks you want to use as you approach", "start": 1091.455, "duration": 3.015}, {"text": "the 4-6 dimensional state space range is,", "start": 1094.47, "duration": 3.66}, {"text": "ah, choose your discretization more carefully.", "start": 1098.13, "duration": 3.09}, {"text": "So for example, if the state S2 is really important.", "start": 1101.22, "duration": 5.055}, {"text": "So if you think the- the actions you need to take or the value of", "start": 1106.275, "duration": 3.945}, {"text": "the performance is really sensitive to the state S2 and less in the state S1,", "start": 1110.22, "duration": 4.8}, {"text": "then, um, in this range people end up designing, um,", "start": 1115.02, "duration": 4.455}, {"text": "unequal discretizations where you might discretize S2 much more finely than S1, right?", "start": 1119.475, "duration": 4.845}, {"text": "And- and the reason you do that is, ah,", "start": 1124.32, "duration": 2.115}, {"text": "the number of states, the number of discrete states is now blowing up exponentially.", "start": 1126.435, "duration": 3.525}, {"text": "Something to the power of 4, something to the power of 6.", "start": 1129.96, "duration": 1.98}, {"text": "And these tricks allow you to just reduce", "start": 1131.94, "duration": 2.1}, {"text": "a little bit the number of discrete states you end up having to model.", "start": 1134.04, "duration": 3.99}, {"text": "Um, I think, you know,", "start": 1138.03, "duration": 3.03}, {"text": "if you have a 7-8 dimensional problem,", "start": 1141.06, "duration": 1.77}, {"text": "ah, I- that- that's pushing it.", "start": 1142.83, "duration": 1.995}, {"text": "That's when I would kind of be nervous, and- and,", "start": 1144.825, "duration": 2.82}, {"text": "you know, be increasingly inclined to not use discretization.", "start": 1147.645, "duration": 3.42}, {"text": "I personally rarely used discretization for problems that are eight-dimensional.", "start": 1151.065, "duration": 4.905}, {"text": "Ah, and then when your problems that are even higher-dimensional than this.", "start": 1155.97, "duration": 3.33}, {"text": "You know like 9, 10,", "start": 1159.3, "duration": 1.41}, {"text": "and higher than I would very seriously consider,", "start": 1160.71, "duration": 2.74}, {"text": "um, ah, an algorithm that does not discretize.", "start": 1163.45, "duration": 3.125}, {"text": "Very rare, um, to use discretization for- for problems this high.", "start": 1166.575, "duration": 4.425}, {"text": "Even seven to eight is quite rare.", "start": 1171.0, "duration": 1.38}, {"text": "I've seen it done in rare occasions", "start": 1172.38, "duration": 1.62}, {"text": "but- but- and- and - and these things get worse exponentially, right?", "start": 1174.0, "duration": 3.9}, {"text": "With the number of dimensions.", "start": 1177.9, "duration": 1.05}, {"text": "So maybe there's a set of guidelines for when to use", "start": 1178.95, "duration": 3.6}, {"text": "discretization and when to seriously consider doing something else.", "start": 1182.55, "duration": 5.08}, {"text": "All right. So, um,", "start": 1189.83, "duration": 3.58}, {"text": "in the alternative approach that you see today, ah,", "start": 1193.41, "duration": 3.915}, {"text": "what you will be able to do is to approximate V star", "start": 1197.325, "duration": 6.135}, {"text": "directly without resorting to discretization, okay?", "start": 1203.46, "duration": 15.61}, {"text": "And, um, uh, there'll be an analogy that will make later,", "start": 1219.07, "duration": 5.05}, {"text": "uh, just, you know alluding to this plot again.", "start": 1224.12, "duration": 3.195}, {"text": "Right, so this analogy between linear regression where you're trying to approximate", "start": 1227.315, "duration": 3.135}, {"text": "y as a function of X and value iteration,", "start": 1230.45, "duration": 3.33}, {"text": "where you're trying to learn or approximate V as a function of s. Right, that's v star.", "start": 1233.78, "duration": 6.345}, {"text": "Which is that in linear regression, um,", "start": 1240.125, "duration": 3.9}, {"text": "you say let's approximate X as a linear function of y, right, um,", "start": 1244.025, "duration": 8.63}, {"text": "or if you don't want to use the roll features y, ah,", "start": 1252.655, "duration": 3.135}, {"text": "what you can do is,", "start": 1255.79, "duration": 1.74}, {"text": "um, use, you know,", "start": 1257.53, "duration": 3.945}, {"text": "theta transpose, theta transpose phi, oh,", "start": 1261.475, "duration": 2.445}, {"text": "I'm sorry, got that totally mixed up.", "start": 1263.92, "duration": 3.52}, {"text": "Right, where phi of X is the features of x, ah, so if, um, ah, right?", "start": 1268.45, "duration": 10.015}, {"text": "So this is what linear regression does where if X is", "start": 1278.465, "duration": 3.285}, {"text": "your housing price then maybe phi of X is equal to,", "start": 1281.75, "duration": 3.735}, {"text": "you know, X_1, X_2,", "start": 1285.485, "duration": 2.4}, {"text": "X_1 squared, X_1, X_2 and so on, right?", "start": 1287.885, "duration": 4.53}, {"text": "So that's how, that's how you can use", "start": 1292.415, "duration": 2.205}, {"text": "linear regression to approximate the price of a house,", "start": 1294.62, "duration": 2.655}, {"text": "either as a function of the raw features or as a function of some,", "start": 1297.275, "duration": 3.75}, {"text": "you know, slightly more sophisticated, slightly more complex set of features of the house.", "start": 1301.025, "duration": 4.185}, {"text": "And what, we will- what,", "start": 1305.21, "duration": 2.265}, {"text": "what you see in, um,", "start": 1307.475, "duration": 1.725}, {"text": "fitted value iteration is a model where we will approximate v star of s as,", "start": 1309.2, "duration": 9.105}, {"text": "um, a linear function of features of the state.", "start": 1318.305, "duration": 7.095}, {"text": "Okay? So that's the algorithm we'll build up to.", "start": 1325.4, "duration": 3.075}, {"text": "And, uh, um, uh,", "start": 1328.475, "duration": 2.85}, {"text": "yeah we're going to try to use linear regression with a lot", "start": 1331.325, "duration": 3.885}, {"text": "of modifications to approximate the value function.", "start": 1335.21, "duration": 3.825}, {"text": "Okay? And, and, and again in reinforcement learning in value iteration, um, the,", "start": 1339.035, "duration": 5.775}, {"text": "the- your goal is to find a good approximation to", "start": 1344.81, "duration": 2.43}, {"text": "the value function because once you have that you can then use,", "start": 1347.24, "duration": 3.45}, {"text": "you know, the equation we had earlier to", "start": 1350.69, "duration": 1.56}, {"text": "compute the optimal action for every state, right?", "start": 1352.25, "duration": 2.31}, {"text": "So, so we just focused on computing the value function.", "start": 1354.56, "duration": 3.52}, {"text": "Now in order to derive the fitted value iteration algorithm, um,", "start": 1358.66, "duration": 8.86}, {"text": "it turns out that, uh, um,", "start": 1367.52, "duration": 3.675}, {"text": "fits it value iteration, um,", "start": 1371.195, "duration": 2.775}, {"text": "works best with a model with simulator of the MDP.", "start": 1373.97, "duration": 4.47}, {"text": "So let me describe what that means and", "start": 1378.44, "duration": 1.98}, {"text": "how you get the model and then we'll talk about how you can", "start": 1380.42, "duration": 2.13}, {"text": "actually you implement the fitted value iteration algorithm", "start": 1382.55, "duration": 3.54}, {"text": "and have it work on these types of problems.", "start": 1386.09, "duration": 2.595}, {"text": "Okay?", "start": 1388.685, "duration": 1.435}, {"text": "All right.", "start": 1398.71, "duration": 1.57}, {"text": "So, um, what a model of a or", "start": 1400.28, "duration": 15.69}, {"text": "a simulator of your robot is- is just a function that takes as input", "start": 1415.97, "duration": 8.34}, {"text": "a state, takes as inputs an action and it outputs", "start": 1424.31, "duration": 5.91}, {"text": "the next state S prime drawn from the state transition probabilities.", "start": 1430.22, "duration": 6.36}, {"text": "Okay? Um, and the way that a model is built,", "start": 1436.58, "duration": 4.455}, {"text": "um, is that, um, uh,", "start": 1441.035, "duration": 3.09}, {"text": "the states and the actions,", "start": 1444.125, "duration": 2.205}, {"text": "uh, above, uh, uh, and,", "start": 1446.33, "duration": 1.77}, {"text": "and let's see, and the way the model is built is the state is just a row value vector.", "start": 1448.1, "duration": 4.875}, {"text": "Okay? Oh, and, um,", "start": 1452.975, "duration": 1.785}, {"text": "I think for simplicity, uh,", "start": 1454.76, "duration": 3.135}, {"text": "for now let's assume that the action space is discrete.", "start": 1457.895, "duration": 4.05}, {"text": "Um, it turns out that for a lot of MDPs,", "start": 1461.945, "duration": 3.435}, {"text": "the state space can be very high dimensional,", "start": 1465.38, "duration": 3.015}, {"text": "and the action space is much lower-dimensional than the state space.", "start": 1468.395, "duration": 4.14}, {"text": "Uh, so for example for a car, you know,", "start": 1472.535, "duration": 3.39}, {"text": "S is, uh, uh, six-dimensional.", "start": 1475.925, "duration": 3.555}, {"text": "But the space of actions is just two dimensional, right?", "start": 1479.48, "duration": 3.03}, {"text": "The steering and braking.", "start": 1482.51, "duration": 1.395}, {"text": "Uh, It turns out for a helicopter you know the state space is 12-dimensional.", "start": 1483.905, "duration": 6.3}, {"text": "And I guess you probably mostly, I wouldn't expect", "start": 1490.205, "duration": 2.985}, {"text": "you to know how a helicopter flies but it turns out there you have, uh,", "start": 1493.19, "duration": 2.899}, {"text": "four-dimensional actions in a helicopter.", "start": 1496.089, "duration": 2.281}, {"text": "The way you fly a helicopter is you have two control sticks,", "start": 1498.37, "duration": 2.01}, {"text": "so your left hand and your right hand you can move,", "start": 1500.38, "duration": 3.09}, {"text": "uh, uh, has two-dimensions of control.", "start": 1503.47, "duration": 2.88}, {"text": "And for the inverted pendulum, I guess,", "start": 1506.35, "duration": 3.52}, {"text": "the state space is 4D and the action spaces is just 1D, right?", "start": 1509.87, "duration": 3.6}, {"text": "You move left or right.", "start": 1513.47, "duration": 1.02}, {"text": "So you actually see in a lot, um,", "start": 1514.49, "duration": 2.37}, {"text": "reinforcing learning problems that it's quite common", "start": 1516.86, "duration": 3.18}, {"text": "for the state-space to be much higher dimensional than the action space.", "start": 1520.04, "duration": 3.36}, {"text": "And so, um, let's say for now", "start": 1523.4, "duration": 3.21}, {"text": "that we do not want to discretize the state space because it's too high dimensional.", "start": 1526.61, "duration": 4.59}, {"text": "But just for the sake of simplicity let's say", "start": 1531.2, "duration": 2.28}, {"text": "we discretize the action space for now, right?", "start": 1533.48, "duration": 2.39}, {"text": "Which is, which is usually much easier to do.", "start": 1535.87, "duration": 1.86}, {"text": "But I think as we develop fitted value integration as well, uh,", "start": 1537.73, "duration": 3.51}, {"text": "we'll- we'll you might- you'll get hints of", "start": 1541.24, "duration": 2.76}, {"text": "when maybe you don't need to discretize your action space either,", "start": 1544.0, "duration": 3.315}, {"text": "but let's just say we have a discrete,", "start": 1547.315, "duration": 1.53}, {"text": "discrete action space for now.", "start": 1548.845, "duration": 1.89}, {"text": "Okay?", "start": 1550.735, "duration": 1.585}, {"text": "So, all right", "start": 1564.4, "duration": 5.45}, {"text": "so how do you get a model, right?", "start": 1569.85, "duration": 3.395}, {"text": "Um, one way to", "start": 1573.245, "duration": 9.645}, {"text": "build a model is to use a physics simulator.", "start": 1582.89, "duration": 4.39}, {"text": "So, um, you know in the case of an inverted pendulum, right?", "start": 1588.52, "duration": 6.835}, {"text": "It turns out that, uh, uh,", "start": 1595.355, "duration": 1.785}, {"text": "well the action is what's the acceleration you apply to", "start": 1597.14, "duration": 3.57}, {"text": "either positive or negative or to the, to accelerate to the left or the right.", "start": 1600.71, "duration": 3.765}, {"text": "Then it turns out that,", "start": 1604.475, "duration": 1.305}, {"text": "um, uh, let's see,", "start": 1605.78, "duration": 1.86}, {"text": "so the state space is four-dimensional, right, and it turns out that, um,", "start": 1607.64, "duration": 7.98}, {"text": "if you sort of flip open a- a physics textbook Newtonian mechanics, uh,", "start": 1615.62, "duration": 5.655}, {"text": "if you know the weight of the car,", "start": 1621.275, "duration": 1.605}, {"text": "the weight of the pole,", "start": 1622.88, "duration": 1.2}, {"text": "um, uh, uh, yeah I think that's it actually.", "start": 1624.08, "duration": 3.42}, {"text": "If you know the mass of the car and the mass of the pole,", "start": 1627.5, "duration": 1.77}, {"text": "uh, and the length of the pole,", "start": 1629.27, "duration": 2.145}, {"text": "it turns out you can derive equations about what is the velocity, right?", "start": 1631.415, "duration": 4.455}, {"text": "So it turns out S dot is equal,", "start": 1635.87, "duration": 1.665}, {"text": "you know, don't- don't worry about this.", "start": 1637.535, "duration": 3.165}, {"text": "Think of the math as decoration rather than something you need to learn where,", "start": 1640.7, "duration": 4.665}, {"text": "you know, L is the length of the pole,", "start": 1645.365, "duration": 1.605}, {"text": "M is the mass of one of these things actually don't worry about it.", "start": 1646.97, "duration": 2.565}, {"text": "M is the pole mass, uh,", "start": 1649.535, "duration": 1.71}, {"text": "A is the force extended and so on.", "start": 1651.245, "duration": 3.045}, {"text": "Um, uh and, and a conventional physics textbook will,", "start": 1654.29, "duration": 4.26}, {"text": "will, kind of let you derive these equations, uh, or,", "start": 1658.55, "duration": 3.195}, {"text": "or rather than trying to derive this yourself using, uh, uh, you know,", "start": 1661.745, "duration": 4.155}, {"text": "either yourself using Newtonian mechanics or finding the help of a physicist friend, uh,", "start": 1665.9, "duration": 4.71}, {"text": "there are also a lot of, um, uh,", "start": 1670.61, "duration": 2.52}, {"text": "open source, uh, physics simulators and software packages.", "start": 1673.13, "duration": 2.925}, {"text": "Where you can download an open source simulator plug in the dimensions", "start": 1676.055, "duration": 3.225}, {"text": "and mass and so on of your system, and then they'll spit out of the simulator like this.", "start": 1679.28, "duration": 3.285}, {"text": "It tells you how the state evolves from one time step to another time step.", "start": 1682.565, "duration": 3.645}, {"text": "All right, and so- but so in this example the simulator would say that,", "start": 1686.21, "duration": 4.275}, {"text": "um, S prime is equal to S plus,", "start": 1690.485, "duration": 3.72}, {"text": "you know, Delta t times I guess,", "start": 1694.205, "duration": 6.225}, {"text": "uh, times S dot,", "start": 1700.43, "duration": 2.52}, {"text": "where Delta t could be lets say 0.1 seconds, right?", "start": 1702.95, "duration": 5.805}, {"text": "So you want to simulate this at 10 hertz, uh,", "start": 1708.755, "duration": 2.655}, {"text": "so that 10, 10 updates per second so that", "start": 1711.41, "duration": 3.375}, {"text": "the time difference between the current state and", "start": 1714.785, "duration": 1.875}, {"text": "the next state is one-tenth of a second.", "start": 1716.66, "duration": 1.755}, {"text": "Then you write a simulator like this.", "start": 1718.415, "duration": 3.165}, {"text": "Okay? Um, and, but- and, and really,", "start": 1721.58, "duration": 3.18}, {"text": "the most common way to do this is not to actually derive the, um, uh,", "start": 1724.76, "duration": 4.155}, {"text": "physics update equations and the most common way to do this is to just", "start": 1728.915, "duration": 2.745}, {"text": "download one or the open source physics engines, right?", "start": 1731.66, "duration": 4.45}, {"text": "So, um, this will work okay for,", "start": 1736.84, "duration": 3.79}, {"text": "uh, problems like the inverted pendulum.", "start": 1740.63, "duration": 3.105}, {"text": "Um, I once used a sort of physics engines to build", "start": 1743.735, "duration": 4.605}, {"text": "a simulator for a four-legged robot and manage to used", "start": 1748.34, "duration": 2.46}, {"text": "reinforcement learning to get a four-legged robot to walk around, right?", "start": 1750.8, "duration": 3.0}, {"text": "So it, it, it works.", "start": 1753.8, "duration": 1.905}, {"text": "Although um, um,", "start": 1755.705, "duration": 6.855}, {"text": "the second way to get a model is to learn it from data.", "start": 1762.56, "duration": 4.57}, {"text": "All right, and I, I personally end up using this much more often.", "start": 1770.83, "duration": 5.36}, {"text": "So, um, here's what I mean.", "start": 1781.22, "duration": 3.925}, {"text": "There actually- let's say you want to build a,", "start": 1785.145, "duration": 2.43}, {"text": "uh, controller for an autonomous helicopter, right?", "start": 1787.575, "duration": 2.705}, {"text": "So, so really, this is a case study.", "start": 1790.28, "duration": 1.5}, {"text": "And what I'm describing is real,", "start": 1791.78, "duration": 1.53}, {"text": "like this will actually work, right?", "start": 1793.31, "duration": 1.56}, {"text": "Uh, let's say you wanna build, uh, uh,", "start": 1794.87, "duration": 1.92}, {"text": "let's say you haven't- let's say you have", "start": 1796.79, "duration": 1.62}, {"text": "a helicopter and you want to build an autonomous controller for it.", "start": 1798.41, "duration": 2.61}, {"text": "What you can do is, um,", "start": 1801.02, "duration": 2.76}, {"text": "start your helicopter off in some state S0, right?", "start": 1803.78, "duration": 4.315}, {"text": "So with, uh, GPS accelerometers, magnetic compass,", "start": 1808.095, "duration": 3.645}, {"text": "you can just measure the position and orientation of", "start": 1811.74, "duration": 2.07}, {"text": "the helicopter and then have a human pilot,", "start": 1813.81, "duration": 3.3}, {"text": "fly the helicopter around.", "start": 1817.11, "duration": 1.44}, {"text": "So the human pilot, [NOISE] you know,", "start": 1818.55, "duration": 2.01}, {"text": "using control sticks, will move the helicopter.", "start": 1820.56, "duration": 3.45}, {"text": "They'll, they'll, they'll command the helicopter with some action A0,", "start": 1824.01, "duration": 3.51}, {"text": "and then a 10th of a second later,", "start": 1827.52, "duration": 2.43}, {"text": "[NOISE] the helicopter will get to", "start": 1829.95, "duration": 1.8}, {"text": "some slightly different position and orientation as one.", "start": 1831.75, "duration": 3.495}, {"text": "And then the human pilot, you know,", "start": 1835.245, "duration": 2.79}, {"text": "will just keep on moving the control sticks, uh,", "start": 1838.035, "duration": 2.97}, {"text": "and rec- so you record down what actions they  are taken, A1.", "start": 1841.005, "duration": 3.645}, {"text": "And based on that, the helicopter [NOISE] will get to some new state S2,", "start": 1844.65, "duration": 3.63}, {"text": "and then they will [NOISE] take some action A2,", "start": 1848.28, "duration": 3.23}, {"text": "[NOISE] that get to some state S3,", "start": 1851.51, "duration": 2.16}, {"text": "[NOISE] and so on.", "start": 1853.67, "duration": 1.29}, {"text": "And, and [NOISE] let me just write this as S_T, right?", "start": 1854.96, "duration": 3.39}, {"text": "So in other words, what you do is, uh,", "start": 1858.35, "duration": 1.815}, {"text": "take the helicopter out to the field and hire a human pilot to fly this thing", "start": 1860.165, "duration": 4.705}, {"text": "for a while and record the position of the helicopter 10 times a second,", "start": 1864.87, "duration": 4.935}, {"text": "and also record all the actions that human pilot was taking on the control stick.", "start": 1869.805, "duration": 5.97}, {"text": "Okay. Um, and then do this not just one time,", "start": 1875.775, "duration": 5.58}, {"text": "but do this m times.", "start": 1881.355, "duration": 1.575}, {"text": "So let me use, uh, superscript 1.", "start": 1882.93, "duration": 2.67}, {"text": "[NOISE] Or you get the idea.", "start": 1885.6, "duration": 2.7}, {"text": "All that, great. Uh, to denote the first, uh, trajectory.", "start": 1888.3, "duration": 5.55}, {"text": "So you do this a second time, [NOISE] right?", "start": 1893.85, "duration": 6.405}, {"text": "And so on and, and, uh,", "start": 1900.255, "duration": 1.29}, {"text": "maybe do this m times, right?", "start": 1901.545, "duration": 2.745}, {"text": "So ba- thi- this is just a lot of math that's saying fly the helicopter around,", "start": 1904.29, "duration": 3.675}, {"text": "you know, m times, right?", "start": 1907.965, "duration": 1.26}, {"text": "And then record everything that happened.", "start": 1909.225, "duration": 2.545}, {"text": "And now, um, your goal is to apply, [NOISE] uh,", "start": 1918.86, "duration": 8.485}, {"text": "supervised learning, [NOISE] right?", "start": 1927.345, "duration": 7.865}, {"text": "To estimate S_t plus", "start": 1935.21, "duration": 6.545}, {"text": "1 as a function of S_t [NOISE] and A_t, right?", "start": 1941.755, "duration": 6.935}, {"text": "So the job of the model- the job of the simulator is to", "start": 1948.69, "duration": 3.105}, {"text": "take as input the current state and the current action,", "start": 1951.795, "duration": 3.015}, {"text": "[NOISE] and tell you where the helicopter is gonna go,", "start": 1954.81, "duration": 2.385}, {"text": "you know, the- like 0.1 seconds later.", "start": 1957.195, "duration": 2.64}, {"text": "And so, um, given all this data,", "start": 1959.835, "duration": 3.585}, {"text": "what you can do is apply a supervised learning algorithm to predict", "start": 1963.42, "duration": 4.71}, {"text": "wha- what is the next state S prime as a function of the current state and action, right?", "start": 1968.13, "duration": 4.98}, {"text": "And, and the other notation as [NOISE] in,", "start": 1973.11, "duration": 1.935}, {"text": "in when I drew that box for the simulator above,", "start": 1975.045, "duration": 2.19}, {"text": "I was using S prime to denote S_t plus 1 and,", "start": 1977.235, "duration": 3.465}, {"text": "uh, S and a, right?", "start": 1980.7, "duration": 1.8}, {"text": "So that's the mapping between the notations.", "start": 1982.5, "duration": 3.42}, {"text": "Um, and so [NOISE] if you use the linear regression version", "start": 1985.92, "duration": 6.66}, {"text": "[NOISE] of this idea,", "start": 1992.58, "duration": 7.05}, {"text": "um, you will say,", "start": 1999.63, "duration": 2.49}, {"text": "[NOISE] let's approximate S_t plus 1 as a linear function of the previous state,", "start": 2002.12, "duration": 6.735}, {"text": "plus another linear function of the previous state.", "start": 2008.855, "duration": 3.87}, {"text": "Um, and it turns out this actually works okay for helicopters flying at slow speeds.", "start": 2012.725, "duration": 4.755}, {"text": "This is actually not a terrible model, if, uh,", "start": 2017.48, "duration": 1.965}, {"text": "if your helicopter is moving slowly,", "start": 2019.445, "duration": 1.785}, {"text": "uh, and, and, and not flying upside down.", "start": 2021.23, "duration": 2.145}, {"text": "If, if your helicopter is flying in a relatively level way at kind of a slow speed,", "start": 2023.375, "duration": 4.095}, {"text": "this model is not too bad.", "start": 2027.47, "duration": 1.2}, {"text": "[NOISE] Um, if you're flying a helicopter in a highly dynamic situations, flying very fast,", "start": 2028.67, "duration": 5.25}, {"text": "making a very fast aggressive turn,", "start": 2033.92, "duration": 1.65}, {"text": "then this is not a great model but this is actually okay for slow speeds, right?", "start": 2035.57, "duration": 4.11}, {"text": "Um, and so I", "start": 2039.68, "duration": 9.12}, {"text": "guess A here will be,", "start": 2048.8, "duration": 2.25}, {"text": "uh, n by n matrix because,", "start": 2051.05, "duration": 3.42}, {"text": "uh, the state space is n-dimensional, you know, uh, uh,", "start": 2054.47, "duration": 2.975}, {"text": "so A is a square matrix and B,", "start": 2057.445, "duration": 3.225}, {"text": "um, will usually be a tall skinny matrix I guess,", "start": 2060.67, "duration": 2.76}, {"text": "whereas the dimension of B is", "start": 2063.43, "duration": 2.07}, {"text": "the dimension of the state space by the dimension of the action space.", "start": 2065.5, "duration": 3.855}, {"text": "Okay? [NOISE] And so,", "start": 2069.355, "duration": 2.92}, {"text": "um, in order to fit the parameters a and b,", "start": 2072.275, "duration": 2.775}, {"text": "[NOISE] you would minimize with respect to the parameters A and", "start": 2075.05, "duration": 3.24}, {"text": "B of this, [NOISE] uh,", "start": 2078.29, "duration": 21.07}, {"text": "okay. [NOISE] So you", "start": 2101.23, "duration": 7.06}, {"text": "wanna approximate S_t plus 1 as a function of that,", "start": 2108.29, "duration": 4.995}, {"text": "and so, you know,", "start": 2113.285, "duration": 2.55}, {"text": "pretty natural to fit the parameters of this linear model in a way", "start": 2115.835, "duration": 5.085}, {"text": "that minimizes the squared difference", "start": 2120.92, "duration": 1.86}, {"text": "between the left-hand side the right-hand side. Wait, did I screw up?", "start": 2122.78, "duration": 3.42}, {"text": "Yes.", "start": 2126.2, "duration": 0.54}, {"text": "Go ahead.", "start": 2126.74, "duration": 0.45}, {"text": "[inaudible].", "start": 2127.19, "duration": 3.39}, {"text": "Uh, say that again.", "start": 2130.58, "duration": 0.78}, {"text": "[inaudible].", "start": 2131.36, "duration": 5.76}, {"text": "Oh, sure. Uh, what's the difference between flying a helicopter m times versus flying a helicopter,", "start": 2137.12, "duration": 3.675}, {"text": "once, very, very long.", "start": 2140.795, "duration": 1.995}, {"text": "Uh, uh in this example,", "start": 2142.79, "duration": 1.29}, {"text": "it, it makes no difference.", "start": 2144.08, "duration": 1.17}, {"text": "Yeah. This, this is fine either way.", "start": 2145.25, "duration": 2.25}, {"text": "Uh, uh, u- u- unless, um, uh- yeah for practical purposes, it doesn't matter.", "start": 2147.5, "duration": 4.83}, {"text": "Uh, sorry. Uh, for,", "start": 2152.33, "duration": 1.74}, {"text": "for, um, for the purposes of this class, it doesn't matter.", "start": 2154.07, "duration": 2.67}, {"text": "For practical purposes, if you fly the helicopter m times,", "start": 2156.74, "duration": 2.955}, {"text": "it turns out the fuel burns down slowly.", "start": 2159.695, "duration": 2.265}, {"text": "And so the way the helicopter changes slowly and you wanna", "start": 2161.96, "duration": 2.76}, {"text": "average over how much fuel do you have or wind conditions,", "start": 2164.72, "duration": 3.03}, {"text": "this is what actually is done.", "start": 2167.75, "duration": 1.35}, {"text": "But for the purposes of understanding this algorithm,", "start": 2169.1, "duration": 3.15}, {"text": "flying a single time for a long time,", "start": 2172.25, "duration": 1.41}, {"text": "you know, works just fine as well.", "start": 2173.66, "duration": 2.47}, {"text": "Okay? Um, so this is the linear regression version of this, and, uh, uh,", "start": 2179.5, "duration": 6.969}, {"text": "and we, we actually talk about, uh, uh,", "start": 2186.469, "duration": 2.056}, {"text": "some other models later,", "start": 2188.525, "duration": 1.725}, {"text": "uh, called LQR and LQG.", "start": 2190.25, "duration": 2.31}, {"text": "Uh, you, you see this linear regression version of a model as well.", "start": 2192.56, "duration": 4.005}, {"text": "Just read, just a linear mo- model, the dynamics, right?", "start": 2196.565, "duration": 2.805}, {"text": "Uh, um, uh, we- we'll,", "start": 2199.37, "duration": 2.025}, {"text": "we'll come back to linear models dynamics later, uh, next week.", "start": 2201.395, "duration": 3.45}, {"text": "But it turns out that, um,", "start": 2204.845, "duration": 1.99}, {"text": "if you want to use a nonlinear model,", "start": 2206.835, "duration": 2.645}, {"text": "uh, you know, plugging in non-linear.", "start": 2209.48, "duration": 2.025}, {"text": "If, if you, you can also plug in,", "start": 2211.505, "duration": 2.475}, {"text": "right, Phi of S, you know,", "start": 2213.98, "duration": 2.01}, {"text": "and maybe phi prime of a as well,", "start": 2215.99, "duration": 1.98}, {"text": "if you want to have a lan- non-linear model.", "start": 2217.97, "duration": 2.655}, {"text": "Um, and, and this will work even better depending on your choice of features.", "start": 2220.625, "duration": 4.815}, {"text": "Okay? Now, um, [NOISE] finally,", "start": 2225.44, "duration": 7.395}, {"text": "having run this little linear regression thing,", "start": 2232.835, "duration": 3.285}, {"text": "where you- and it- it's not quite linear regression because A and B are matrices,", "start": 2236.12, "duration": 3.39}, {"text": "but, uh, but you can minimize this objective.", "start": 2239.51, "duration": 2.7}, {"text": "And it turns out to- this turns out to be equivalent", "start": 2242.21, "duration": 2.49}, {"text": "to running linear regression n times.", "start": 2244.7, "duration": 2.835}, {"text": "Um, so S has 12 dimensions.", "start": 2247.535, "duration": 3.06}, {"text": "This turns out to be equivalent to running linear regression", "start": 2250.595, "duration": 2.61}, {"text": "n times to predict the first state,", "start": 2253.205, "duration": 2.595}, {"text": "second state, third state variable, and so on, right?", "start": 2255.8, "duration": 2.925}, {"text": "That- that's- this is what- what this is equivalent to.", "start": 2258.725, "duration": 2.715}, {"text": "But having done this,", "start": 2261.44, "duration": 1.545}, {"text": "you now have a choice of two possible models.", "start": 2262.985, "duration": 3.195}, {"text": "One model would be to just [NOISE] say my model will set S_t plus 1", "start": 2266.18, "duration": 4.56}, {"text": "as A_St [NOISE] plus B_At,", "start": 2270.74, "duration": 4.53}, {"text": "uh, another version. [NOISE]", "start": 2275.27, "duration": 10.7}, {"text": "Would be to set St plus 1 equals A_st plus B_at plus Epsilon t,", "start": 2285.97, "duration": 5.025}, {"text": "where Epsilon t is distributed.", "start": 2290.995, "duration": 4.275}, {"text": "[NOISE] Uh, maybe from, uh, from a", "start": 2295.27, "duration": 4.89}, {"text": "Gaussian- from a Gaussian density.", "start": 2300.16, "duration": 5.34}, {"text": "Okay? Um, and so this first model would be a deterministic model,", "start": 2305.5, "duration": 5.715}, {"text": "and this model would be a stochastic model, right?", "start": 2311.215, "duration": 5.76}, {"text": "And, um, if you use a stochastic model,", "start": 2316.975, "duration": 4.32}, {"text": "then that's saying", "start": 2321.295, "duration": 2.58}, {"text": "that- [NOISE] right.", "start": 2323.875, "duration": 8.67}, {"text": "When you're running your simulator,", "start": 2332.545, "duration": 1.665}, {"text": "when you're running the model, um,", "start": 2334.21, "duration": 1.8}, {"text": "every time you generate St plus one,", "start": 2336.01, "duration": 2.76}, {"text": "you would be sampling this Epsilon from a Gaussian vector,", "start": 2338.77, "duration": 3.855}, {"text": "and adding it to the prediction of your linear model, and,", "start": 2342.625, "duration": 3.15}, {"text": "and if you use a stochastic model,", "start": 2345.775, "duration": 1.875}, {"text": "what that means is that, you know,", "start": 2347.65, "duration": 1.605}, {"text": "if you simulate your helicopter flying around,", "start": 2349.255, "duration": 2.07}, {"text": "your simulator will generate random noise that adds and subtracts", "start": 2351.325, "duration": 3.735}, {"text": "a little bit to the state space of", "start": 2355.06, "duration": 1.58}, {"text": "helicopter as if there were little wind gusts blowing it,", "start": 2356.64, "duration": 2.865}, {"text": "blowing the helicopter around, okay?", "start": 2359.505, "duration": 2.325}, {"text": "Um, and this is, uh,", "start": 2361.83, "duration": 1.935}, {"text": "uh, uh, yeah, right.", "start": 2363.765, "duration": 4.4}, {"text": "So, um, right.", "start": 2368.165, "duration": 4.385}, {"text": "So it turn- and,", "start": 2372.55, "duration": 2.13}, {"text": "uh, in, um, in most cases,", "start": 2374.68, "duration": 3.435}, {"text": "when you're building reinforcement learning models- oh,", "start": 2378.115, "duration": 2.865}, {"text": "and so the, the approach we're taking here,", "start": 2380.98, "duration": 2.355}, {"text": "this is called model-based reinforcement", "start": 2383.335, "duration": 2.115}, {"text": "learning where you're going to build a model of your robot,", "start": 2385.45, "duration": 3.15}, {"text": "and then let's train the reinforcement learning algorithm in the simulator,", "start": 2388.6, "duration": 4.695}, {"text": "and then take the policy you learn,", "start": 2393.295, "duration": 1.665}, {"text": "take the policy of how you learned in simulation and", "start": 2394.96, "duration": 2.34}, {"text": "apply it back on your real robot, right?", "start": 2397.3, "duration": 2.37}, {"text": "So this, this, this approach we're taking is called model-based RL.", "start": 2399.67, "duration": 4.02}, {"text": "[NOISE] Um, there is an alternative called model-free RL,", "start": 2403.69, "duration": 8.79}, {"text": "which is you just run your reinforcement learning algorithm on the robot directly,", "start": 2412.48, "duration": 3.78}, {"text": "and let the robot bash the robot around and so on, and let it learn.", "start": 2416.26, "duration": 3.315}, {"text": "I think that in terms of robotics applications, uh, um,", "start": 2419.575, "duration": 4.35}, {"text": "I think model-based RL has been taking off faster.", "start": 2423.925, "duration": 4.395}, {"text": "A lot of the most promising approaches are", "start": 2428.32, "duration": 1.65}, {"text": "model-based RL because if you have a physical robot, you know,", "start": 2429.97, "duration": 3.99}, {"text": "you just can't afford to have", "start": 2433.96, "duration": 1.38}, {"text": "a reinforcement learning algorithm bash your robot around for too long,", "start": 2435.34, "duration": 3.09}, {"text": "or how many helicopters do you want to crash before your learning algorithm figures it out?", "start": 2438.43, "duration": 3.0}, {"text": "Um, model-free RL works fine if you", "start": 2441.43, "duration": 3.69}, {"text": "want to play video games because if you're trying to get a computer or,", "start": 2445.12, "duration": 3.93}, {"text": "or, or, or play chess, or Othello or Go, right?", "start": 2449.05, "duration": 2.55}, {"text": "Because, um, you have a perfect simulator", "start": 2451.6, "duration": 1.95}, {"text": "for the video game which is a video game itself,", "start": 2453.55, "duration": 1.83}, {"text": "and so your, your,", "start": 2455.38, "duration": 1.605}, {"text": "your RL algorithm can, I don't know,", "start": 2456.985, "duration": 2.265}, {"text": "blow up hundreds of millions of times in a video game,", "start": 2459.25, "duration": 2.43}, {"text": "and, and that's fine, uh, for so- for,", "start": 2461.68, "duration": 1.875}, {"text": "for playing video games or for playing,", "start": 2463.555, "duration": 2.565}, {"text": "um, like, uh, you know, traditional games,", "start": 2466.12, "duration": 2.115}, {"text": "model-free approaches can work fine,", "start": 2468.235, "duration": 2.505}, {"text": "but I- most of the, um,", "start": 2470.74, "duration": 2.085}, {"text": "a lot of the, uh, uh, uh,", "start": 2472.825, "duration": 2.355}, {"text": "success applications of reinforcement learning robots have been model-based.", "start": 2475.18, "duration": 4.305}, {"text": "Although again, the field is evolving quickly so there's", "start": 2479.485, "duration": 3.465}, {"text": "this very interesting work at the intersection of model-based and model-free,", "start": 2482.95, "duration": 3.63}, {"text": "that that, that, gets more complicated, right?", "start": 2486.58, "duration": 1.56}, {"text": "But I- I- I want to say, if you want to use something tried and true, you know,", "start": 2488.14, "duration": 3.705}, {"text": "for robotics problems seriously because they're using model-based RL,", "start": 2491.845, "duration": 3.345}, {"text": "because you can then fly a helicopter in simulation,", "start": 2495.19, "duration": 2.834}, {"text": "let it crash a million times, right?", "start": 2498.024, "duration": 1.726}, {"text": "And no one's hurt, there's no physical damage anywhere in the world.", "start": 2499.75, "duration": 2.235}, {"text": "It was just, uh, uh, Okay.", "start": 2501.985, "duration": 3.39}, {"text": "And, uh, um, and- oh,", "start": 2505.375, "duration": 2.235}, {"text": "and just one last tip.", "start": 2507.61, "duration": 1.26}, {"text": "One thing we learned,", "start": 2508.87, "duration": 1.215}, {"text": "um, uh, building these,", "start": 2510.085, "duration": 1.905}, {"text": "uh, reinforcement learning algorithms for a lot of robots is that,", "start": 2511.99, "duration": 3.315}, {"text": "um, you know, having run this model,", "start": 2515.305, "duration": 2.505}, {"text": "you might ask, well,", "start": 2517.81, "duration": 1.155}, {"text": "how do I choose the distribution for this noise, right?", "start": 2518.965, "duration": 4.545}, {"text": "Uh, there- how, how,", "start": 2523.51, "duration": 1.095}, {"text": "how do you model the distribution for the noise?", "start": 2524.605, "duration": 2.325}, {"text": "Um, one thing you could do is estimate it from data.", "start": 2526.93, "duration": 2.955}, {"text": "But as a practical matter,", "start": 2529.885, "duration": 2.4}, {"text": "what happens is so long as you remember to inject- so let's see.", "start": 2532.285, "duration": 4.695}, {"text": "It turns out if you use a deterministic simulator, uh,", "start": 2536.98, "duration": 3.33}, {"text": "a lot of reinforcement learning algorithms will learn a very brittle model, uh,", "start": 2540.31, "duration": 3.6}, {"text": "that works in your simulator but doesn't actually", "start": 2543.91, "duration": 2.61}, {"text": "work when you put it into your real robot, right?", "start": 2546.52, "duration": 2.46}, {"text": "And so if you- if you actually look on YouTube or Twitter, um,", "start": 2548.98, "duration": 3.06}, {"text": "in the last year or two,", "start": 2552.04, "duration": 2.1}, {"text": "there have been a lot of cool-looking videos.", "start": 2554.14, "duration": 2.52}, {"text": "There are people using reinforcement learning to", "start": 2556.66, "duration": 1.83}, {"text": "control various weirdly-configured robots, like a", "start": 2558.49, "duration": 2.925}, {"text": "snake robot or some five-legged thing or some- whatever.", "start": 2561.415, "duration": 3.345}, {"text": "it's just a cool random,", "start": 2564.76, "duration": 1.305}, {"text": "I- I- this is- I- I- I'm not good at drawing this but, you know,", "start": 2566.065, "duration": 2.91}, {"text": "if you build a five-legged robot,", "start": 2568.975, "duration": 1.755}, {"text": "I don't even know what has five legs, right?", "start": 2570.73, "duration": 1.68}, {"text": "How do you control that?", "start": 2572.41, "duration": 1.215}, {"text": "It turns out that if you have a deterministic simulator,", "start": 2573.625, "duration": 3.915}, {"text": "um, using these methods,", "start": 2577.54, "duration": 1.89}, {"text": "it's not that hard to generate", "start": 2579.43, "duration": 1.335}, {"text": "a cool-looking video of your reinforcement learning algorithm,", "start": 2580.765, "duration": 3.075}, {"text": "supposedly controlling a five-legged thing or some crazy,", "start": 2583.84, "duration": 4.16}, {"text": "you know, a worm with, uh,", "start": 2588.0, "duration": 1.56}, {"text": "two legs or something, these crazy robots that you can build in a simulator.", "start": 2589.56, "duration": 3.72}, {"text": "But it turns out that, um,", "start": 2593.28, "duration": 1.94}, {"text": "uh, even those easy,", "start": 2595.22, "duration": 1.82}, {"text": "it's, uh, well, not easy.", "start": 2597.04, "duration": 1.17}, {"text": "Even though you can generate those types of videos in the deterministic simulator,", "start": 2598.21, "duration": 4.08}, {"text": "um, if you use a deterministic model of a robot, uh,", "start": 2602.29, "duration": 3.75}, {"text": "and you ever actually tried to build a physical robot,", "start": 2606.04, "duration": 2.73}, {"text": "and you take that policy from your physics simulator to the real robot, uh, the,", "start": 2608.77, "duration": 4.785}, {"text": "the odds of it working on the real robot are quite low,", "start": 2613.555, "duration": 2.745}, {"text": "if you use a deterministic simulator, right?", "start": 2616.3, "duration": 2.64}, {"text": "Because the problem with simulators is", "start": 2618.94, "duration": 2.64}, {"text": "that your simulator is never 100% accurate, right?", "start": 2621.58, "duration": 3.465}, {"text": "You know, it's always just a little bit off.", "start": 2625.045, "duration": 1.65}, {"text": "And one of the lessons we learned,", "start": 2626.695, "duration": 1.92}, {"text": "uh, that we've- I hope you learned, uh, [NOISE] uh,", "start": 2628.615, "duration": 2.79}, {"text": "applying RL to a lot of robots is that if you want", "start": 2631.405, "duration": 3.42}, {"text": "your model-based RL work to work not just in simulation and generate a cool video,", "start": 2634.825, "duration": 5.385}, {"text": "but you want it to actually work on a physical robot,", "start": 2640.21, "duration": 2.55}, {"text": "like a physical helicopter that you own,", "start": 2642.76, "duration": 1.875}, {"text": "that is really important to add some noise to your simulator.", "start": 2644.635, "duration": 3.87}, {"text": "Because if the policy you learn is,", "start": 2648.505, "duration": 3.36}, {"text": "um, robust to a slightly stochastic simulator,", "start": 2651.865, "duration": 4.62}, {"text": "then the odds of it generalizing,", "start": 2656.485, "duration": 2.19}, {"text": "um, uh, you know, to the, to the real world,", "start": 2658.675, "duration": 2.355}, {"text": "to the physical real world is much higher", "start": 2661.03, "duration": 2.37}, {"text": "than if you had a completely deterministic simulator.", "start": 2663.4, "duration": 2.76}, {"text": "So I think whenever I'm building a robot, right?", "start": 2666.16, "duration": 2.295}, {"text": "I- I- I pretty much- actually,", "start": 2668.455, "duration": 1.83}, {"text": "you know, I don't think I- oh,", "start": 2670.285, "duration": 1.485}, {"text": "with one exception- okay,", "start": 2671.77, "duration": 1.41}, {"text": "I [inaudible] will talk about that next week,", "start": 2673.18, "duration": 1.35}, {"text": "but with one, with one very narrow exception,", "start": 2674.53, "duration": 2.745}, {"text": "I pretty much never use deterministic simulators, uh, when,", "start": 2677.275, "duration": 3.495}, {"text": "when working on robotic control problems, unless- uh, uh,", "start": 2680.77, "duration": 3.3}, {"text": "assuming, assuming I want it to work in the real world as well, right?", "start": 2684.07, "duration": 3.33}, {"text": "Um, and, uh, and again,", "start": 2687.4, "duration": 3.36}, {"text": "you know, tips and tricks.", "start": 2690.76, "duration": 1.32}, {"text": "Uh, so, uh, the most important thing is to add some noise,", "start": 2692.08, "duration": 3.57}, {"text": "and then, uh, sometimes the exact distribution of noise.", "start": 2695.65, "duration": 3.765}, {"text": "Yeah, go ahead and try to pick something realistic,", "start": 2699.415, "duration": 2.16}, {"text": "but the exact distribution of noise actually matters less,", "start": 2701.575, "duration": 3.075}, {"text": "I want to say than just the fact of remembering to add some noise.", "start": 2704.65, "duration": 3.555}, {"text": "Okay.", "start": 2708.205, "duration": 0.405}, {"text": "[NOISE]", "start": 2708.61, "duration": 12.63}, {"text": "By the way,", "start": 2721.24, "duration": 0.435}, {"text": "I- you guys really don't know this,", "start": 2721.675, "duration": 1.425}, {"text": "but my PhD thesis, uh,", "start": 2723.1, "duration": 2.7}, {"text": "was, um, using reinforcement learning to fly helicopters.", "start": 2725.8, "duration": 2.94}, {"text": "So, so I'm trying to,", "start": 2728.74, "duration": 1.8}, {"text": "I don't know, so,", "start": 2730.54, "duration": 1.14}, {"text": "so you're telling me someone has crashed a bunch of", "start": 2731.68, "duration": 1.59}, {"text": "helicopters [LAUGHTER] model helicopters,", "start": 2733.27, "duration": 3.09}, {"text": "and has lived through the pain and the joys of seeing this stuff work or not work.", "start": 2736.36, "duration": 4.32}, {"text": "[LAUGHTER]", "start": 2740.68, "duration": 4.02}, {"text": "[NOISE]", "start": 2744.7, "duration": 10.375}, {"text": "All right. So now that you have built a model,", "start": 2755.075, "duration": 5.13}, {"text": "built a simulator, uh, for your helicopter,", "start": 2760.205, "duration": 2.685}, {"text": "for your four-legged robot or for your car, um,", "start": 2762.89, "duration": 3.315}, {"text": "how do you, um,", "start": 2766.205, "duration": 3.66}, {"text": "how do you approximate the value function, right?", "start": 2769.865, "duration": 3.915}, {"text": "So, um, in order to apply, um,", "start": 2773.78, "duration": 9.63}, {"text": "fitted value iteration, the first step is to choose features", "start": 2783.41, "duration": 5.19}, {"text": "of the state s. Right.", "start": 2788.6, "duration": 9.33}, {"text": "And then, um, we approximate v of s. You know,", "start": 2797.93, "duration": 5.355}, {"text": "we approximate v-star using a function v of s,", "start": 2803.285, "duration": 3.135}, {"text": "which is going to be Theta transpose Phi of s. Um,", "start": 2806.42, "duration": 4.53}, {"text": "and so, I don't know.", "start": 2810.95, "duration": 2.715}, {"text": "And so, uh, you know,", "start": 2813.665, "duration": 4.665}, {"text": "in the case of, uh,", "start": 2818.33, "duration": 1.2}, {"text": "uh, in, in, the case of the,", "start": 2819.53, "duration": 2.97}, {"text": "um, uh, inverted pendulum, right?", "start": 2822.5, "duration": 3.465}, {"text": "Then Phi of s,", "start": 2825.965, "duration": 1.34}, {"text": "maybe you have x, x-dot,", "start": 2827.305, "duration": 2.085}, {"text": "maybe you've x squared or x times x-dot or x,", "start": 2829.39, "duration": 3.975}, {"text": "uh, times the polar orientation, and so on.", "start": 2833.365, "duration": 3.315}, {"text": "So take, take your state to s,", "start": 2836.68, "duration": 2.27}, {"text": "and think up some nonlinear features that,", "start": 2838.95, "duration": 2.69}, {"text": "that you think might be useful for representing the value.", "start": 2841.64, "duration": 3.765}, {"text": "Um, and remember that what the value is,", "start": 2845.405, "duration": 2.325}, {"text": "the value of a state is your expected payoff from that state,", "start": 2847.73, "duration": 3.795}, {"text": "expected sum of discounted rewards.", "start": 2851.525, "duration": 1.455}, {"text": "So the value function captures,", "start": 2852.98, "duration": 2.325}, {"text": "if your robot starts off in that state,", "start": 2855.305, "duration": 2.7}, {"text": "you know, how well is it gonna do if it starts here?", "start": 2858.005, "duration": 2.685}, {"text": "So when you're designing features pick a bunch of features that you think hope convey,", "start": 2860.69, "duration": 5.279}, {"text": "um, how well is your robot doing. That makes sense?", "start": 2865.969, "duration": 3.046}, {"text": "And so, uh, maybe for the inverted pendulum, for example,", "start": 2869.015, "duration": 3.48}, {"text": "if the pole is way over to the right,", "start": 2872.495, "duration": 3.18}, {"text": "then maybe the pole will fall over given a reward of minus 1 when the pole falls over.", "start": 2875.675, "duration": 4.89}, {"text": "Right? Uh, but so, sorry.", "start": 2880.565, "duration": 2.655}, {"text": "I'm overloading the notation a bit.", "start": 2883.22, "duration": 1.38}, {"text": "Theta is both the angle of the pole as well as the parameters.", "start": 2884.6, "duration": 2.97}, {"text": "But, but, but if the pole is falling way over that looks extreme pretty badly,", "start": 2887.57, "duration": 4.305}, {"text": "unless, um, x-dot is very large and positive, right?", "start": 2891.875, "duration": 5.01}, {"text": "And so maybe there's interaction between Phi and x-dot.", "start": 2896.885, "duration": 2.895}, {"text": "So you might say, \"Well, let me have a new feature,", "start": 2899.78, "duration": 2.385}, {"text": "which is the angle of the pole multiplied by the velocity.\"", "start": 2902.165, "duration": 3.57}, {"text": "Right? Because then-, uh,", "start": 2905.735, "duration": 2.305}, {"text": "because it seems like these two variables kind of depend on each other.", "start": 2908.04, "duration": 3.115}, {"text": "Um, so, so, so just as when you are trying to predict the price of a house,", "start": 2911.155, "duration": 5.085}, {"text": "you would say, \"Well, what are the most useful features predicting the price of a house?\"", "start": 2916.24, "duration": 3.745}, {"text": "Uh, um, you would do something similar,", "start": 2919.985, "duration": 2.52}, {"text": "um, for fitted evaluation.", "start": 2922.505, "duration": 3.3}, {"text": "And one nice thing about-, um, uh,", "start": 2925.805, "duration": 4.23}, {"text": "one nice thing about model-based RL is that once- model-based reinforcement learning,", "start": 2930.035, "duration": 6.225}, {"text": "is that once you have built a model,", "start": 2936.26, "duration": 2.64}, {"text": "you see a little bit that you can collect", "start": 2938.9, "duration": 2.31}, {"text": "an essentially infinite amount of data from your model.", "start": 2941.21, "duration": 3.285}, {"text": "Right? And so with a lot of data,", "start": 2944.495, "duration": 2.445}, {"text": "you can usually afford to choose a larger number of features,", "start": 2946.94, "duration": 3.54}, {"text": "because you can generate a ton of data with which to fit this linear function.", "start": 2950.48, "duration": 4.89}, {"text": "And so, you know, you- you're,", "start": 2955.37, "duration": 1.71}, {"text": "you're usually not super constrained in terms of, uh,", "start": 2957.08, "duration": 2.64}, {"text": "needing to be really careful not to choose", "start": 2959.72, "duration": 2.25}, {"text": "too many features because of fear of overfitting.", "start": 2961.97, "duration": 2.64}, {"text": "You could get so much data from your simulator that, you know,", "start": 2964.61, "duration": 3.885}, {"text": "you can usually make up quite a lot of features,", "start": 2968.495, "duration": 2.549}, {"text": "uh, and then some of the features end up not being useful, it's okay.", "start": 2971.044, "duration": 2.956}, {"text": "Because you can get enough data for running", "start": 2974.0, "duration": 2.28}, {"text": "your simulator for the algorithm to still fit a pretty good set of parameters Theta,", "start": 2976.28, "duration": 4.65}, {"text": "even if you have a lot of features.", "start": 2980.93, "duration": 1.71}, {"text": "Because you can have a lot- you can generate a lot of data to fit this function.", "start": 2982.64, "duration": 3.93}, {"text": "Okay. So, um, let's talk through the fitted value iteration algorithm.", "start": 2986.57, "duration": 8.29}, {"text": "Let's see. All right. You know what?", "start": 2996.31, "duration": 2.545}, {"text": "This is a long algorithm.", "start": 2998.855, "duration": 1.2}, {"text": "Let me just use a fresh board for this.", "start": 3000.055, "duration": 1.785}, {"text": "[NOISE].", "start": 3001.84, "duration": 12.21}, {"text": "All right. So, uh,", "start": 3014.05, "duration": 1.26}, {"text": "let me just write down the original value iteration algorithm for these v states.", "start": 3015.31, "duration": 5.78}, {"text": "Uh, so what we had previously was we would update V of s according to R of s,", "start": 3021.09, "duration": 6.375}, {"text": "plus Gamma, max over a, right?", "start": 3027.465, "duration": 9.7}, {"text": "So this is what we had, um, last Monday.", "start": 3037.165, "duration": 3.075}, {"text": "And, uh, I said at the start of today's lecture that you can also write this as this.", "start": 3040.24, "duration": 7.68}, {"text": "[NOISE].", "start": 3047.92, "duration": 10.08}, {"text": "Okay. So let's take that and generalize it to a fitted value iteration.", "start": 3058.0, "duration": 5.78}, {"text": "[NOISE].", "start": 3063.78, "duration": 27.96}, {"text": "All right. Um, so first,", "start": 3091.74, "duration": 7.12}, {"text": "let's choose a set of states", "start": 3098.86, "duration": 2.89}, {"text": "randomly, and let's initialize the parameters to equal 0, okay?", "start": 3109.86, "duration": 10.735}, {"text": "Um, and what we're going to do is where-,uh,", "start": 3120.595, "duration": 4.44}, {"text": "so, so let's see.", "start": 3125.035, "duration": 1.29}, {"text": "In linear regression, you learn a mapping from x-y,", "start": 3126.325, "duration": 5.955}, {"text": "and you have a discrete set of examples for x,", "start": 3132.28, "duration": 2.58}, {"text": "and you fit a function mapping from x and y.", "start": 3134.86, "duration": 2.85}, {"text": "So and what we're going to do here,", "start": 3137.71, "duration": 1.92}, {"text": "we're going to learn the mapping from s to v of", "start": 3139.63, "duration": 3.81}, {"text": "s. And we are going to take a discrete set of examples for s,", "start": 3143.44, "duration": 5.7}, {"text": "and try to figure out what is v of s for them,", "start": 3149.14, "duration": 2.655}, {"text": "and then for the straight line, you know,", "start": 3151.795, "duration": 1.785}, {"text": "to try to model this relationship, right.", "start": 3153.58, "duration": 2.145}, {"text": "So, so just as you have a finite set of examples,", "start": 3155.725, "duration": 3.135}, {"text": "a finite set of houses that you see a certain set of", "start": 3158.86, "duration": 2.67}, {"text": "values of x in your training set for predicting housing prices.", "start": 3161.53, "duration": 3.195}, {"text": "We're gonna see, you know,", "start": 3164.725, "duration": 1.425}, {"text": "a certain set of states,", "start": 3166.15, "duration": 1.155}, {"text": "and then use that finite set of examples to use linear regression to fit v of s. Right?", "start": 3167.305, "duration": 5.37}, {"text": "So that's what this initial sample is meant to do.", "start": 3172.675, "duration": 3.765}, {"text": "And so, um, this is the outermost loop of value iteration- of fitted value iteration.", "start": 3176.44, "duration": 10.59}, {"text": "And then for i equals 1 [NOISE] through m.", "start": 3187.03, "duration": 8.12}, {"text": "[NOISE]", "start": 3195.15, "duration": 29.5}, {"text": "Let's see, [NOISE] uh.", "start": 3224.65, "duration": 2.83}, {"text": "All right. So, um,", "start": 3251.79, "duration": 4.975}, {"text": "what we're going to do is, um,", "start": 3256.765, "duration": 4.885}, {"text": "go over each of these m states, uh,", "start": 3261.96, "duration": 3.52}, {"text": "go over each of these m states, right,", "start": 3265.48, "duration": 2.41}, {"text": "and for each one of them, um,", "start": 3268.23, "duration": 3.4}, {"text": "we're going to- and for each one of those states of each one of those actions,", "start": 3271.63, "duration": 4.17}, {"text": "we're going to take a sample of k things in order to estimate that expected value.", "start": 3275.8, "duration": 6.225}, {"text": "Right. And so this expectation", "start": 3282.025, "duration": 3.165}, {"text": "is over S prime drawn from this state transition distribution.", "start": 3285.19, "duration": 3.75}, {"text": "They say, you know, from this state,", "start": 3288.94, "duration": 1.38}, {"text": "if you take this action where you get to the next.", "start": 3290.32, "duration": 2.325}, {"text": "And so, uh, these two loops this for i", "start": 3292.645, "duration": 4.995}, {"text": "equals 1 through m. And for each action a", "start": 3297.64, "duration": 2.52}, {"text": "this is just looping over every state and every action,", "start": 3300.16, "duration": 2.895}, {"text": "and taking k samples.", "start": 3303.055, "duration": 2.145}, {"text": "Sampling k samples of where you get to if you take an action a in a certain status.", "start": 3305.2, "duration": 5.985}, {"text": "Right. And so [NOISE] um, uh,", "start": 3311.185, "duration": 3.33}, {"text": "and by taking that k examples and computing this average q a,", "start": 3314.515, "duration": 9.115}, {"text": "right, is your estimate of that expectation.", "start": 3324.93, "duration": 3.52}, {"text": "Okay. So, so all we've done so far is,", "start": 3328.45, "duration": 2.22}, {"text": "uh, take k samples, you know,", "start": 3330.67, "duration": 2.805}, {"text": "from this distribution of with S prime is drawn and average V of s. Oh,", "start": 3333.475, "duration": 7.095}, {"text": "actually, uh, oh, I'm sorry.", "start": 3340.57, "duration": 2.235}, {"text": "And, uh, if I move R of s inside,", "start": 3342.805, "duration": 4.395}, {"text": "sorry, then that's q of a. Yeah.", "start": 3347.2, "duration": 2.64}, {"text": "Okay, that makes sense?", "start": 3349.84, "duration": 1.68}, {"text": "[NOISE] Sorry.", "start": 3351.52, "duration": 3.54}, {"text": "Let me just rewrite this to move R of s inside [NOISE].", "start": 3355.06, "duration": 8.82}, {"text": "Fix this up a little bit. So this is written as Gamma.", "start": 3363.88, "duration": 5.14}, {"text": "If you write this as max over a,", "start": 3370.8, "duration": 3.265}, {"text": "of R of s plus Gamma, uh, [NOISE]", "start": 3374.065, "duration": 18.735}, {"text": "Yeah. Okay. Yes, sorry.", "start": 3392.8, "duration": 1.23}, {"text": "So we move the max and expectation out,", "start": 3394.03, "duration": 2.265}, {"text": "then this is, this is q of a.", "start": 3396.295, "duration": 4.125}, {"text": "Okay?", "start": 3400.42, "duration": 1.87}, {"text": "Um, next,", "start": 3406.56, "duration": 9.28}, {"text": "let's set y i equals max over", "start": 3415.84, "duration": 6.66}, {"text": "a of q of a [NOISE].", "start": 3422.5, "duration": 7.11}, {"text": "And so by taking the max over a of q of a,", "start": 3429.61, "duration": 7.5}, {"text": "um, that's what y i is.", "start": 3437.11, "duration": 4.635}, {"text": "Is your estimate at the right-hand side of value iteration.", "start": 3441.745, "duration": 5.55}, {"text": "Okay. [NOISE] And so", "start": 3447.295, "duration": 9.345}, {"text": "y i is your estimate for,", "start": 3456.64, "duration": 2.805}, {"text": "um, for this quantity,", "start": 3459.445, "duration": 2.354}, {"text": "for the right hand side of value iteration.", "start": 3461.799, "duration": 2.836}, {"text": "Now, in the original value iteration algorithm,", "start": 3464.635, "duration": 15.12}, {"text": "um, I'm, I'm just using VI to approximate that to abbreviate value iteration.", "start": 3479.755, "duration": 5.205}, {"text": "In the original algorithm,", "start": 3484.96, "duration": 1.92}, {"text": "what we did was we set V of S i to be equal to y i, right?", "start": 3486.88, "duration": 8.07}, {"text": "In the original value iteration algorithm,", "start": 3494.95, "duration": 2.52}, {"text": "we would compute the right hand side, this purple thing,", "start": 3497.47, "duration": 3.165}, {"text": "and then set V of s equals to that, right,", "start": 3500.635, "duration": 2.205}, {"text": "just set right-hand side equal to- I", "start": 3502.84, "duration": 1.485}, {"text": "set the left hand side equal to the right-hand side.", "start": 3504.325, "duration": 1.995}, {"text": "But in, um, fitted value iteration, you know,", "start": 3506.32, "duration": 4.845}, {"text": "V of s is now approximated by a linear function.", "start": 3511.165, "duration": 5.505}, {"text": "So you can't just go into a linear function,", "start": 3516.67, "duration": 2.235}, {"text": "and set the value of the points individually.", "start": 3518.905, "duration": 2.805}, {"text": "So what we're going to do instead is in fitted Vi,", "start": 3521.71, "duration": 6.22}, {"text": "we're going to use linear regression to make V of Si as close as possible to yi.", "start": 3530.0, "duration": 10.75}, {"text": "But V of Si is now represented as a linear function of the state.", "start": 3540.75, "duration": 9.79}, {"text": "So a linear function of the features of state.", "start": 3550.54, "duration": 1.845}, {"text": "So V of Si is Theta transpose Phi of Si,", "start": 3552.385, "duration": 3.285}, {"text": "and you want that to be close to yi.", "start": 3555.67, "duration": 2.67}, {"text": "And so the final step is run", "start": 3558.34, "duration": 3.87}, {"text": "linear regression to choose", "start": 3562.21, "duration": 4.86}, {"text": "the parameters Theta that minimizes the squared error, okay? [NOISE]", "start": 3567.07, "duration": 24.15}, {"text": "Does that make sense?", "start": 3591.22, "duration": 0.54}, {"text": "Okay, um, oh, yes. Let me just make my curly braces match.", "start": 3591.76, "duration": 34.24}, {"text": "Yeah. Okay, okay.", "start": 3626.52, "duration": 6.98}, {"text": "So that's fitted. Uh, go ahead, question?", "start": 3634.62, "duration": 2.98}, {"text": "[inaudible].", "start": 3637.6, "duration": 10.8}, {"text": "Oh, this one? Oh, this one?", "start": 3648.4, "duration": 3.315}, {"text": "Oh, no, the, the m is used differently.", "start": 3651.715, "duration": 3.06}, {"text": "Uh, so when we were learning a model m was", "start": 3654.775, "duration": 3.435}, {"text": "just how many times you fly the helicopter in order to build a model.", "start": 3658.21, "duration": 3.42}, {"text": "And the number of times you fly the helicopter in order to build a physics model,", "start": 3661.63, "duration": 4.635}, {"text": "to build a model, the helicopter dynamics has,", "start": 3666.265, "duration": 2.805}, {"text": "has nothing to do with this m,", "start": 3669.07, "duration": 2.145}, {"text": "which is the number of states you use in order to,", "start": 3671.215, "duration": 3.435}, {"text": "sort of, anchor, or in order to, uh, uh,", "start": 3674.65, "duration": 3.21}, {"text": "so I think I'm actually- so the,", "start": 3677.86, "duration": 2.445}, {"text": "the, the way to think about this is,", "start": 3680.305, "duration": 1.935}, {"text": "is you want to learn a mapping from states to B of S.", "start": 3682.24, "duration": 5.46}, {"text": "And so, uh, this sample,", "start": 3687.7, "duration": 3.165}, {"text": "this m states is- we're gonna choose m states on the x axis, right?", "start": 3690.865, "duration": 7.38}, {"text": "So, uh, and that m is the number of points you choose on the x axis.", "start": 3698.245, "duration": 4.545}, {"text": "And then in each, uh, iteration,", "start": 3702.79, "duration": 2.91}, {"text": "the value iteration we're gonna go through this procedure.", "start": 3705.7, "duration": 3.09}, {"text": "So you have sub S1 up to Sm.", "start": 3708.79, "duration": 2.97}, {"text": "Right. And then for each of these,", "start": 3711.76, "duration": 2.1}, {"text": "you're going to compute some value yi using this procedure.", "start": 3713.86, "duration": 8.13}, {"text": "And then you fit a straight line to the sample of yi's.", "start": 3721.99, "duration": 4.38}, {"text": "[inaudible].", "start": 3726.37, "duration": 10.63}, {"text": "Uh, think of this- think of the way you build a model and the way you", "start": 3737.0, "duration": 5.94}, {"text": "apply fitted value evaluation as two completely separate operations.", "start": 3742.94, "duration": 4.62}, {"text": "So, um, you can have one team of ten engineers flying a helicopter", "start": 3747.56, "duration": 4.05}, {"text": "around 1,000 times, build a model,", "start": 3751.61, "duration": 4.05}, {"text": "run the linear regression and then they have a model and", "start": 3755.66, "duration": 2.94}, {"text": "then they could publish the model on the Internet and", "start": 3758.6, "duration": 3.06}, {"text": "a totally different team could download their model and", "start": 3761.66, "duration": 2.94}, {"text": "do this and the second team does not need to talk to the first team at all,", "start": 3764.6, "duration": 3.315}, {"text": "other than downloading the model off the Internet.", "start": 3767.915, "duration": 2.205}, {"text": "There is a question.", "start": 3770.12, "duration": 1.8}, {"text": "[inaudible]", "start": 3771.92, "duration": 5.72}, {"text": "Oh, yes. Good question.", "start": 3777.64, "duration": 1.62}, {"text": "You mean they're sampling, they're sampling  k times, right?", "start": 3779.26, "duration": 3.345}, {"text": "Yeah. That's a great question, yes.", "start": 3782.605, "duration": 2.46}, {"text": "That was a- yes.", "start": 3785.065, "duration": 1.41}, {"text": "That was one my next points which is the reason you sample from this distribution", "start": 3786.475, "duration": 5.35}, {"text": "is because you're using- so you should do", "start": 3791.825, "duration": 2.925}, {"text": "this if you are using a stochastic simulator, right?", "start": 3794.75, "duration": 3.615}, {"text": "And then actually it does.", "start": 3798.365, "duration": 1.545}, {"text": "Actually, I just wanted to ask you guys what should you do?", "start": 3799.91, "duration": 2.535}, {"text": "How can you simplify this algorithm if you use", "start": 3802.445, "duration": 2.235}, {"text": "a deterministic simulator instead of a stochastic simulator?", "start": 3804.68, "duration": 3.7}, {"text": "Oh, well, let's see. So if you use a determinic- deterministic simulator then, you know,", "start": 3813.52, "duration": 7.24}, {"text": "given a certain state at", "start": 3820.76, "duration": 3.42}, {"text": "a certain action it will always map to the exact same S-prime right?", "start": 3824.18, "duration": 4.365}, {"text": "So how can you simplify the algorithm?", "start": 3828.545, "duration": 2.805}, {"text": "[inaudible] action instead of drawing k times,", "start": 3831.35, "duration": 4.2}, {"text": "you only need to draw once.", "start": 3835.55, "duration": 2.19}, {"text": "Yeah, yeah, cool. Great. Yes. So if you're a deterministic simulator,", "start": 3837.74, "duration": 4.125}, {"text": "you can set k equals 1 and set the sample only once because this distribution,", "start": 3841.865, "duration": 6.06}, {"text": "it always returns the same value.", "start": 3847.925, "duration": 2.055}, {"text": "So all of these k samples would be exactly", "start": 3849.98, "duration": 2.88}, {"text": "the same so you might as well just do this once rather than K times.", "start": 3852.86, "duration": 3.57}, {"text": "Make sense? Okay cool. Yeah.", "start": 3856.43, "duration": 4.23}, {"text": "[inaudible]", "start": 3860.66, "duration": 9.029}, {"text": "Oh, this one?", "start": 3869.689, "duration": 0.631}, {"text": "[inaudible]", "start": 3870.32, "duration": 2.61}, {"text": "Oh, no. This is, um,", "start": 3872.93, "duration": 1.755}, {"text": "this is actually a square bracket.", "start": 3874.685, "duration": 2.31}, {"text": "Um, the thing is, um,", "start": 3876.995, "duration": 1.875}, {"text": "we're trying to approximate this expectation and the way you", "start": 3878.87, "duration": 4.59}, {"text": "approximate the mean is you'd sample k times if you take the average, right?", "start": 3883.46, "duration": 4.965}, {"text": "Right. So- so what we've done here is in order to approximate this expectation,", "start": 3888.425, "duration": 4.545}, {"text": "we're gonna draw k samples and then sum over", "start": 3892.97, "duration": 3.12}, {"text": "them and divide by k. So you average over the k samples.", "start": 3896.09, "duration": 4.08}, {"text": "All right, cool. Got some more question?", "start": 3900.17, "duration": 2.1}, {"text": "What's the little [inaudible] how many states", "start": 3902.27, "duration": 15.48}, {"text": "you'll get from K sample and [inaudible]", "start": 3917.75, "duration": 3.96}, {"text": "Let's see. So how do you choose M and how do you test for overfitting and so,", "start": 3921.71, "duration": 5.205}, {"text": "you know, one- once you have a model,", "start": 3926.915, "duration": 1.905}, {"text": "one of the nice things about model-based RL is let's say that Phi of S,", "start": 3928.82, "duration": 4.74}, {"text": "right, let's say that Phi of S has 50 features.", "start": 3933.56, "duration": 4.24}, {"text": "So let's say you chose 50 features to approximate", "start": 3938.92, "duration": 2.95}, {"text": "the value function of your inverted pendulum system.", "start": 3941.87, "duration": 3.975}, {"text": "Then we know that- you know that you're going to be fitting linear regression,", "start": 3945.845, "duration": 4.784}, {"text": "right, to this 50-dimensional state-space.", "start": 3950.629, "duration": 2.311}, {"text": "I mean this step here,", "start": 3952.94, "duration": 1.275}, {"text": "this is really linear regression, right?", "start": 3954.215, "duration": 4.245}, {"text": "And so you can ask,", "start": 3958.46, "duration": 1.83}, {"text": "if you want to run linear regression with 50 parameters,", "start": 3960.29, "duration": 3.645}, {"text": "how many examples do you need to fit linear regression?", "start": 3963.935, "duration": 3.24}, {"text": "And I will say you know if M was maybe 500,", "start": 3967.175, "duration": 4.23}, {"text": "right, maybe you'd be okay.", "start": 3971.405, "duration": 1.365}, {"text": "You have 500 examples to 50-50 parameters.", "start": 3972.77, "duration": 2.895}, {"text": "But if for computational reasons,", "start": 3975.665, "duration": 2.55}, {"text": "if- if it doesn't run too slowly ,", "start": 3978.215, "duration": 2.025}, {"text": "to even set M equals 1,000 or even 5,000,", "start": 3980.24, "duration": 3.705}, {"text": "then there's no harm to letting M be bigger.", "start": 3983.945, "duration": 3.195}, {"text": "So usually M, you might as well set to be as big as you feel", "start": 3987.14, "duration": 4.2}, {"text": "like, subject to the program not taking too long to run because it- it,", "start": 3991.34, "duration": 4.53}, {"text": "you know if- if you're,", "start": 3995.87, "duration": 1.305}, {"text": "um, if you're fitting- unlike supervised learning,", "start": 3997.175, "duration": 3.135}, {"text": "if you're fitting data to housing prices,", "start": 4000.31, "duration": 2.43}, {"text": "um, you need to go out and, you know,", "start": 4002.74, "duration": 2.46}, {"text": "collect data right off Craigslist or- or what's", "start": 4005.2, "duration": 4.68}, {"text": "on Zillow or Trulia or Redfin or whatever about prices of houses.", "start": 4009.88, "duration": 5.055}, {"text": "And so data is expensive to collect in the real world.", "start": 4014.935, "duration": 3.42}, {"text": "But once you have a model,", "start": 4018.355, "duration": 1.47}, {"text": "you can set M equals 5,000 or 10,000 or", "start": 4019.825, "duration": 2.745}, {"text": "100,000 and just- and then your algorithm will run more slowly.", "start": 4022.57, "duration": 4.17}, {"text": "But as long as your algorithm doesn't run too slowly,", "start": 4026.74, "duration": 3.06}, {"text": "there is no harm to setting M to be bigger. Makes sense?", "start": 4029.8, "duration": 3.69}, {"text": "Um, all right cool.", "start": 4033.49, "duration": 6.585}, {"text": "So, um, so I know that there's a lot", "start": 4040.075, "duration": 4.245}, {"text": "going on to this algorithm but this is fitted value iteration.", "start": 4044.32, "duration": 3.405}, {"text": "And if you do this, uh, this,", "start": 4047.725, "duration": 2.655}, {"text": "you can get reasonable behavior on a lot of", "start": 4050.38, "duration": 3.09}, {"text": "robots by choosing a set of features and learning", "start": 4053.47, "duration": 3.66}, {"text": "the value function to approximate the value of the- really", "start": 4057.13, "duration": 3.555}, {"text": "approximate the expected payoff of a robot starting off in different states.", "start": 4060.685, "duration": 4.86}, {"text": "Okay. Um, now just a few details", "start": 4065.545, "duration": 8.205}, {"text": "to wrap up, again, some practical aspects of how you do this.", "start": 4073.75, "duration": 7.42}, {"text": "After you've learned all these parameters,", "start": 4092.01, "duration": 3.415}, {"text": "this- you've now learned- go ahead, yeah.", "start": 4095.425, "duration": 2.775}, {"text": "[inaudible]", "start": 4098.2, "duration": 14.4}, {"text": "Oh, I see. Yes, thank you.", "start": 4112.6, "duration": 1.14}, {"text": "Um, yes.", "start": 4113.74, "duration": 1.32}, {"text": "So in this, um,", "start": 4115.06, "duration": 2.535}, {"text": "expression, where do you get V of S prime j from?", "start": 4117.595, "duration": 4.335}, {"text": "Yes. So you would get this from Theta transpose Phi of S prime j,", "start": 4121.93, "duration": 6.18}, {"text": "using the parameters of Theta from the last iteration of fitted value iteration.", "start": 4128.11, "duration": 5.295}, {"text": "Ju- just as in value iteration,", "start": 4133.405, "duration": 3.329}, {"text": "this is the values from the last iteration that you use to update a new iteration.", "start": 4136.734, "duration": 4.396}, {"text": "So then you use the last value of Theta to update the new one. Yeah, thank you.", "start": 4141.13, "duration": 4.63}, {"text": "Cool. Oh, and, um,", "start": 4147.03, "duration": 6.685}, {"text": "one- one other thing you could do which is, um,", "start": 4153.715, "duration": 4.575}, {"text": "I talked about the linear regression version of this algorithm which is, you know,", "start": 4158.29, "duration": 5.52}, {"text": "this whole- this whole exercise is about generating a sample of S", "start": 4163.81, "duration": 5.79}, {"text": "and Y so you can apply linear regression to", "start": 4169.6, "duration": 2.61}, {"text": "predict the value of Y from the values of S, right?", "start": 4172.21, "duration": 3.225}, {"text": "But there's nothing in this algorithm that says you have to use linear regression.", "start": 4175.435, "duration": 4.35}, {"text": "In order to- now that you've generated this dataset,", "start": 4179.785, "duration": 3.015}, {"text": "that's this box that I have here,", "start": 4182.8, "duration": 1.455}, {"text": "this- this is linear regression,", "start": 4184.255, "duration": 1.635}, {"text": "right, but you don't have to use linear regression.", "start": 4185.89, "duration": 2.685}, {"text": "In modern yo- deep reinforcement learning, um,", "start": 4188.575, "duration": 3.24}, {"text": "one of the ways- well one of the ways to go from reinforcement learning", "start": 4191.815, "duration": 3.045}, {"text": "to deep reinforcement learning is to just use a neural network with this step instead.", "start": 4194.86, "duration": 3.315}, {"text": "Then you can- then- then you call that deep reinforcement learning where- no.", "start": 4198.175, "duration": 3.78}, {"text": "But, hey, it's legit, you know.", "start": 4201.955, "duration": 1.365}, {"text": "[LAUGHTER]", "start": 4203.32, "duration": 2.91}, {"text": "Um, uh, but, but,", "start": 4206.23, "duration": 1.29}, {"text": "you can also use locally weighted linear regression", "start": 4207.52, "duration": 2.31}, {"text": "or whatever regression algorithm you want in order", "start": 4209.83, "duration": 2.52}, {"text": "to estimate y as a function of the state s. Yeah,", "start": 4212.35, "duration": 5.895}, {"text": "and actually if you use a neural network,", "start": 4218.245, "duration": 1.74}, {"text": "it relieves the need to choose features Phi as well,", "start": 4219.985, "duration": 2.835}, {"text": "you can feed in the raw features.", "start": 4222.82, "duration": 1.725}, {"text": "You know, your angle, your orientation and,", "start": 4224.545, "duration": 2.115}, {"text": "and using neural networks,", "start": 4226.66, "duration": 1.14}, {"text": "to learn that mapping in a supervised learning way.", "start": 4227.8, "duration": 2.625}, {"text": "Okay, um, all right.", "start": 4230.425, "duration": 7.425}, {"text": "So one last, ah, ah, important,", "start": 4237.85, "duration": 3.66}, {"text": "ah, I guess practical implementational detail, which is, um,", "start": 4241.51, "duration": 4.86}, {"text": "fitted VI right, uh, gives, uh,", "start": 4246.37, "duration": 5.1}, {"text": "approximation to V star.", "start": 4251.47, "duration": 7.965}, {"text": "And this, um, implicitly defines Pi star.", "start": 4259.435, "duration": 9.945}, {"text": "Right, because the definition for Pi star is that, um,", "start": 4269.38, "duration": 6.7}, {"text": "right. So, um, when you're running a robot,", "start": 4291.9, "duration": 8.125}, {"text": "you know, you need to execute the policy Pi right,", "start": 4300.025, "duration": 3.195}, {"text": "given the state you're gonna pick an action,", "start": 4303.22, "duration": 1.41}, {"text": "given the state you're gonna pick an action.", "start": 4304.63, "duration": 1.56}, {"text": "And, and having computed V star,", "start": 4306.19, "duration": 2.595}, {"text": "it only implicitly defines the optimal policy Pi star.", "start": 4308.785, "duration": 4.515}, {"text": "All right, um, and", "start": 4313.3, "duration": 3.27}, {"text": "so ah if you're running a robo- if you're running a robot in real time,", "start": 4316.57, "duration": 4.935}, {"text": "then you know actually if you fly a helicopter,", "start": 4321.505, "duration": 2.774}, {"text": "you might have to choose control actions at 10 hertz", "start": 4324.279, "duration": 2.671}, {"text": "meaning 10 times a second you're given the state, you have to choose an action.", "start": 4326.95, "duration": 3.405}, {"text": "Uh, uh, if you're building a self-driving car,", "start": 4330.355, "duration": 1.845}, {"text": "again a 10 hertz controller wo- would be pretty reasonable.", "start": 4332.2, "duration": 2.49}, {"text": "I guess choose a new action and maybe 10 times a second would be pretty reasonable.", "start": 4334.69, "duration": 3.84}, {"text": "Um, but how do you compute this expectation and this maximization 10 times per second?", "start": 4338.53, "duration": 5.82}, {"text": "So, um, in what we use for fitted value iteration,", "start": 4344.35, "duration": 5.31}, {"text": "we used right, a sample,", "start": 4349.66, "duration": 5.25}, {"text": "uh, of- we use k examples to approximate the expectation.", "start": 4361.58, "duration": 5.27}, {"text": "Right, but if you're running this, um,", "start": 4366.85, "duration": 3.48}, {"text": "in real time on a helicopter, you know,", "start": 4370.33, "duration": 2.655}, {"text": "probably you don't want to, uh, uh, uh,", "start": 4372.985, "duration": 4.17}, {"text": "at least I know for my robotics implementations I have been reluctant to use", "start": 4377.155, "duration": 4.395}, {"text": "a random number generator right in the inner loop of how we control a helicopter.", "start": 4381.55, "duration": 4.89}, {"text": "Right it, it, it might work but I,", "start": 4386.44, "duration": 1.71}, {"text": "but I think, you know,", "start": 4388.15, "duration": 1.47}, {"text": "it's approximately- if you want to compute", "start": 4389.62, "duration": 2.04}, {"text": "this arg max, you need to approximate this expectation and", "start": 4391.66, "duration": 3.075}, {"text": "do you really want to be running a random number generator on a helicopter?", "start": 4394.735, "duration": 3.165}, {"text": "And if you're really unlucky the random number gen-", "start": 4397.9, "duration": 1.95}, {"text": "generator generates an unlucky value,", "start": 4399.85, "duration": 2.49}, {"text": "will your helicopter do something you know, bad and crash?", "start": 4402.34, "duration": 3.45}, {"text": "Oh, I, I, I would,", "start": 4405.79, "duration": 1.47}, {"text": "again just emotionally I don't feel very good if,", "start": 4407.26, "duration": 2.82}, {"text": "uh, your self-driving car has a random number generator and,", "start": 4410.08, "duration": 3.495}, {"text": "and a loop of how it's choosing to drive.", "start": 4413.575, "duration": 1.695}, {"text": "Right, um, so just as a practical matter, ah,", "start": 4415.27, "duration": 3.825}, {"text": "ah, ah, there are a couple of tricks that people often use.", "start": 4419.095, "duration": 7.645}, {"text": "Which is, um, the simulator", "start": 4427.44, "duration": 6.29}, {"text": "is often of this form, right.", "start": 4438.48, "duration": 16.33}, {"text": "Okay, so most simulators have this form,", "start": 4454.81, "duration": 3.48}, {"text": "next state is equal to some function of the pre- uh,", "start": 4458.29, "duration": 3.795}, {"text": "previous state and action plus some noise.", "start": 4462.085, "duration": 3.51}, {"text": "And so one thing that is often done is, um,", "start": 4465.595, "duration": 5.235}, {"text": "for your deployment or for the,", "start": 4470.83, "duration": 6.075}, {"text": "you know for the, for, for,", "start": 4476.905, "duration": 1.695}, {"text": "for the actual policy you implement on the robot.", "start": 4478.6, "duration": 3.165}, {"text": "Um, set epsilon t equals 0 and set k equals 1.", "start": 4481.765, "duration": 9.86}, {"text": "Right and so, um,", "start": 4491.625, "duration": 2.19}, {"text": "so, so, so this,", "start": 4493.815, "duration": 1.62}, {"text": "this is a reasonable way to make this policy run on a helicopter,", "start": 4495.435, "duration": 4.255}, {"text": "which is during training you do want to add noise to", "start": 4499.69, "duration": 4.14}, {"text": "the simulator because it causes a policy you learn to be much more robust.", "start": 4503.83, "duration": 5.01}, {"text": "So little errors in the simulator,", "start": 4508.84, "duration": 1.815}, {"text": "your simulator is always a little bit off.", "start": 4510.655, "duration": 1.635}, {"text": "You know maybe it didn't quite simulate wind gusts", "start": 4512.29, "duration": 2.52}, {"text": "or when you turn the helicopter does it bank exactly the right amount.", "start": 4514.81, "duration": 3.315}, {"text": "Simulator is always, you know,", "start": 4518.125, "duration": 1.095}, {"text": "it's in practice is always a little bit off.", "start": 4519.22, "duration": 1.905}, {"text": "Um, so it's important to have noise in the simulator in model based RL.", "start": 4521.125, "duration": 4.95}, {"text": "But when you're deploying this in a physical simulator, um,", "start": 4526.075, "duration": 3.57}, {"text": "one thing you could do that'll be very reasonable is just get rid of", "start": 4529.645, "duration": 3.255}, {"text": "the noise and set k equals 1 and so what you would do is,", "start": 4532.9, "duration": 4.71}, {"text": "um, uh, let's see.", "start": 4537.61, "duration": 10.74}, {"text": "Um, whenever you're in the state s,", "start": 4548.35, "duration": 8.05}, {"text": "pick the action a according to", "start": 4558.42, "duration": 6.55}, {"text": "arg max over a of v of s, a.", "start": 4564.97, "duration": 6.465}, {"text": "Right so, uh, this f is this f from here.", "start": 4571.435, "duration": 4.29}, {"text": "So this is the simulator", "start": 4575.725, "duration": 2.785}, {"text": "with the noise removed.", "start": 4584.49, "duration": 2.485}, {"text": "Okay and so what you would do is actually,", "start": 4586.975, "duration": 4.05}, {"text": "and, and, you know, computers are now", "start": 4591.025, "duration": 1.785}, {"text": "fast enough you can- you could do this 10 times a second.", "start": 4592.81, "duration": 2.13}, {"text": "Right if you want to control a helicopter or a self car at 10 hertz,", "start": 4594.94, "duration": 2.52}, {"text": "you could actually easily do this, you know, at,", "start": 4597.46, "duration": 2.34}, {"text": "at, at 10 times a second,", "start": 4599.8, "duration": 1.14}, {"text": "which is your car or your helicopter is in some physical state in the world.", "start": 4600.94, "duration": 4.14}, {"text": "So you know what is S and so you can", "start": 4605.08, "duration": 2.97}, {"text": "quickly for every possible action a that you could take,", "start": 4608.05, "duration": 4.35}, {"text": "use a simulator to simulate where your helicopter will go,", "start": 4612.4, "duration": 4.275}, {"text": "um, if you were to take that action.", "start": 4616.675, "duration": 2.13}, {"text": "So go ahead and run your simulator,", "start": 4618.805, "duration": 2.115}, {"text": "you know, once for each possible action you could take.", "start": 4620.92, "duration": 2.49}, {"text": "Right, computers are actually fast enough to do this in real time.", "start": 4623.41, "duration": 2.505}, {"text": "Um, and then for each of the possible next actions you could get to,", "start": 4625.915, "duration": 4.815}, {"text": "compute v apply to that.", "start": 4630.73, "duration": 2.13}, {"text": "Uh, so, so this is really right S prime, um, uh,", "start": 4632.86, "duration": 4.455}, {"text": "drawn from P_sa, uh,", "start": 4637.315, "duration": 2.31}, {"text": "but with a deterministic simulator, right.", "start": 4639.625, "duration": 3.565}, {"text": "Right, so every 10th of a second you could", "start": 4652.32, "duration": 2.74}, {"text": "in your simulator try out every single possible action,", "start": 4655.06, "duration": 3.39}, {"text": "use your simulator to figure out where you would go under each and every single possible action,", "start": 4658.45, "duration": 6.36}, {"text": "and apply your value function to see of all of", "start": 4664.81, "duration": 3.09}, {"text": "these possible actions, which one gets my helicopter,", "start": 4667.9, "duration": 3.735}, {"text": "you know, in the next one-tenth of a second to the state that", "start": 4671.635, "duration": 3.825}, {"text": "looks best according to the value functions you've learned from fitted value iteration.", "start": 4675.46, "duration": 4.845}, {"text": "Okay, um, and it turns out if you do this then you can,", "start": 4680.305, "duration": 5.355}, {"text": "this is how you actually implement something that runs in real time.", "start": 4685.66, "duration": 3.315}, {"text": "And, oh, and I just mentioned, you know, the, the,", "start": 4688.975, "duration": 2.985}, {"text": "the idea of a training with stochastic simulator and just setting the noise to zero,", "start": 4691.96, "duration": 4.875}, {"text": "it's one of those things that's not very vigorously justified but in practice this,", "start": 4696.835, "duration": 4.875}, {"text": "this works well. Yes, question?", "start": 4701.71, "duration": 1.8}, {"text": "[inaudible].", "start": 4703.51, "duration": 2.61}, {"text": "Oh yes. Ah, so, so, um,", "start": 4706.12, "duration": 2.37}, {"text": "for the purposes of this, you can assume you have a discretized action space,", "start": 4708.49, "duration": 3.33}, {"text": "ah, and it turns out that for a self-driving car it's", "start": 4711.82, "duration": 2.82}, {"text": "actually okay to discretize the action space.", "start": 4714.64, "duration": 3.285}, {"text": "Uh, for a helicopter,", "start": 4717.925, "duration": 1.79}, {"text": "we tend not to discretize the action space but, um,", "start": 4719.715, "duration": 3.09}, {"text": "it turns out if f is a continuous function,", "start": 4722.805, "duration": 2.925}, {"text": "then you can use other methods as well.", "start": 4725.73, "duration": 2.575}, {"text": "Right this is about optimizing over the, I,", "start": 4728.305, "duration": 1.98}, {"text": "I didn't mean to talk about this and sorry this is getting a little bit deeper.", "start": 4730.285, "duration": 2.745}, {"text": "But, uh, even if a was a continuous thing, uh,", "start": 4733.03, "duration": 3.405}, {"text": "you can actually use real time optimization algorithms, uh,", "start": 4736.435, "duration": 3.675}, {"text": "to very quickly try to optimize", "start": 4740.11, "duration": 1.77}, {"text": "this function even as the function that it contains actually.", "start": 4741.88, "duration": 2.52}, {"text": "Uh, there's a literature on something called model predictive control which,", "start": 4744.4, "duration": 3.51}, {"text": "which can actually, you can actually do these optimizations in", "start": 4747.91, "duration": 2.58}, {"text": "real time and use to fly a helicopter. Just one last question.", "start": 4750.49, "duration": 2.685}, {"text": "So what's your different action you'll transition from the next stage?", "start": 4753.175, "duration": 3.495}, {"text": "So how do you know when you're still looking?", "start": 4756.67, "duration": 1.62}, {"text": "Do you make an observation or do you use your [inaudible]?", "start": 4758.29, "duration": 4.74}, {"text": "Wait oh, uh, uh say, what's the question again?", "start": 4763.03, "duration": 1.86}, {"text": "So once you are, like when you have had the helicopter,", "start": 4764.89, "duration": 2.55}, {"text": "once you pick an action you'll transition to the next stage so do you make", "start": 4767.44, "duration": 3.78}, {"text": "an observation to set up where you are or do you use the [inaudible].", "start": 4771.22, "duration": 4.86}, {"text": "Oh, I use an observation, yeah, yes, yes.", "start": 4776.08, "duration": 2.07}, {"text": "So you take an action and then", "start": 4778.15, "duration": 1.62}, {"text": "your helicopter will do something, there will be some wind,", "start": 4779.77, "duration": 2.145}, {"text": "your model may be off and so you would then a 10th of a second later,", "start": 4781.915, "duration": 3.87}, {"text": "take another you know GPS reading, accelerometer reading,", "start": 4785.785, "duration": 3.075}, {"text": "magnetic compass reading and use", "start": 4788.86, "duration": 1.44}, {"text": "the helicopter sensors that tell you where you actually are.", "start": 4790.3, "duration": 2.7}, {"text": "Now, cool. Okay, cool.", "start": 4793.0, "duration": 3.12}, {"text": "All right, I hope, uh, yeah,", "start": 4796.12, "duration": 1.575}, {"text": "hope- hopefully this was helpful.", "start": 4797.695, "duration": 2.16}, {"text": "I feel like, you know, the- I think it's fascinating that the", "start": 4799.855, "duration": 2.205}, {"text": "excitement about self-driving cars and flying helicopters and all that,", "start": 4802.06, "duration": 2.775}, {"text": "it gives well-balanced equations like these.", "start": 4804.835, "duration": 1.875}, {"text": "I, I think that's kinda cool.", "start": 4806.71, "duration": 1.14}, {"text": "[LAUGHTER] Okay, that's great.", "start": 4807.85, "duration": 1.05}, {"text": "Thanks, I'll see you guys next week.", "start": 4808.9, "duration": 2.14}]