[{"text": "Hello everyone. Uh, so my name is Raphael Townshend.", "start": 3.47, "duration": 5.59}, {"text": "I'm one of the head TAs for this class.", "start": 9.06, "duration": 2.07}, {"text": "This week Andrew is traveling and my advisor is still dealing with medical issues.", "start": 11.13, "duration": 4.44}, {"text": "So I'm going to be giving today's lecture.", "start": 15.57, "duration": 2.12}, {"text": "Um, you heard from my wonderful co-head TA Anand a couple of weeks ago.", "start": 17.69, "duration": 4.095}, {"text": "And so today, we're gonna be going over decision trees and various ensemble methods.", "start": 21.785, "duration": 5.495}, {"text": "Uh, so these might seem a bit like disparate topics at first,", "start": 27.28, "duration": 3.25}, {"text": "but really decision trees are,", "start": 30.53, "duration": 1.45}, {"text": "sort of, a classical example model class to use with various ensembling methods.", "start": 31.98, "duration": 4.73}, {"text": "We're gonna get into a little bit why in a bit,", "start": 36.71, "duration": 2.415}, {"text": "but just to give you guys an overview of what the outlines can be.", "start": 39.125, "duration": 3.145}, {"text": "We're first gonna go over decision trees,", "start": 42.27, "duration": 1.38}, {"text": "then we're gonna go over general ensembling methods and then", "start": 43.65, "duration": 2.51}, {"text": "go specifically into bagging random forests and boosting.", "start": 46.16, "duration": 3.255}, {"text": "Okay. So let's get started.", "start": 49.415, "duration": 3.465}, {"text": "So first let's cover some decision trees.", "start": 52.88, "duration": 4.19}, {"text": "Okay. So last week,", "start": 64.91, "duration": 2.2}, {"text": "Andrew was covering SVNs that are, sort of,", "start": 67.11, "duration": 2.23}, {"text": "one of the classical linear models and,", "start": 69.34, "duration": 3.155}, {"text": "sort of, brought to a close a lot of discussion of those linear models.", "start": 72.495, "duration": 2.925}, {"text": "And so today we gonna be getting to decision trees which is really", "start": 75.42, "duration": 2.705}, {"text": "one of our first examples of a non-linear model.", "start": 78.125, "duration": 3.14}, {"text": "And so to motivate these guys let me give you guys an example.", "start": 81.265, "duration": 3.255}, {"text": "Okay. So I'm Canadian,", "start": 84.52, "duration": 2.4}, {"text": "I really like to ski.", "start": 86.92, "duration": 1.215}, {"text": "So I'm gonna motivate it using that.", "start": 88.135, "duration": 2.1}, {"text": "So pretend you have a classifier that given", "start": 90.235, "duration": 2.88}, {"text": "a time and a location tells you whether or not you can ski,", "start": 93.115, "duration": 3.815}, {"text": "so it's a binary classifier saying yes or no.", "start": 96.93, "duration": 2.78}, {"text": "And so you have, you can imagine,", "start": 99.71, "duration": 1.87}, {"text": "a graph like this,", "start": 101.58, "duration": 1.98}, {"text": "and on the x-axis we're gonna have time in months,", "start": 103.56, "duration": 4.125}, {"text": "so counting from the start.", "start": 107.685, "duration": 2.425}, {"text": "So starting at 1 for January to 12 for December,", "start": 112.48, "duration": 4.965}, {"text": "and then on the y-axis we're gonna use latitude in degrees, okay?", "start": 117.445, "duration": 4.94}, {"text": "And so for those of you who might have forgotten what latitude is,", "start": 122.385, "duration": 3.365}, {"text": "it's basically at positive 90 degrees you're at the North Pole,", "start": 125.75, "duration": 3.81}, {"text": "at negative 90 degrees you're at the South Pole.", "start": 129.56, "duration": 3.585}, {"text": "So positive 90, negative 90,", "start": 133.145, "duration": 4.839}, {"text": "0 being the Equator and it's, sort of,", "start": 137.984, "duration": 2.466}, {"text": "your location along the north-south axis.", "start": 140.45, "duration": 2.535}, {"text": "Okay. So given this,", "start": 142.985, "duration": 3.13}, {"text": "if you might recall,", "start": 146.115, "duration": 1.195}, {"text": "the winter in the Northern Hemisphere generally happens in the early months of the year.", "start": 147.31, "duration": 5.05}, {"text": "So you might see that you can ski in", "start": 152.36, "duration": 1.65}, {"text": "these early months over here and it has some positive data points,", "start": 154.01, "duration": 2.955}, {"text": "and then in the later months,", "start": 156.965, "duration": 1.665}, {"text": "right, and then in the middle, you can't really ski.", "start": 158.63, "duration": 6.625}, {"text": "Versus in the Southern Hemisphere,", "start": 165.255, "duration": 2.475}, {"text": "it's basically flipped, where you can not ski in the early months.", "start": 167.73, "duration": 3.89}, {"text": "You can ski during the May,", "start": 171.62, "duration": 2.74}, {"text": "June, July, August time period,", "start": 174.36, "duration": 2.76}, {"text": "and then you can't ski in the earlier months,", "start": 177.12, "duration": 2.64}, {"text": "and then the equator in general is just not", "start": 179.76, "duration": 2.03}, {"text": "great for skiing that's the reason I don't live there,", "start": 181.79, "duration": 2.205}, {"text": "and so you just have a bunch of negatives here.", "start": 183.995, "duration": 3.145}, {"text": "Okay. And so when you look at a data set like this,", "start": 187.67, "duration": 3.86}, {"text": "you've sort of got these separate regions that you're looking at, right?", "start": 191.53, "duration": 2.83}, {"text": "And you sort of want to isolate out those regions of positive examples.", "start": 194.36, "duration": 3.315}, {"text": "If you had a linear classifier, you'd sort of", "start": 197.675, "duration": 2.185}, {"text": "be hard-pressed to come up with any sort of", "start": 199.86, "duration": 1.8}, {"text": "decision boundary that would separate this reasonably.", "start": 201.66, "duration": 2.21}, {"text": "Now you could think okay, maybe you have an SVM or something,", "start": 203.87, "duration": 2.88}, {"text": "you've come up with a kernel that could perh-", "start": 206.75, "duration": 1.98}, {"text": "perhaps project this into a higher feature space that would make it linearly separable,", "start": 208.73, "duration": 4.11}, {"text": "but it turns out that with decision trees,", "start": 212.84, "duration": 2.19}, {"text": "you have a very natural way to do this.", "start": 215.03, "duration": 3.02}, {"text": "So to sort of make clear exactly what we want to do with decision trees,", "start": 218.05, "duration": 4.495}, {"text": "is we wanna sort of partition the space into individual regions.", "start": 222.545, "duration": 3.655}, {"text": "So we sort of wanna isolate out these,", "start": 226.2, "duration": 1.49}, {"text": "like, positive examples, for example.", "start": 227.69, "duration": 2.495}, {"text": "In general this problem is fairly intractable just coming up with the optimal regions.", "start": 230.185, "duration": 4.765}, {"text": "But how we do with decision trees is we do it in", "start": 234.95, "duration": 3.03}, {"text": "this basically greedy,", "start": 237.98, "duration": 3.13}, {"text": "top-down, recursive manner,", "start": 241.96, "duration": 8.6}, {"text": "and this is going to be recursive partitioning.", "start": 252.08, "duration": 4.28}, {"text": "Okay? And so it's- basically it's top-down because", "start": 259.9, "duration": 4.93}, {"text": "we're starting with the overall region and we wanna slowly partition it up, okay?", "start": 264.83, "duration": 4.14}, {"text": "And then it's greedy because at each step we wanna pick the best partition possible.", "start": 268.97, "duration": 4.685}, {"text": "Okay. So let's actually try and work out intuitively what a decision tree would do, okay?", "start": 273.655, "duration": 5.785}, {"text": "So what we do is we start with the overall space and the tree", "start": 279.44, "duration": 3.24}, {"text": "is basically gonna play 20 Questions with this space.", "start": 282.68, "duration": 3.29}, {"text": "Okay. So like for example,", "start": 285.97, "duration": 1.34}, {"text": "one question it might ask is,", "start": 287.31, "duration": 2.35}, {"text": "if we have the data coming in like this, is,", "start": 289.66, "duration": 2.875}, {"text": "is the latitude greater than 30 degrees, okay?", "start": 292.535, "duration": 5.965}, {"text": "And that would involve, sort of,", "start": 298.51, "duration": 2.185}, {"text": "cutting the space like this, for example, okay?", "start": 300.695, "duration": 2.85}, {"text": "And then we'd have a yes or a no.", "start": 303.545, "duration": 4.345}, {"text": "And so starting from, like,", "start": 308.78, "duration": 2.01}, {"text": "the most general space now we have partitioned", "start": 310.79, "duration": 2.805}, {"text": "the overall space into two separate spaces using this, this question.", "start": 313.595, "duration": 4.605}, {"text": "Okay. And this is where the recursive part comes in now,", "start": 318.2, "duration": 3.24}, {"text": "because now that you've sort of", "start": 321.44, "duration": 1.03}, {"text": "split the space into two,", "start": 322.47, "duration": 1.8}, {"text": "you can then sort of", "start": 324.27, "duration": 1.56}, {"text": "treat each individual space as a new problem to ask a new question about.", "start": 325.83, "duration": 4.085}, {"text": "So for example now that you've asked this latitude greater than 30 question,", "start": 329.915, "duration": 3.275}, {"text": "you could then ask something like,", "start": 333.19, "duration": 1.855}, {"text": "month less than like March or something like that.", "start": 335.045, "duration": 5.93}, {"text": "All right, and that would give you a yes or no.", "start": 340.975, "duration": 4.19}, {"text": "And what that works out to effectively,", "start": 345.165, "duration": 1.885}, {"text": "is that now you've taken this upper space here and divided it", "start": 347.05, "duration": 3.645}, {"text": "up into these two separate regions like this.", "start": 350.695, "duration": 4.9}, {"text": "And so you could imagine how through asking these recursive questions over and over again,", "start": 355.595, "duration": 5.075}, {"text": "you could start splitting up the entire space into your individual regions like this.", "start": 360.67, "duration": 5.68}, {"text": "Okay, and so to make this a little bit more formal,", "start": 368.36, "duration": 4.79}, {"text": "what we're looking for is,", "start": 373.15, "duration": 1.77}, {"text": "we're looking for, sort of,", "start": 374.92, "duration": 1.29}, {"text": "the split function, okay?", "start": 376.21, "duration": 1.32}, {"text": "So you can, sort of, define a region.", "start": 377.53, "duration": 2.37}, {"text": "So you have a region and let's call that region R_p in this case for R parent, okay?", "start": 379.9, "duration": 9.23}, {"text": "And we're looking for,", "start": 389.13, "duration": 1.815}, {"text": "looking for a split S_p,", "start": 390.945, "duration": 12.765}, {"text": "such that you have an S_p, you can, sort of,", "start": 403.71, "duration": 2.85}, {"text": "write out this S_p function as a function of j,t.", "start": 406.56, "duration": 5.475}, {"text": "Okay, where we saw you- j is which feature number and T is the threshold you're using.", "start": 412.035, "duration": 6.205}, {"text": "And so you can, sort of, write this out formally as,", "start": 418.24, "duration": 1.78}, {"text": "sort of, you're outputting a tuple,", "start": 420.02, "duration": 2.295}, {"text": "where on the one hand you have a set X where you", "start": 422.315, "duration": 4.975}, {"text": "have the x j- the jth feature of x is less than the threshold,", "start": 427.29, "duration": 5.385}, {"text": "and you have Xs element of R-p,", "start": 432.675, "duration": 2.565}, {"text": "since we're only partitioning that parent region.", "start": 435.24, "duration": 3.11}, {"text": "And then the second set is literally the same thing,", "start": 439.11, "duration": 4.06}, {"text": "except it's just those that are greater than t. And so we can refer", "start": 443.17, "duration": 10.68}, {"text": "to each one of these as R_1 and", "start": 453.85, "duration": 4.74}, {"text": "R_2.", "start": 458.59, "duration": 5.4}, {"text": "Any questions so far?", "start": 463.99, "duration": 2.05}, {"text": "No? Okay. So we,", "start": 467.36, "duration": 2.89}, {"text": "sort of, define now how we would, sort of, do this.", "start": 470.25, "duration": 2.22}, {"text": "We're trying to, like, greedily pick these peaks that are", "start": 472.47, "duration": 2.44}, {"text": "partitioning our input space and the splits are,", "start": 474.91, "duration": 2.78}, {"text": "sort of, defined by which feature you're looking at and", "start": 477.69, "duration": 2.44}, {"text": "the threshold that you're applying to that feature.", "start": 480.13, "duration": 3.415}, {"text": "Uh, sort of a natural question to ask now is,", "start": 483.545, "duration": 3.485}, {"text": "is how do you choose these splits,", "start": 487.03, "duration": 3.07}, {"text": "right? And so I sort of", "start": 502.37, "duration": 2.38}, {"text": "gave this intuitive explanation,", "start": 504.75, "duration": 1.9}, {"text": "that really what you're trying to do is you're trying to isolate out", "start": 506.65, "duration": 2.49}, {"text": "the space of positives and negatives in this case.", "start": 509.14, "duration": 3.09}, {"text": "And so what is useful to define is a loss on a region, okay?", "start": 512.23, "duration": 6.02}, {"text": "So define your loss L on R,", "start": 518.25, "duration": 6.875}, {"text": "loss on R. And", "start": 525.125, "duration": 8.795}, {"text": "so for now let's define our loss as something fairly obvious,", "start": 533.92, "duration": 3.855}, {"text": "is your misclassification loss.", "start": 537.775, "duration": 1.89}, {"text": "It's how many examples in your region you get wrong.", "start": 539.665, "duration": 3.9}, {"text": "And so assuming that you have, uh,", "start": 543.565, "duration": 3.08}, {"text": "given C classes total,", "start": 546.645, "duration": 5.885}, {"text": "you can define P hat c", "start": 554.37, "duration": 12.04}, {"text": "to be the proportion", "start": 566.41, "duration": 2.41}, {"text": "of examples in R", "start": 575.49, "duration": 8.785}, {"text": "that are of class c. [NOISE]", "start": 584.275, "duration": 9.785}, {"text": "And so now that we've got this definition,", "start": 594.06, "duration": 2.13}, {"text": "where we had this p hat c of telling us", "start": 596.19, "duration": 2.13}, {"text": "the proportion of examples that we've gotten that case,", "start": 598.32, "duration": 2.325}, {"text": "you can try to define the loss of any region as loss,", "start": 600.645, "duration": 5.505}, {"text": "let's call it misclassification,", "start": 606.15, "duration": 2.95}, {"text": "it's just 1 minus max over c of p hat c, okay?", "start": 609.64, "duration": 11.0}, {"text": "And so the reasoning behind this is", "start": 620.64, "duration": 2.85}, {"text": "basically you can say that for any region that you've subdivided generally,", "start": 623.49, "duration": 3.06}, {"text": "what you'll want to do is predict the most common class there,", "start": 626.55, "duration": 2.97}, {"text": "which is just the maximum p hat c, right?", "start": 629.52, "duration": 3.355}, {"text": "And so then all the remaining probability just gets thrown", "start": 632.875, "duration": 2.755}, {"text": "onto misclassification errors, okay?", "start": 635.63, "duration": 3.64}, {"text": "And so then once we do this,", "start": 639.27, "duration": 2.565}, {"text": "we want to basically pick- now that we have a loss defined,", "start": 641.835, "duration": 3.629}, {"text": "we want to, um,", "start": 645.464, "duration": 1.396}, {"text": "pick a split that decreases the loss as much as possible.", "start": 646.86, "duration": 4.77}, {"text": "So you recall I've defined this region,", "start": 651.63, "duration": 2.295}, {"text": "R_parent, and then these two children regions R_1 and R_2.", "start": 653.925, "duration": 4.32}, {"text": "And you basically want to reduce that loss as much as possible.", "start": 658.245, "duration": 4.185}, {"text": "So you want to, um,", "start": 662.43, "duration": 2.085}, {"text": "basically minimize loss,", "start": 664.515, "duration": 6.66}, {"text": "R_parent minus loss of R_1 plus loss of R_2.", "start": 671.175, "duration": 8.515}, {"text": "And so this is sort of your parent loss,", "start": 682.13, "duration": 5.18}, {"text": "this is your children loss.", "start": 691.31, "duration": 3.32}, {"text": "Okay. And since you're picking- and basically what you're", "start": 697.37, "duration": 4.21}, {"text": "minimizing over in some case is this j, t that we", "start": 701.58, "duration": 3.36}, {"text": "defined over here since this split is really what is gonna", "start": 704.94, "duration": 3.45}, {"text": "define our two children regions, right.", "start": 708.39, "duration": 3.585}, {"text": "And what you'll notice is that the loss of the parent doesn't really", "start": 711.975, "duration": 2.505}, {"text": "matter in this case because that's already defined.", "start": 714.48, "duration": 2.55}, {"text": "So really all you're trying to do is minimize this negative", "start": 717.03, "duration": 3.015}, {"text": "sum of losses of your children, okay?", "start": 720.045, "duration": 4.885}, {"text": "So let's move to the next board here.", "start": 727.15, "duration": 4.24}, {"text": "[NOISE]", "start": 731.39, "duration": 15.79}, {"text": "So I started to find this misclassification loss.", "start": 747.18, "duration": 1.98}, {"text": "Let's get a little bit into actually why misclassification loss", "start": 749.16, "duration": 2.865}, {"text": "isn't actually the right loss to use for this problem, so,", "start": 752.025, "duration": 4.285}, {"text": "okay? And so for a simple example,", "start": 770.78, "duration": 3.265}, {"text": "let's pretend- So I've sort of drawn out a tree like this,", "start": 774.045, "duration": 3.03}, {"text": "Let's pretend that instead we have", "start": 777.075, "duration": 2.13}, {"text": "another setup here where we're coming into a decision node.", "start": 779.205, "duration": 5.445}, {"text": "And at this point we have 900 positives and 100 negatives, okay?", "start": 784.65, "duration": 5.955}, {"text": "So this is sort of a misclassification loss,", "start": 790.605, "duration": 2.34}, {"text": "of 100 in this case because you'd predict", "start": 792.945, "duration": 2.085}, {"text": "the most common class and end up with 100 misclassified examples.", "start": 795.03, "duration": 4.305}, {"text": "All right, and so this would be your region R_p right now, right?", "start": 799.335, "duration": 4.395}, {"text": "And so then you can split it into these two other regions, right?", "start": 803.73, "duration": 4.14}, {"text": "Say R_1 and R_2.", "start": 807.87, "duration": 3.13}, {"text": "And say that what you've achieved now is you have the 700 positive,", "start": 814.04, "duration": 5.095}, {"text": "100 negatives on this side versus, uh,", "start": 819.135, "duration": 4.32}, {"text": "200 positives and 0 negatives on this side, okay?", "start": 823.455, "duration": 5.935}, {"text": "Now, this seems like a pretty good split since you're getting out some more examples.", "start": 829.73, "duration": 5.065}, {"text": "But what you can see is that, if you just drew the same thing again,", "start": 834.795, "duration": 3.165}, {"text": "right, R_p with 900 and 100,", "start": 837.96, "duration": 4.66}, {"text": "split split, and say in this case, instead,", "start": 844.67, "duration": 6.715}, {"text": "you've got 400 positives over here,", "start": 851.385, "duration": 2.565}, {"text": "100 negatives, and 500 positives and 0 negatives.", "start": 853.95, "duration": 8.355}, {"text": "So most people would argue that this bright decision boundary is better than", "start": 862.305, "duration": 4.095}, {"text": "the left one because you're basically isolating out even more positives in this case.", "start": 866.4, "duration": 4.14}, {"text": "However, if you're just looking at your misclassification loss,", "start": 870.54, "duration": 3.12}, {"text": "it turns out that on this left one here,", "start": 873.66, "duration": 2.31}, {"text": "let's call this R_1 and R_2 versus this right one,", "start": 875.97, "duration": 1.71}, {"text": "Let's call this R_1 prime,", "start": 877.68, "duration": 1.68}, {"text": "R_2 prime, okay?", "start": 879.36, "duration": 2.52}, {"text": "So your loss of R_1 plus R_2,", "start": 881.88, "duration": 5.77}, {"text": "on this left case it's just 100 plus 0.", "start": 887.84, "duration": 3.835}, {"text": "All right, so it's just 100.", "start": 891.675, "duration": 2.01}, {"text": "And then on the right side here,", "start": 893.685, "duration": 2.205}, {"text": "it's actually still just the same, right?", "start": 895.89, "duration": 8.445}, {"text": "And in fact, if you'd look at the original loss of", "start": 904.335, "duration": 2.595}, {"text": "your parent it's also just 100, right?", "start": 906.93, "duration": 2.97}, {"text": "So you haven't really according to this loss metric changed anything at all.", "start": 909.9, "duration": 4.92}, {"text": "And so that sort of brings up one problem with the misclassification loss is that,", "start": 914.82, "duration": 3.0}, {"text": "it's not really sensitive enough, okay?", "start": 917.82, "duration": 3.45}, {"text": "So like instead what we can do is we can define this cross-entropy loss, okay?", "start": 921.27, "duration": 5.46}, {"text": "So which we'll define as L_cross.", "start": 926.73, "duration": 21.73}, {"text": "Let me just write this out here.", "start": 951.83, "duration": 3.26}, {"text": "And so really what you're doing is you're just summing over", "start": 960.65, "duration": 2.8}, {"text": "the classes and it's the probability-", "start": 963.45, "duration": 2.175}, {"text": "that the proportion of elements in that class", "start": 965.625, "duration": 2.025}, {"text": "times the log of the proportion in that class.", "start": 967.65, "duration": 2.415}, {"text": "And how you can think of this is,", "start": 970.065, "duration": 2.115}, {"text": "It's sort of this concept that we borrow from information theory,", "start": 972.18, "duration": 3.0}, {"text": "which is sort of like the number of bits you need to", "start": 975.18, "duration": 2.67}, {"text": "communicate to tell someone who already", "start": 977.85, "duration": 2.22}, {"text": "knows what the probabilities are what class you are looking at.", "start": 980.07, "duration": 2.94}, {"text": "And so that sounds like a mouthful but really you can sort of think of it intuitively as,", "start": 983.01, "duration": 4.605}, {"text": "if someone already knows the probabilities,", "start": 987.615, "duration": 1.725}, {"text": "like say it's a 100% chance that it is of one class,", "start": 989.34, "duration": 3.48}, {"text": "then you don't need to communicate anything to tell", "start": 992.82, "duration": 2.295}, {"text": "them exactly which class it is because it's obvious that it is that", "start": 995.115, "duration": 2.385}, {"text": "one class versus if you have a fairly even split then you'd need to communicate", "start": 997.5, "duration": 3.99}, {"text": "a lot more information to tell someone exactly what class you were in.", "start": 1001.49, "duration": 5.505}, {"text": "Any questions so far? Yeah?", "start": 1006.995, "duration": 3.945}, {"text": "[inaudible].", "start": 1010.94, "duration": 6.81}, {"text": "The R_1, R_2 for the parent class?", "start": 1017.75, "duration": 1.77}, {"text": "[inaudible].", "start": 1019.52, "duration": 6.06}, {"text": "For this case here?", "start": 1025.58, "duration": 1.875}, {"text": "Yeah, yeah, so, um,", "start": 1027.455, "duration": 2.265}, {"text": "for that case there so you see that, er,", "start": 1029.72, "duration": 2.22}, {"text": "I'll try and reach up there, but so it's like say like R_p was your start region, right?", "start": 1031.94, "duration": 4.59}, {"text": "You could say it's the overall region, right?", "start": 1036.53, "duration": 2.58}, {"text": "And then R_1 would be all the points above this latitude 30 line.", "start": 1039.11, "duration": 4.62}, {"text": "And R_2 would be all the points below the latitude 30 line.", "start": 1043.73, "duration": 4.6}, {"text": "Yeah, yeah?", "start": 1048.46, "duration": 2.29}, {"text": "[inaudible].", "start": 1050.75, "duration": 8.88}, {"text": "Yeah. So the question is,", "start": 1059.63, "duration": 1.755}, {"text": "when you're trying to minimize this loss here,", "start": 1061.385, "duration": 1.905}, {"text": "is it the same as maximizing the,", "start": 1063.29, "duration": 2.49}, {"text": "the children loss, and since,", "start": 1065.78, "duration": 1.365}, {"text": "er - no, uh,", "start": 1067.145, "duration": 2.355}, {"text": "ah, let's see, of maximizing the children loss.", "start": 1069.5, "duration": 2.16}, {"text": "And yeah, it turns out it doesn't really matter,", "start": 1071.66, "duration": 2.37}, {"text": "which, um, which way you put it.", "start": 1074.03, "duration": 1.68}, {"text": "It just- basically, you're trying to either minimize the loss of", "start": 1075.71, "duration": 3.21}, {"text": "the children or maximize the gain in information, basically.", "start": 1078.92, "duration": 4.29}, {"text": "[inaudible].", "start": 1083.21, "duration": 12.32}, {"text": "Yeah. Let's see. Yeah, you're right.", "start": 1095.53, "duration": 3.1}, {"text": "That should actually be a max.", "start": 1098.63, "duration": 1.86}, {"text": "Let me fix that really quick.", "start": 1100.49, "duration": 2.98}, {"text": "Because you start with your parent loss,", "start": 1110.68, "duration": 2.65}, {"text": "and then you're subtracting out your children's loss,", "start": 1113.33, "duration": 2.82}, {"text": "and so the amount left,", "start": 1116.15, "duration": 2.264}, {"text": "let's see, the higher this loss is- yeah.", "start": 1118.414, "duration": 1.876}, {"text": "So you really want to maximize this guy.", "start": 1120.29, "duration": 2.56}, {"text": "Makes sense, everyone? Thanks for that.", "start": 1125.05, "duration": 5.09}, {"text": "Okay, so I've sort of given this like, hand-wavy- Oh, sure, what's up?", "start": 1142.39, "duration": 3.79}, {"text": "[inaudible].", "start": 1146.18, "duration": 4.5}, {"text": "So that would be log-based.", "start": 1150.68, "duration": 1.23}, {"text": "The question is, for the cross-entropy loss,", "start": 1151.91, "duration": 1.83}, {"text": "is it log base 2 or log base c?", "start": 1153.74, "duration": 1.47}, {"text": "It's log base 2.", "start": 1155.21, "duration": 1.44}, {"text": "Okay, here, I can write that out. Yep.", "start": 1156.65, "duration": 8.1}, {"text": "[inaudible].", "start": 1164.75, "duration": 4.08}, {"text": "Oh, sorry, I didn't quite hear that.", "start": 1168.83, "duration": 1.14}, {"text": "[inaudible].", "start": 1169.97, "duration": 9.33}, {"text": "Okay. Um, so the question is can- uh,", "start": 1179.3, "duration": 3.075}, {"text": "what is the proportion that are correct versus incorrect", "start": 1182.375, "duration": 2.535}, {"text": "for these two examples we've worked through here?", "start": 1184.91, "duration": 2.745}, {"text": "Um, and so, yeah- basically, what we're starting with is,", "start": 1187.655, "duration": 3.525}, {"text": "we're starting with we have 900/100, 900 positives and 100 negatives.", "start": 1191.18, "duration": 3.765}, {"text": "All right, so you can imagine that if you just stopped at this point, right,", "start": 1194.945, "duration": 3.315}, {"text": "you would just cla- classify everything as positive,", "start": 1198.26, "duration": 2.61}, {"text": "right, and so you get 100 negatives incorrect.", "start": 1200.87, "duration": 3.57}, {"text": "Does that make sense? Because this is 900 positives and 100 negatives.", "start": 1204.44, "duration": 4.41}, {"text": "So if you just stopped here and just tried to classify,", "start": 1208.85, "duration": 2.37}, {"text": "given this whole region R_p,", "start": 1211.22, "duration": 2.025}, {"text": "you would end up getting 10% of your examples wrong, right?", "start": 1213.245, "duration": 5.325}, {"text": "In this case, we're sort of talking- we're not talking about percentages,", "start": 1218.57, "duration": 3.03}, {"text": "we're talking about absolute number of examples that we've gotten wrong,", "start": 1221.6, "duration": 3.24}, {"text": "but you can also definitely talk in terms of percentages instead.", "start": 1224.84, "duration": 3.615}, {"text": "And then down here, once you've split it,", "start": 1228.455, "duration": 2.925}, {"text": "right, now you've got these two subregions, right?", "start": 1231.38, "duration": 3.21}, {"text": "And for- on this, on this left one here,", "start": 1234.59, "duration": 2.52}, {"text": "you still have more positives than negatives, right?", "start": 1237.11, "duration": 2.865}, {"text": "So you're still gonna classify positive in this leaf, right?", "start": 1239.975, "duration": 4.05}, {"text": "And you're still gonna classify positive in this leaf, too,", "start": 1244.025, "duration": 2.73}, {"text": "because they- they're both majority class,", "start": 1246.755, "duration": 4.44}, {"text": "or the positives are still the majority class there.", "start": 1251.195, "duration": 2.475}, {"text": "And in this case, since you have 0 negatives,", "start": 1253.67, "duration": 1.71}, {"text": "you're not gonna make any errors in your classification,", "start": 1255.38, "duration": 2.22}, {"text": "whereas in this case here,", "start": 1257.6, "duration": 1.17}, {"text": "it's still going to make 100 errors.", "start": 1258.77, "duration": 1.845}, {"text": "And so what I'm saying is that,", "start": 1260.615, "duration": 1.485}, {"text": "at this level, so if we just look above this line at R_p,", "start": 1262.1, "duration": 3.6}, {"text": "right, you're making 100 mistakes,", "start": 1265.7, "duration": 2.175}, {"text": "and then below this line you're still making 100 mistakes.", "start": 1267.875, "duration": 2.97}, {"text": "So what I'm saying is that, that the loss in this case is not very informative.", "start": 1270.845, "duration": 3.705}, {"text": "[inaudible].", "start": 1274.55, "duration": 4.14}, {"text": "Um, so this, this p-hat- okay,", "start": 1278.69, "duration": 2.64}, {"text": "I'm being a little bit loose with terminology with the notation here,", "start": 1281.33, "duration": 2.52}, {"text": "but the p-hat in this case is a proportion, okay?", "start": 1283.85, "duration": 3.21}, {"text": "But you can also easily- basically,", "start": 1287.06, "duration": 1.89}, {"text": "it's like whether you're normalizing the whole thing or not.", "start": 1288.95, "duration": 2.31}, {"text": "Yeah. Okay. So I've", "start": 1291.26, "duration": 7.38}, {"text": "sort of given this a bit handwavy explanation as to", "start": 1298.64, "duration": 2.1}, {"text": "why misclassification loss versus cross-entropy loss might be better or worse.", "start": 1300.74, "duration": 4.05}, {"text": "Um, we can actually get a fairly good intuition for why this is", "start": 1304.79, "duration": 3.42}, {"text": "the case by looking at it from a sort of geometric perspective.", "start": 1308.21, "duration": 4.44}, {"text": "So pretend now that you have this, this plot, okay?", "start": 1312.65, "duration": 7.695}, {"text": "And what you're plotting here is- pretend you have a binary classification problem, okay?", "start": 1320.345, "duration": 4.035}, {"text": "So you have just- is it positive class or negative class, okay?", "start": 1324.38, "duration": 4.17}, {"text": "And so you can sort of represent, say p-hat,", "start": 1328.55, "duration": 2.905}, {"text": "as like the proportion of positives in your set, okay?", "start": 1331.455, "duration": 3.865}, {"text": "And what you've got plotted up here is your loss.", "start": 1335.32, "duration": 3.405}, {"text": "Okay. For cross-entropy loss,", "start": 1338.725, "duration": 3.655}, {"text": "where your curve is gonna end up looking like is,", "start": 1342.38, "duration": 1.68}, {"text": "is gonna end up looking like this strictly concave curve like this, okay?", "start": 1344.06, "duration": 5.1}, {"text": "And what you can do is you can sort of look at where", "start": 1349.16, "duration": 3.78}, {"text": "your children versus your parent would fall on this curve.", "start": 1352.94, "duration": 4.005}, {"text": "So say that you have two children, okay?", "start": 1356.945, "duration": 3.03}, {"text": "You have one up here, so like let's call this LR1.", "start": 1359.975, "duration": 3.66}, {"text": "And you have one down here, LR2, okay?", "start": 1363.635, "duration": 6.045}, {"text": "And say that you have an equal number of examples in both R1 and R2,", "start": 1369.68, "duration": 4.68}, {"text": "so they're equally weighted.", "start": 1374.36, "duration": 1.65}, {"text": "If you take- when you're looking at the overall loss between the two,", "start": 1376.01, "duration": 3.96}, {"text": "right, that's really just the average of the two.", "start": 1379.97, "duration": 2.37}, {"text": "So you can draw a line between these two,", "start": 1382.34, "duration": 2.475}, {"text": "and the midpoint turns out to be the average of your two losses.", "start": 1384.815, "duration": 5.115}, {"text": "So this is LR1 plus LR2 divided by 2.", "start": 1389.93, "duration": 8.98}, {"text": "That's for this guy, okay?", "start": 1402.85, "duration": 4.615}, {"text": "And what you can notice is that, in fact,", "start": 1407.465, "duration": 2.415}, {"text": "the loss of the parent node is actually just this point projected upwards here,", "start": 1409.88, "duration": 5.535}, {"text": "so this would be your LR parent.", "start": 1415.415, "duration": 3.525}, {"text": "And this difference right here,", "start": 1418.94, "duration": 2.925}, {"text": "this difference, is sort of your change in loss.", "start": 1421.865, "duration": 7.015}, {"text": "Does this makes sense? Any questions?", "start": 1436.24, "duration": 4.73}, {"text": "Okay. So we have this- just to recap, okay.", "start": 1443.14, "duration": 3.46}, {"text": "So we have- say,", "start": 1446.6, "duration": 1.08}, {"text": "we have two children regions, right?", "start": 1447.68, "duration": 1.86}, {"text": "And they have different probabilities of positive examples occurring, right?", "start": 1449.54, "duration": 4.92}, {"text": "They sort of would fall- one would fall on this point on the curve, and say,", "start": 1454.46, "duration": 3.69}, {"text": "the other one falls on this point on the curve,", "start": 1458.15, "duration": 1.545}, {"text": "then the average of the two losses sort of falls on", "start": 1459.695, "duration": 2.265}, {"text": "the midpoint between these two original losses.", "start": 1461.96, "duration": 3.015}, {"text": "And if you look at the parent,", "start": 1464.975, "duration": 2.505}, {"text": "it's really just halfway between on the x-axis,", "start": 1467.48, "duration": 2.79}, {"text": "and you can project up towards for that as well,", "start": 1470.27, "duration": 1.92}, {"text": "and you end up with the loss of R_parent. What's up?", "start": 1472.19, "duration": 2.82}, {"text": "[inaudible].", "start": 1475.01, "duration": 9.345}, {"text": "Okay. So what we're looking at here is we're looking at the cross entropy loss.", "start": 1484.355, "duration": 3.675}, {"text": "So you've got this function here,", "start": 1488.03, "duration": 1.2}, {"text": "this L cross entropy right,", "start": 1489.23, "duration": 1.92}, {"text": "and that's in terms of p-hat c's, right?", "start": 1491.15, "duration": 3.06}, {"text": "In this case here,", "start": 1494.21, "duration": 1.53}, {"text": "we're just assuming that we have two classes, okay?", "start": 1495.74, "duration": 2.61}, {"text": "So what we're doing is we're just modifying the p-hat c, we're,", "start": 1498.35, "duration": 4.17}, {"text": "we're changing that on the x-axis and then we're looking at what", "start": 1502.52, "duration": 2.67}, {"text": "the response of the overall loss function is on the y-axis.", "start": 1505.19, "duration": 3.84}, {"text": "And so what I just did here is for any- this curve just represents for any p-hat c,", "start": 1509.03, "duration": 5.565}, {"text": "what the cross entropy loss would look like.", "start": 1514.595, "duration": 2.79}, {"text": "Okay. And so we can come back to this, for example, right?", "start": 1517.385, "duration": 3.615}, {"text": "And if we look at this parent here right,", "start": 1521.0, "duration": 2.1}, {"text": "this guy has a 10%, right?", "start": 1523.1, "duration": 2.46}, {"text": "It's sort of like p-hat,", "start": 1525.56, "duration": 2.715}, {"text": "p-hat for this guy is 0.1,", "start": 1528.275, "duration": 3.66}, {"text": "it's 10% basically or,", "start": 1531.935, "duration": 2.64}, {"text": "or I guess no, in this case, would be 0.9 sorry.", "start": 1534.575, "duration": 3.315}, {"text": "And then versus here, in these two cases, right,", "start": 1537.89, "duration": 2.97}, {"text": "your p-hat, in this case,", "start": 1540.86, "duration": 1.665}, {"text": "is 1 since you've got them all right,", "start": 1542.525, "duration": 2.73}, {"text": "all right, and then, in this case,", "start": 1545.255, "duration": 2.19}, {"text": "it's 0.8, okay?", "start": 1547.445, "duration": 2.55}, {"text": "So you can sort of see since these are equal,", "start": 1549.995, "duration": 1.83}, {"text": "there's the same number of examples in both of these,", "start": 1551.825, "duration": 2.565}, {"text": "the p-hat of the parent is just the average of the p-hat's of the children.", "start": 1554.39, "duration": 4.005}, {"text": "Okay. And so that's how we can sort of take this LR_parent,", "start": 1558.395, "duration": 4.325}, {"text": "this LR_parent is just halfway, if we projected this down, all right.", "start": 1562.72, "duration": 3.765}, {"text": "Let me just erase this little bit here.", "start": 1566.485, "duration": 4.675}, {"text": "If we projected this down like this,", "start": 1573.55, "duration": 4.01}, {"text": "we'd see that this- that this point here is the midpoint.", "start": 1580.48, "duration": 5.72}, {"text": "Okay. Um, but then when you're", "start": 1589.42, "duration": 3.82}, {"text": "actually averaging the two losses after you've done the split,", "start": 1593.24, "duration": 3.33}, {"text": "then you can basically just,", "start": 1596.57, "duration": 1.53}, {"text": "you're just taking the average loss right?", "start": 1598.1, "duration": 1.68}, {"text": "You're just summing LR1 plus", "start": 1599.78, "duration": 2.07}, {"text": "LR2 and if you're taking the average then you're dividing by two,", "start": 1601.85, "duration": 2.745}, {"text": "and what you can do is you can just draw the line and take", "start": 1604.595, "duration": 2.055}, {"text": "the midpoint of this line instead. Yeah.", "start": 1606.65, "duration": 2.61}, {"text": "[inaudible].", "start": 1609.26, "duration": 4.26}, {"text": "Yeah.", "start": 1613.52, "duration": 0.3}, {"text": "[inaudible]", "start": 1613.82, "duration": 12.09}, {"text": "Yeah. Exactly. So yeah really any- if there- it's a good point.", "start": 1625.91, "duration": 3.6}, {"text": "The question was if you have an uneven split,", "start": 1629.51, "duration": 3.285}, {"text": "uh what would that look like on this curve, right?", "start": 1632.795, "duration": 3.33}, {"text": "And so at this point, I've been making the math easy by", "start": 1636.125, "duration": 2.415}, {"text": "just saying there's an even split but really if there was", "start": 1638.54, "duration": 2.07}, {"text": "a slightly uneven split you- the average would just be", "start": 1640.61, "duration": 2.4}, {"text": "any point along this line that you've drawn.", "start": 1643.01, "duration": 2.73}, {"text": "As you can see the whole thing is strictly concave so any point along", "start": 1645.74, "duration": 3.81}, {"text": "that line is going to lie below the original loss curve for the parent.", "start": 1649.55, "duration": 4.83}, {"text": "So you're basically, as long as you're not picking", "start": 1654.38, "duration": 2.43}, {"text": "the exact same points on", "start": 1656.81, "duration": 1.41}, {"text": "the probability curve and not making any gain at all in your split,", "start": 1658.22, "duration": 2.955}, {"text": "you're gonna gain some amount of information through this split.", "start": 1661.175, "duration": 4.525}, {"text": "Okay. Now, this was the cross-entropy loss, right?", "start": 1667.72, "duration": 11.0}, {"text": "If instead, we look at the misclassification loss over here,", "start": 1682.96, "duration": 5.335}, {"text": "let's draw this one instead.", "start": 1688.295, "duration": 2.305}, {"text": "What we can see, in this case,", "start": 1712.18, "duration": 2.68}, {"text": "if you draw it is that it's in fact really this pyramid kind of shape where", "start": 1714.86, "duration": 3.84}, {"text": "it's just linear and then flips over once you start classifying the other side.", "start": 1718.7, "duration": 4.14}, {"text": "And if you did the same argument here where we had LR1 and LR2,", "start": 1722.84, "duration": 8.08}, {"text": "and then you drew a line between them, all right,", "start": 1730.93, "duration": 3.115}, {"text": "that's basically just still the loss curve, and so,", "start": 1734.045, "duration": 2.775}, {"text": "in this case, like your midpoint would be the same point as your parent.", "start": 1736.82, "duration": 3.48}, {"text": "So your loss of R_parent, in this case,", "start": 1740.3, "duration": 3.63}, {"text": "would equal your loss of R1 plus loss of R2 divided by 2.", "start": 1743.93, "duration": 7.99}, {"text": "All right. And so in this case,", "start": 1752.59, "duration": 2.32}, {"text": "you can- there's even now according to the cross entropy formulation,", "start": 1754.91, "duration": 3.48}, {"text": "you do have a gain in information and intuitively", "start": 1758.39, "duration": 2.07}, {"text": "we do see a gain in information over here.", "start": 1760.46, "duration": 2.16}, {"text": "For the misclassification loss, since it's not very sensitive,", "start": 1762.62, "duration": 2.805}, {"text": "if you end up with points on the same side of the curve,", "start": 1765.425, "duration": 2.535}, {"text": "then you actually don't see any sort of", "start": 1767.96, "duration": 2.25}, {"text": "information gain based on this kind of representation.", "start": 1770.21, "duration": 3.43}, {"text": "And so there's actually a couple, I,", "start": 1776.38, "duration": 2.425}, {"text": "I presented the cross entropy loss here.", "start": 1778.805, "duration": 2.07}, {"text": "There's also the Gini loss which is another one,", "start": 1780.875, "duration": 3.135}, {"text": "which people just write out as,", "start": 1784.01, "duration": 2.725}, {"text": "as the sum over your classes p-hat c times one minus p-hat c,", "start": 1786.735, "duration": 7.945}, {"text": "okay, and it turns out that this curve also looks very", "start": 1794.68, "duration": 3.42}, {"text": "similar to this original cross entropy curve.", "start": 1798.1, "duration": 2.89}, {"text": "And what you'll see is that actually most curves that", "start": 1800.99, "duration": 2.61}, {"text": "are successfully used for de- decision splits,", "start": 1803.6, "duration": 2.79}, {"text": "look basically like the strictly concave function.", "start": 1806.39, "duration": 3.76}, {"text": "Okay. So that's where it covers a lot of the criteria we use for splits.", "start": 1811.84, "duration": 5.44}, {"text": "Um, let's look at some extensions for decision trees.", "start": 1817.28, "duration": 4.72}, {"text": "Actually, I'm going to keep this guy.", "start": 1838.15, "duration": 3.2}, {"text": "Okay. So, so far I've been talking about decision trees for classification.", "start": 1858.1, "duration": 5.17}, {"text": "You could also imagine having decision trees for regression,", "start": 1863.27, "duration": 4.095}, {"text": "and people generally call these regression trees, okay.", "start": 1867.365, "duration": 3.99}, {"text": "So taking the ski example again let's", "start": 1871.355, "duration": 2.715}, {"text": "pretend that instead of now predicting whether or not you can ski,", "start": 1874.07, "duration": 2.895}, {"text": "you're predicting the amount of snowfall you would expect in that area around that time.", "start": 1876.965, "duration": 4.95}, {"text": "Um, so like let's- I'm just gonna say it's like inches of snowfall I guess or something,", "start": 1881.915, "duration": 5.445}, {"text": "per like day or something and just like maybe have some values up here.", "start": 1887.36, "duration": 5.91}, {"text": "Some high value because you're- it's winter over there,", "start": 1893.27, "duration": 3.855}, {"text": "it's mostly 0s over here because there's summer,", "start": 1897.125, "duration": 3.21}, {"text": "and then you have some more high values over here,", "start": 1900.335, "duration": 3.714}, {"text": "and then you have 0s along the equator again.", "start": 1904.24, "duration": 4.13}, {"text": "0s, southern hemisphere over our winter,", "start": 1911.08, "duration": 5.81}, {"text": "and then more 0s like this.", "start": 1919.54, "duration": 2.695}, {"text": "And you can sort of see how you would do just the exact same thing.", "start": 1922.235, "duration": 3.135}, {"text": "You still want to isolate out regions and sort of", "start": 1925.37, "duration": 2.115}, {"text": "increase like the purity of those regions.", "start": 1927.485, "duration": 2.715}, {"text": "So you could still create like your trees like this,", "start": 1930.2, "duration": 3.735}, {"text": "all right, and split out like this for example.", "start": 1933.935, "duration": 4.305}, {"text": "And what you do when you get to one of your leaves", "start": 1938.24, "duration": 2.655}, {"text": "is instead of just predicting a majority class,", "start": 1940.895, "duration": 2.4}, {"text": "what you can do is predict the mean of the values left.", "start": 1943.295, "duration": 4.32}, {"text": "So you're predicting,", "start": 1947.615, "duration": 2.625}, {"text": "predict y hat where, well for Rm.", "start": 1950.24, "duration": 8.25}, {"text": "So pretend you have a region Rm,", "start": 1958.49, "duration": 1.575}, {"text": "you're predicting y hat of m which is the sum of all the indices in Rm,", "start": 1960.065, "duration": 7.525}, {"text": "Y i minus y hat m,", "start": 1967.63, "duration": 4.18}, {"text": "and you want the squared loss and then you can sort of I guess,", "start": 1971.81, "duration": 3.72}, {"text": "in this case, you want to normalize by", "start": 1975.53, "duration": 3.03}, {"text": "the overall cardinality of Rm or how many points you have in Rm.", "start": 1978.56, "duration": 5.89}, {"text": "And so in this case, basically all you've done is you've switched", "start": 1985.27, "duration": 3.76}, {"text": "your loss function or, no sorry that's wrong.", "start": 1989.03, "duration": 5.16}, {"text": "[LAUGHTER] This is actually- I got a little bit ahead of myself.", "start": 1994.19, "duration": 4.26}, {"text": "This is actually just- the,", "start": 1998.45, "duration": 2.1}, {"text": "the mean value would just be this, in this case, right?", "start": 2000.55, "duration": 2.685}, {"text": "It's just your summing all the values within your region.", "start": 2003.235, "duration": 2.685}, {"text": "So in this case, 7, 9, 8,", "start": 2005.92, "duration": 1.38}, {"text": "10, and then just taking the average of that.", "start": 2007.3, "duration": 2.685}, {"text": "Um, but so then what you do,", "start": 2009.985, "duration": 3.465}, {"text": "what I was starting to write out there was actually really the,", "start": 2013.45, "duration": 2.475}, {"text": "the loss that you would use, in this case,", "start": 2015.925, "duration": 1.98}, {"text": "right, which is your squared loss, okay?", "start": 2017.905, "duration": 3.43}, {"text": "So like we'll just call that L squared which, in this case,", "start": 2021.335, "duration": 6.955}, {"text": "would be equal to Y i minus", "start": 2028.29, "duration": 7.23}, {"text": "y hat m squared over R m. That's what I started to write over there.", "start": 2035.52, "duration": 8.46}, {"text": "But in this case, right,", "start": 2043.98, "duration": 1.62}, {"text": "you have your mean prediction and then your loss in this case,", "start": 2045.6, "duration": 2.58}, {"text": "is how far off your mean prediction is from the overall predictions,", "start": 2048.18, "duration": 4.284}, {"text": "in this case. Yep.", "start": 2052.464, "duration": 9.276}, {"text": "So in terms of [inaudible].", "start": 2061.74, "duration": 12.46}, {"text": "So that's a really good question. The question was uh,", "start": 2074.2, "duration": 2.745}, {"text": "how do you actually search for your splits,", "start": 2076.945, "duration": 2.265}, {"text": "how do you actually solve the optimization problem of finding these splits?", "start": 2079.21, "duration": 3.285}, {"text": "And it turns out that you can actually basically brute force it very efficiently.", "start": 2082.495, "duration": 3.72}, {"text": "I'm going to get into sot of the details of how you do that shortly,", "start": 2086.215, "duration": 3.555}, {"text": "but it turns out that you can just go through everything", "start": 2089.77, "duration": 2.19}, {"text": "fairly quickly. Um, I'll get into that.", "start": 2091.96, "duration": 2.34}, {"text": "I think that's in a couple of sections from now,", "start": 2094.3, "duration": 2.92}, {"text": "yeah. Any other questions?", "start": 2097.5, "duration": 3.02}, {"text": "Okay. So this is,", "start": 2101.43, "duration": 3.76}, {"text": "uh, for regression trees, right?", "start": 2105.19, "duration": 1.755}, {"text": "It turns out that,", "start": 2106.945, "duration": 1.63}, {"text": "um, another useful extension that,", "start": 2108.575, "duration": 2.87}, {"text": "that you don't really get for other learning algorithms is that you can also deal with,", "start": 2111.445, "duration": 4.425}, {"text": "uh, categorical variables fairly easily.", "start": 2115.87, "duration": 3.16}, {"text": "And basically, for this case,", "start": 2129.63, "duration": 2.83}, {"text": "you could imagine that instead of having your latitude in degrees,", "start": 2132.46, "duration": 3.24}, {"text": "you could just have three categories right?", "start": 2135.7, "duration": 2.205}, {"text": "You could have something like, uh,", "start": 2137.905, "duration": 3.295}, {"text": "this is the northern hemisphere,", "start": 2141.24, "duration": 3.265}, {"text": "this is the equator,", "start": 2144.505, "duration": 2.755}, {"text": "and this is the southern hemisphere, okay?", "start": 2147.57, "duration": 4.01}, {"text": "And then you could ask questions instead of the sort,", "start": 2152.52, "duration": 3.55}, {"text": "like that initial question we had before,", "start": 2156.07, "duration": 2.22}, {"text": "where it was latitude greater than 30.", "start": 2158.29, "duration": 1.92}, {"text": "Your question could instead be is,", "start": 2160.21, "duration": 2.79}, {"text": "is- I guess this would be,", "start": 2163.0, "duration": 4.665}, {"text": "is location in northern hemisphere?", "start": 2167.665, "duration": 6.885}, {"text": "Right. And you can have basically any sort of subset- you could ask me", "start": 2174.55, "duration": 3.0}, {"text": "question about any sort of subset of the categories you're looking at.", "start": 2177.55, "duration": 3.735}, {"text": "Right? So in this case Northern,", "start": 2181.285, "duration": 1.515}, {"text": "you would still- this question would still split out", "start": 2182.8, "duration": 1.95}, {"text": "this top part from these bottom pieces here.", "start": 2184.75, "duration": 2.7}, {"text": "One thing to be careful about though is that if you have q categories,", "start": 2187.45, "duration": 5.59}, {"text": "then you have- I mean,", "start": 2196.65, "duration": 2.83}, {"text": "you basically are considering every single possible subset of these categories.", "start": 2199.48, "duration": 3.87}, {"text": "So that's 2 to the q possible splits.", "start": 2203.35, "duration": 3.79}, {"text": "And so in general, you don't want to deal with too many categories because this will", "start": 2212.04, "duration": 4.66}, {"text": "become quickly intractable to look through that many possible examples.", "start": 2216.7, "duration": 4.515}, {"text": "It turns out that in certain very specific cases,", "start": 2221.215, "duration": 3.435}, {"text": "you can still deal with a lot of categories.", "start": 2224.65, "duration": 2.925}, {"text": "One such case is for binary classification where then you can just- the math is a little", "start": 2227.575, "duration": 5.655}, {"text": "bit complicated for this one but you can basically sort", "start": 2233.23, "duration": 2.4}, {"text": "your categories by how many positive examples are in each category,", "start": 2235.63, "duration": 3.345}, {"text": "and then just take that as like a sorted order then search through that linearly,", "start": 2238.975, "duration": 4.56}, {"text": "and it turns out that that yields to an optimal solution.", "start": 2243.535, "duration": 3.385}, {"text": "So decision trees, we can use them for regression,", "start": 2254.04, "duration": 3.1}, {"text": "we can also use them for categorical variables.", "start": 2257.14, "duration": 2.385}, {"text": "Um, one thing that I've not gotten into is that,", "start": 2259.525, "duration": 3.195}, {"text": "you can imagine that in the limit if you grew your tree without ever stopping,", "start": 2262.72, "duration": 4.23}, {"text": "you could end up just having a separate region for every single data point that you have.", "start": 2266.95, "duration": 4.68}, {"text": "Um, so that's really- you could consider that probably", "start": 2271.63, "duration": 3.41}, {"text": "over fitting if you ran it all the way to that completion, right?", "start": 2275.04, "duration": 2.82}, {"text": "So you can sort of see that decision trees are fairly high variance models.", "start": 2277.86, "duration": 7.7}, {"text": "So one thing that we're interested in doing is regularizing these high variance models.", "start": 2285.69, "duration": 6.26}, {"text": "And generally, how people have solved this problem is through a number of heuristics, okay?", "start": 2304.92, "duration": 4.645}, {"text": "So one such heuristic is that if you hit a certain minimum leaf size,", "start": 2309.565, "duration": 5.295}, {"text": "you stop splitting that leaf, okay?", "start": 2314.86, "duration": 4.0}, {"text": "So for example in this case if you've hit like you only have", "start": 2319.59, "duration": 3.43}, {"text": "four examples left in this leaf, then you just stop.", "start": 2323.02, "duration": 3.225}, {"text": "Another one is you can enforce a maximum depth,", "start": 2326.245, "duration": 4.495}, {"text": "and sort of a related one in this case is a max number of nodes.", "start": 2334.38, "duration": 5.84}, {"text": "And then a fourth very tempting one I've got to say to use is you say,", "start": 2347.76, "duration": 5.845}, {"text": "a minimum decrease in loss, right?", "start": 2353.605, "duration": 3.535}, {"text": "I say this one's tempting because it's generally not", "start": 2364.71, "duration": 3.52}, {"text": "actually a good idea to use this minimum decrease in loss 1.", "start": 2368.23, "duration": 3.195}, {"text": "You can think about that,", "start": 2371.425, "duration": 1.53}, {"text": "by thinking that if you have any sort of", "start": 2372.955, "duration": 1.665}, {"text": "higher-order interactions between your variables, um,", "start": 2374.62, "duration": 3.06}, {"text": "you might have to ask one question that is not very optimal,", "start": 2377.68, "duration": 3.645}, {"text": "or doesn't give you that much of an increase in loss,", "start": 2381.325, "duration": 1.98}, {"text": "and then your follow-up question combined with", "start": 2383.305, "duration": 2.145}, {"text": "that first question might give you a much better increase.", "start": 2385.45, "duration": 2.19}, {"text": "And you can sort of see that in this case,", "start": 2387.64, "duration": 1.59}, {"text": "where the initial latitude questions doesn't really give us that much of a gain.", "start": 2389.23, "duration": 3.78}, {"text": "We sort of split some positive and negatives,", "start": 2393.01, "duration": 1.74}, {"text": "but the combination of the latitude question", "start": 2394.75, "duration": 2.1}, {"text": "plus the time question really nails down what we want.", "start": 2396.85, "duration": 3.195}, {"text": "And if we were looking at it purely from the minimum decrease in loss perspective,", "start": 2400.045, "duration": 3.435}, {"text": "we might stop too early and miss that entirely.", "start": 2403.48, "duration": 4.2}, {"text": "And so a better way to do this kind of loss decrease is instead you grow out your full tree,", "start": 2407.68, "duration": 6.02}, {"text": "and then you prune it backwards instead.", "start": 2413.7, "duration": 1.935}, {"text": "So you grow out the whole thing and then you check which nodes to prune out.", "start": 2415.635, "duration": 4.56}, {"text": "Pruning. And how you generally do this, is you,", "start": 2420.195, "duration": 4.48}, {"text": "you take it- you have a validation set that you use this with,", "start": 2424.675, "duration": 3.045}, {"text": "and you evaluate what your misclassification error is on your validation set.", "start": 2427.72, "duration": 4.695}, {"text": "If for each example that you might remove for each leaf that you might remove.", "start": 2432.415, "duration": 3.84}, {"text": "So you would use misclassification in", "start": 2436.255, "duration": 5.175}, {"text": "this case with a validation set.", "start": 2441.43, "duration": 8.83}, {"text": "Any questions? Yeah?", "start": 2460.62, "duration": 3.73}, {"text": "The minimum decrease in loss.", "start": 2464.35, "duration": 1.935}, {"text": "The minimum decrease in loss?", "start": 2466.285, "duration": 2.055}, {"text": "So, um, yeah of course.", "start": 2468.34, "duration": 2.64}, {"text": "Uh, so you'll recall that before I was talking about sort of this RP,", "start": 2470.98, "duration": 3.735}, {"text": "this loss of R_parent versus loss of R_1 plus loss of R_2.", "start": 2474.715, "duration": 3.815}, {"text": "All right, so when we're- I had written out a maximization basically,", "start": 2478.53, "duration": 4.105}, {"text": "um, oh to be clear, the question is,", "start": 2482.635, "duration": 2.835}, {"text": "can you explain a little bit more clearly what this minimum decrease in loss means?", "start": 2485.47, "duration": 5.08}, {"text": "And so you have your loss of R_1 and R_2 versus your loss of R_parent, right?", "start": 2491.34, "duration": 4.975}, {"text": "So the split before the split, right,", "start": 2496.315, "duration": 2.775}, {"text": "you have your loss before split.", "start": 2499.09, "duration": 6.1}, {"text": "You have the loss of R_parent,", "start": 2505.83, "duration": 3.28}, {"text": "and then after split,", "start": 2509.11, "duration": 2.98}, {"text": "you have loss of R_1 plus loss of R_2.", "start": 2516.21, "duration": 5.035}, {"text": "Yeah. And if, if this decrease", "start": 2521.245, "duration": 3.87}, {"text": "between your loss of R_parent to your loss of your children is not great enough,", "start": 2525.115, "duration": 3.405}, {"text": "you might be tempted to say, \"Okay,", "start": 2528.52, "duration": 1.455}, {"text": "that question didn't really gain us anything,", "start": 2529.975, "duration": 2.445}, {"text": "and so therefore we will not actually use that question.\"", "start": 2532.42, "duration": 3.39}, {"text": "But what I'm saying is that sometimes you have to ask multiple questions, right?", "start": 2535.81, "duration": 3.84}, {"text": "You have to ask sort of sub-optimal questions first to get to the really good questions,", "start": 2539.65, "duration": 3.54}, {"text": "especially if you have sort of interaction between your variables,", "start": 2543.19, "duration": 3.09}, {"text": "if there is some amount of correlation between your variables.", "start": 2546.28, "duration": 3.13}, {"text": "Okay. So we talked about regularization.", "start": 2556.89, "duration": 5.03}, {"text": "I said that we would get to run time,", "start": 2562.32, "duration": 3.34}, {"text": "let's actually just go up here again.", "start": 2565.66, "duration": 2.16}, {"text": "[NOISE] So let's cover that really quickly.", "start": 2567.82, "duration": 6.84}, {"text": "[NOISE]", "start": 2574.66, "duration": 33.505}, {"text": "Okay. So it'll be useful to define a couple of numbers at this point.", "start": 2608.165, "duration": 4.995}, {"text": "So say you have n examples.", "start": 2613.16, "duration": 2.19}, {"text": "[NOISE] You have f features,", "start": 2615.35, "duration": 7.78}, {"text": "and finally, you have, uh,", "start": 2627.07, "duration": 3.37}, {"text": "d- let's say the depth of your tree is d, okay.", "start": 2630.44, "duration": 4.33}, {"text": "All right. So you've gra- you, you have n examples that you trained on you- with the each", "start": 2637.63, "duration": 4.96}, {"text": "of f features and your resulting tree has depth d. So at test time,", "start": 2642.59, "duration": 4.305}, {"text": "your run-time is basically just your depth d, right?", "start": 2646.895, "duration": 4.095}, {"text": "[NOISE] It's just o of d,", "start": 2650.99, "duration": 6.51}, {"text": "right? Which is your depth.", "start": 2657.5, "duration": 1.95}, {"text": "And typically, though not in all cases, um,", "start": 2659.45, "duration": 3.675}, {"text": "d is sort of about- is less than the log of your number of examples.", "start": 2663.125, "duration": 7.08}, {"text": "And you can sort of think about this as if you have a fairly balanced tree right,", "start": 2670.205, "duration": 4.815}, {"text": "you'll end up sort of evenly splitting out all the examples and sort of recursively like", "start": 2675.02, "duration": 4.245}, {"text": "doing these binary splits and so you'll be splitting it at the log of that n. Okay.", "start": 2679.265, "duration": 4.655}, {"text": "So at test-time you've generally got it pretty quick.", "start": 2683.92, "duration": 2.61}, {"text": "Uh, at train time,", "start": 2686.53, "duration": 3.01}, {"text": "um, you have each point.", "start": 2692.52, "duration": 5.075}, {"text": "So if you return back to this example,", "start": 2697.595, "duration": 2.445}, {"text": "you'll see that each point, right,", "start": 2700.04, "duration": 1.935}, {"text": "once you've done a split only belongs to", "start": 2701.975, "duration": 2.325}, {"text": "the left or right of that split afterwards. All right.", "start": 2704.3, "duration": 2.58}, {"text": "So it's sort of like, like this point right here,", "start": 2706.88, "duration": 2.04}, {"text": "once you've split here will only ever be part of this region,", "start": 2708.92, "duration": 2.37}, {"text": "will never be considered on the other side,", "start": 2711.29, "duration": 1.8}, {"text": "on the right-hand side of that split. All right.", "start": 2713.09, "duration": 3.6}, {"text": "So if your, if your tree is of depth d, each point,", "start": 2716.69, "duration": 5.37}, {"text": "each point is part", "start": 2722.06, "duration": 6.075}, {"text": "of Od nodes.", "start": 2728.135, "duration": 7.135}, {"text": "Okay. And then at each node,", "start": 2736.99, "duration": 4.255}, {"text": "you can actually work out that the cost of evaluating that point", "start": 2741.245, "duration": 3.81}, {"text": "for- at training time is actually just proportional to the number of features f.", "start": 2745.055, "duration": 4.975}, {"text": "I won't get too much into the details of why this is,", "start": 2764.65, "duration": 3.46}, {"text": "but you can consider that if you're doing binary features, for example,", "start": 2768.11, "duration": 3.57}, {"text": "where each feature is just yes or no of some sort,", "start": 2771.68, "duration": 2.28}, {"text": "then you only have to consider,", "start": 2773.96, "duration": 2.01}, {"text": "if you have f features total,", "start": 2775.97, "duration": 1.23}, {"text": "you only have to consider,", "start": 2777.2, "duration": 1.38}, {"text": "um, f possible splits.", "start": 2778.58, "duration": 2.025}, {"text": "So that's why the cost in that case would be f,", "start": 2780.605, "duration": 2.595}, {"text": "and then if it was instead a, uh, quantitative feature,", "start": 2783.2, "duration": 3.69}, {"text": "I mentioned briefly that you could sort", "start": 2786.89, "duration": 1.755}, {"text": "the overall features and then scan through them linearly,", "start": 2788.645, "duration": 3.015}, {"text": "um, and that also ends up being asymptotically O of f to do that.", "start": 2791.66, "duration": 5.23}, {"text": "Okay. So each point is at most O of d nodes,", "start": 2797.41, "duration": 4.42}, {"text": "and then the cost of point at each node is O of f and you have n points total.", "start": 2801.83, "duration": 4.41}, {"text": "So the total cost is really just,", "start": 2806.24, "duration": 3.1}, {"text": "is just O of nfd, like this.", "start": 2814.51, "duration": 5.275}, {"text": "It turns out that this is actually surprisingly fast, uh,", "start": 2819.785, "duration": 5.49}, {"text": "especially if you consider that n", "start": 2825.275, "duration": 3.495}, {"text": "times f is just the size of your original design matrix,", "start": 2828.77, "duration": 3.585}, {"text": "right or your data matrix, all right.", "start": 2832.355, "duration": 1.575}, {"text": "Your data matrix is", "start": 2833.93, "duration": 7.11}, {"text": "of size n times f,", "start": 2841.04, "duration": 5.64}, {"text": "right, and then you're only- your,", "start": 2846.68, "duration": 2.295}, {"text": "your runtime is going through the data matrix that most depth times,", "start": 2848.975, "duration": 3.555}, {"text": "and since depth is log of n,", "start": 2852.53, "duration": 1.56}, {"text": "that turns out to be or generally bounded by log of n,", "start": 2854.09, "duration": 3.3}, {"text": "you have generally, a fairly,", "start": 2857.39, "duration": 1.86}, {"text": "fast training time as well.", "start": 2859.25, "duration": 2.025}, {"text": "Any questions about runtime?", "start": 2861.275, "duration": 1.845}, {"text": "[NOISE] Okay.", "start": 2863.12, "duration": 7.29}, {"text": "So I've been talking a lot about the good sides of decision trees right,", "start": 2870.41, "duration": 3.705}, {"text": "they seem pretty nice so far.", "start": 2874.115, "duration": 1.455}, {"text": "However, there are a number of downsides too.", "start": 2875.57, "duration": 2.745}, {"text": "Um, and one big one is that it doesn't have additive structure to it.", "start": 2878.315, "duration": 8.41}, {"text": "And so let me explain a little bit what that means.", "start": 2886.725, "duration": 3.395}, {"text": "Okay. So let's say now we have an example and you have just two features again,", "start": 2909.61, "duration": 6.025}, {"text": "so x1 and x2,", "start": 2915.635, "duration": 2.97}, {"text": "and you ca- say you define a line, okay,", "start": 2918.605, "duration": 2.925}, {"text": "just running through the middle defined by x1 equals x2.", "start": 2921.53, "duration": 4.065}, {"text": "And all the points above this line are positive,", "start": 2925.595, "duration": 4.315}, {"text": "and all the points below it are negative.", "start": 2930.13, "duration": 3.34}, {"text": "Now, if you have a simple linear model like logistic regression,", "start": 2933.47, "duration": 3.39}, {"text": "you'll have no issue with this kind of setup.", "start": 2936.86, "duration": 2.07}, {"text": "But for a decision tree, [LAUGHTER] basically,", "start": 2938.93, "duration": 3.165}, {"text": "you'd have to ask a lot of questions that even somewhat approximate this line.", "start": 2942.095, "duration": 3.99}, {"text": "Like, what you can try is you're going to say okay let's split it this way,", "start": 2946.085, "duration": 3.525}, {"text": "and maybe we can do a split this way and then now I split here,", "start": 2949.61, "duration": 3.614}, {"text": "maybe something like this,", "start": 2953.224, "duration": 1.906}, {"text": "and basically something like that, right?", "start": 2955.13, "duration": 3.555}, {"text": "Even here you- so you've asked a lot of questions and you've only gotten", "start": 2958.685, "duration": 3.705}, {"text": "a very rough approximation of the actual line that you've drawn in this case.", "start": 2962.39, "duration": 4.26}, {"text": "And so decision trees do have a lot of issues with these kind of structures", "start": 2966.65, "duration": 3.75}, {"text": "where the v- the features are interacting additively with one another.", "start": 2970.4, "duration": 4.96}, {"text": "Okay. So to recap so far,", "start": 2976.96, "duration": 4.03}, {"text": "since we've covered a number of different things about decision trees,", "start": 2980.99, "duration": 3.88}, {"text": "there's a number of pu- pluses and minuses to decision trees.", "start": 2986.32, "duration": 3.835}, {"text": "Okay. So on the plus side, they're actually,", "start": 2990.155, "duration": 2.97}, {"text": "I think this is an important point is that they're actually", "start": 2993.125, "duration": 1.785}, {"text": "pretty easy to explain, right?", "start": 2994.91, "duration": 2.175}, {"text": "If you're explaining what a decision tree is to like a non-technical person,", "start": 2997.085, "duration": 4.395}, {"text": "it's fairly obvious you're like okay you have this tree,", "start": 3001.48, "duration": 1.89}, {"text": "you're just playing 20 Questions with your data", "start": 3003.37, "duration": 2.115}, {"text": "and letting it co- come up with one question at a time.", "start": 3005.485, "duration": 3.225}, {"text": "There are also interpretable,", "start": 3008.71, "duration": 2.115}, {"text": "you can just draw out the tree especially for", "start": 3010.825, "duration": 2.265}, {"text": "shorter trees to see exactly what it's doing.", "start": 3013.09, "duration": 5.5}, {"text": "It can deal with categorical variables,", "start": 3020.01, "duration": 3.859}, {"text": "and it's generally pretty fast.", "start": 3029.67, "duration": 3.32}, {"text": "However, on the negative side,", "start": 3035.73, "duration": 3.595}, {"text": "one that I alluded to is that they're", "start": 3039.325, "duration": 2.685}, {"text": "fairly high variance models and so are oftentimes prone to overfitting your data.", "start": 3042.01, "duration": 6.91}, {"text": "They're bad at additive structure.", "start": 3051.09, "duration": 3.65}, {"text": "And then finally they have,", "start": 3060.75, "duration": 2.965}, {"text": "because in large part because of these first two,", "start": 3063.715, "duration": 3.225}, {"text": "they generally have fairly low predictive accuracy.", "start": 3066.94, "duration": 2.88}, {"text": "[NOISE] I know what you guys are thinking,", "start": 3069.82, "duration": 6.84}, {"text": "I just spent all this time talking about", "start": 3076.66, "duration": 1.23}, {"text": "decision trees and then I tell you guys they actually sort of suck.", "start": 3077.89, "duration": 2.07}, {"text": "So why did I actually cover decision trees?", "start": 3079.96, "duration": 2.46}, {"text": "And the answer is that in fact you can make decision trees a lot better through ensembling.", "start": 3082.42, "duration": 5.76}, {"text": "And a lot of the methods,", "start": 3088.18, "duration": 1.455}, {"text": "for example at the leading methods in Kaggle these days are", "start": 3089.635, "duration": 2.715}, {"text": "actually built on ensembles of decision trees,", "start": 3092.35, "duration": 3.045}, {"text": "and they really provide an ideal sort of model framework to look at,", "start": 3095.395, "duration": 3.6}, {"text": "through which we can examine a lot of these different ensembling methods.", "start": 3098.995, "duration": 3.835}, {"text": "Any questions about decision trees before I move on?", "start": 3103.11, "duration": 3.49}, {"text": "[NOISE] Yeah?", "start": 3106.6, "duration": 1.86}, {"text": "[inaudible].", "start": 3108.46, "duration": 6.15}, {"text": "I don't think that's strictly- Okay.", "start": 3114.61, "duration": 2.145}, {"text": "So the question is for the cross-entropy loss,", "start": 3116.755, "duration": 3.435}, {"text": "does the log need to be base 2?", "start": 3120.19, "duration": 1.59}, {"text": "And the answer is I'm pretty sure that it's not very relevant in this case,", "start": 3121.78, "duration": 4.455}, {"text": "I'm not 100% sure about that but I'm", "start": 3126.235, "duration": 1.545}, {"text": "pretty sure that the base of the log of that makes,", "start": 3127.78, "duration": 1.785}, {"text": "it's cross entropy loss actually initially came out of like information theory,", "start": 3129.565, "duration": 3.375}, {"text": "we have like computer bits and you're transmitting bits.", "start": 3132.94, "duration": 2.31}, {"text": "So it's useful to think in terms of bits of information that you can transmit,", "start": 3135.25, "duration": 3.735}, {"text": "which is why it came up as log base 2 in the initial formulation.", "start": 3138.985, "duration": 4.035}, {"text": "[NOISE]", "start": 3143.02, "duration": 31.29}, {"text": "Okay. So now let's talk about ensembling.", "start": 3174.31, "duration": 3.28}, {"text": "Okay. So why does ensembling help?", "start": 3186.33, "duration": 4.765}, {"text": "At some level, you can sort of think back to your basic, uh, statistics.", "start": 3191.095, "duration": 3.645}, {"text": "So say you have, um, you have XIs,", "start": 3194.74, "duration": 4.395}, {"text": "XIs, which are random variables.", "start": 3199.135, "duration": 12.235}, {"text": "I'll sometimes write this as just RV, um,", "start": 3216.9, "duration": 5.68}, {"text": "that are independent and identically distributed.", "start": 3222.58, "duration": 15.615}, {"text": "And so probably a lot of you are familiar with this", "start": 3238.195, "duration": 2.535}, {"text": "already or you can call this IID, okay.", "start": 3240.73, "duration": 8.77}, {"text": "Now say that your variance of one of these variables is Sigma squared.", "start": 3250.17, "duration": 9.53}, {"text": "Then what you can show is that the variance of the mean of many of these variables.", "start": 3261.12, "duration": 7.18}, {"text": "So let's- of many of these random variables or written alternatively,", "start": 3268.3, "duration": 5.37}, {"text": "1 over N sum over I to the XI is equal to Sigma", "start": 3273.67, "duration": 8.34}, {"text": "squared over N. And so", "start": 3282.01, "duration": 3.735}, {"text": "each independent variable you factor in is", "start": 3285.745, "duration": 2.385}, {"text": "decreasing the variance of your model, all right?", "start": 3288.13, "duration": 4.245}, {"text": "And so the thought is that if you can factor in a number of independent sources,", "start": 3292.375, "duration": 5.115}, {"text": "you can slowly decrease your variance.", "start": 3297.49, "duration": 2.895}, {"text": "Okay, so, uh, so that- though this is", "start": 3300.385, "duration": 2.475}, {"text": "a little bit simplistic of a way of looking at this,", "start": 3302.86, "duration": 2.475}, {"text": "because really all these different things are factoring", "start": 3305.335, "duration": 1.935}, {"text": "together have some amount of correlation with each other.", "start": 3307.27, "duration": 2.325}, {"text": "And so this independence assumption is oftentimes not correct.", "start": 3309.595, "duration": 3.765}, {"text": "So if instead,", "start": 3313.36, "duration": 2.769}, {"text": "you drop the independence assumption.", "start": 3321.48, "duration": 3.86}, {"text": "So now your variables are just ID, right?", "start": 3337.89, "duration": 5.78}, {"text": "Okay. And say we can characterize what the correlation between", "start": 3351.03, "duration": 4.33}, {"text": "any two XIs is and we can write that down as Rho. So Xi.", "start": 3355.36, "duration": 18.81}, {"text": "Then you can actually write out the variance of", "start": 3374.17, "duration": 2.34}, {"text": "your mean as", "start": 3376.51, "duration": 5.49}, {"text": "Rho Sigma squared- Sigma squared,", "start": 3382.0, "duration": 6.795}, {"text": "plus 1 minus Rho over M or- no,", "start": 3388.795, "duration": 4.65}, {"text": "N Sigma squared, okay?", "start": 3393.445, "duration": 4.62}, {"text": "And so you can sort of see that if your correlation- if they're fully correlated,", "start": 3398.065, "duration": 3.24}, {"text": "then your- this term will drop to 0 and", "start": 3401.305, "duration": 2.295}, {"text": "that you'll just have Sigma squared again because adding", "start": 3403.6, "duration": 2.19}, {"text": "a bunch of fully correlated variables is just gonna give you", "start": 3405.79, "duration": 2.28}, {"text": "the original variable's variance versus if they're", "start": 3408.07, "duration": 2.91}, {"text": "completely decorrelated then this term drops to 0 and you", "start": 3410.98, "duration": 2.7}, {"text": "just end up with Sigma squared over N which gives you the initial,", "start": 3413.68, "duration": 2.955}, {"text": "uh, independent identically distributed equation.", "start": 3416.635, "duration": 5.1}, {"text": "And so in this case, really what you wanna do- the name of the game is,", "start": 3421.735, "duration": 4.035}, {"text": "you wanna have as many different models that you're", "start": 3425.77, "duration": 3.27}, {"text": "factoring as possible to increase this N which drives this term down.", "start": 3429.04, "duration": 3.54}, {"text": "And then on the other hand, you also want to make sure", "start": 3432.58, "duration": 2.19}, {"text": "those models are as decorrelated as possible so", "start": 3434.77, "duration": 2.43}, {"text": "that your Rho goes down and this first term goes down as well, okay?", "start": 3437.2, "duration": 5.71}, {"text": "And so this gives rise to a number of different ways to ensemble.", "start": 3455.31, "duration": 5.24}, {"text": "And one way you could think about doing this is you just use different algorithms, right?", "start": 3468.09, "duration": 6.56}, {"text": "This is actually what a lot of people in Kaggle, for example, will do,", "start": 3482.51, "duration": 4.0}, {"text": "is they'll just take a neural network or Random Forest, an SVM,", "start": 3486.51, "duration": 3.57}, {"text": "average them all together and generally that", "start": 3490.08, "duration": 2.53}, {"text": "actually works pretty well but- then you sort of have to", "start": 3492.61, "duration": 2.9}, {"text": "spend your time implementing all these separate algorithms", "start": 3495.51, "duration": 2.43}, {"text": "which is oftentimes not the most efficient use of your time.", "start": 3497.94, "duration": 3.875}, {"text": "Another one that people would like to do is just use different training sets.", "start": 3501.815, "duration": 6.675}, {"text": "Okay. And again, in this case,", "start": 3517.71, "duration": 2.95}, {"text": "like you probably spent a lot of effort collecting your initial training set,", "start": 3520.66, "duration": 3.3}, {"text": "you don't want your- like machine learning person to just come and recommend to you that,", "start": 3523.96, "duration": 3.795}, {"text": "just go collect a whole second training set", "start": 3527.755, "duration": 2.505}, {"text": "or something like that to improve your performance.", "start": 3530.26, "duration": 2.1}, {"text": "Like that's generally not the most helpful recommendation, okay?", "start": 3532.36, "duration": 4.68}, {"text": "And so then, what we're gonna cover now are", "start": 3537.04, "duration": 2.37}, {"text": "these two other methods that we use to do ensembling.", "start": 3539.41, "duration": 2.58}, {"text": "And one of them is called bagging,", "start": 3541.99, "duration": 2.56}, {"text": "which is sort of trying to approximate having different training sets.", "start": 3544.86, "duration": 5.41}, {"text": "We'll get into that quickly.", "start": 3550.27, "duration": 1.995}, {"text": "And then you also have boosting.", "start": 3552.265, "duration": 2.935}, {"text": "And just so that you guys will have a little bit of context,", "start": 3558.51, "duration": 3.43}, {"text": "we're gonna be using decision trees to talk a lot about these models;", "start": 3561.94, "duration": 3.015}, {"text": "and so bagging, you might have heard of random forests,", "start": 3564.955, "duration": 4.08}, {"text": "that's a variant of bagging for decision trees.", "start": 3569.035, "duration": 4.225}, {"text": "And then for boosting,", "start": 3573.6, "duration": 2.02}, {"text": "you might have heard of things like AdaBoost,", "start": 3575.62, "duration": 4.38}, {"text": "or XGBoost, which are variants of boosting for decision trees.", "start": 3580.0, "duration": 7.96}, {"text": "Okay, so that sort of covers at a high level what we would wanna do.", "start": 3590.94, "duration": 4.96}, {"text": "These first two are very nice because they're sort of would give us a much", "start": 3595.9, "duration": 2.97}, {"text": "more like independently correlated- or less correlated variables.", "start": 3598.87, "duration": 4.32}, {"text": "But generally, we're- we end up doing these latter two", "start": 3603.19, "duration": 3.18}, {"text": "because we don't want to collect new training sets or train entirely new algorithms.", "start": 3606.37, "duration": 4.125}, {"text": "Okay, so let's cover bagging first.", "start": 3610.495, "duration": 3.655}, {"text": "Okay, so bagging really stands for this thing.", "start": 3620.85, "duration": 3.475}, {"text": "It's called bootstrap aggregation, okay?", "start": 3624.325, "duration": 3.36}, {"text": "Um, and so- first,", "start": 3627.685, "duration": 13.725}, {"text": "let's just break down this term.", "start": 3641.41, "duration": 1.29}, {"text": "So bootstrap, what that is,", "start": 3642.7, "duration": 1.32}, {"text": "is it's typically this method used in statistics to measure", "start": 3644.02, "duration": 3.18}, {"text": "the uncertainty of your estimate, okay?", "start": 3647.2, "duration": 3.78}, {"text": "And so what- what is useful to define in this case for when you're talking about bagging", "start": 3650.98, "duration": 4.86}, {"text": "is you can say that you have", "start": 3655.84, "duration": 2.5}, {"text": "a true population P, okay?", "start": 3659.07, "duration": 8.74}, {"text": "And your training set- training", "start": 3667.81, "duration": 3.21}, {"text": "set S is sampled from P, right?", "start": 3671.02, "duration": 7.71}, {"text": "So you just start drawing a bunch of examples from", "start": 3678.73, "duration": 1.95}, {"text": "P and that's what forms your training set at some level.", "start": 3680.68, "duration": 2.82}, {"text": "And so ideally, like for example,", "start": 3683.5, "duration": 2.19}, {"text": "this different training set's approach.", "start": 3685.69, "duration": 1.95}, {"text": "What you do is, you just draw S1, S2,", "start": 3687.64, "duration": 2.1}, {"text": "S3, S4, and then train your model in each one of those separately.", "start": 3689.74, "duration": 2.955}, {"text": "Unfortunately, you generally don't have the time to do that.", "start": 3692.695, "duration": 3.165}, {"text": "And so what ba- what Bootstrapping does,", "start": 3695.86, "duration": 3.345}, {"text": "is you assume basically that your population is your training sample, okay?", "start": 3699.205, "duration": 8.945}, {"text": "So you assume that your population is your training sample.", "start": 3708.15, "duration": 2.475}, {"text": "And so now that you have this S is approximating your P,", "start": 3710.625, "duration": 4.005}, {"text": "then you can draw new samples from", "start": 3714.63, "duration": 2.91}, {"text": "your population by just drawing samples from S instead, okay?", "start": 3717.54, "duration": 3.9}, {"text": "So you have bootstrap samples, is what they're called.", "start": 3721.44, "duration": 5.11}, {"text": "Z sampled from S. And so how that", "start": 3731.04, "duration": 4.84}, {"text": "works is you basically just take your train- your- your training sample, okay?", "start": 3735.88, "duration": 4.41}, {"text": "Say it's of like cardinality N or something.", "start": 3740.29, "duration": 2.415}, {"text": "And you just sample N times from S and this is important,", "start": 3742.705, "duration": 3.615}, {"text": "you do it with replacement.", "start": 3746.32, "duration": 1.68}, {"text": "Because they're pretending that this is the population,", "start": 3748.0, "duration": 2.31}, {"text": "and so doing it with replacement sort of makes that assumption", "start": 3750.31, "duration": 2.97}, {"text": "hold that you're sampling from it as a population.", "start": 3753.28, "duration": 4.0}, {"text": "Okay, so that's bootstrapping.", "start": 3758.81, "duration": 2.41}, {"text": "So you generate all these different bootstrap samples Z on your- from your training set.", "start": 3761.22, "duration": 5.88}, {"text": "And what you can do is you can take your model and", "start": 3767.1, "duration": 2.1}, {"text": "train it on all these separate bootstrap samples,", "start": 3769.2, "duration": 2.765}, {"text": "and then you can sort of look at the variability in", "start": 3771.965, "duration": 2.915}, {"text": "the predictions that your model ends up", "start": 3774.88, "duration": 1.62}, {"text": "making based on these different bootstrap samples.", "start": 3776.5, "duration": 2.46}, {"text": "And that gives you sort of a measure of uncertainty.", "start": 3778.96, "duration": 2.715}, {"text": "I'm not gonna go into too much detail now because that's", "start": 3781.675, "duration": 2.295}, {"text": "not actually what we're gonna use Bootstrapping for.", "start": 3783.97, "duration": 2.415}, {"text": "What we want to use bootstrapping for is we wanna aggregate these two Bootstrap samples.", "start": 3786.385, "duration": 4.665}, {"text": "And so at a very high level,", "start": 3791.05, "duration": 1.59}, {"text": "what that means is we're gonna take a bunch of Bootstrap samples,", "start": 3792.64, "duration": 3.09}, {"text": "train separate models on each and then average their outputs, okay?", "start": 3795.73, "duration": 5.95}, {"text": "So let's make that a little bit more formal.", "start": 3802.23, "duration": 2.95}, {"text": "[NOISE]", "start": 3805.18, "duration": 21.715}, {"text": "So you have bootstrap samples", "start": 3826.895, "duration": 12.375}, {"text": "Z_1 through Z_M say, okay, capital M.", "start": 3839.27, "duration": 4.21}, {"text": "That's just say how many bootstrap samples you're going to take.", "start": 3843.55, "duration": 4.165}, {"text": "Okay, you train [NOISE] a model,", "start": 3847.715, "duration": 7.045}, {"text": "G_M, okay, on Z_M, okay?", "start": 3856.18, "duration": 4.22}, {"text": "Then all you're doing is you're just defining this new sort of meta model.", "start": 3865.54, "duration": 5.44}, {"text": "I'm not putting a subscript on this one to show that it's a meta model, T of M,", "start": 3870.98, "duration": 4.425}, {"text": "which is just the sum of your predictions of your individual models,", "start": 3875.405, "duration": 7.755}, {"text": "divided by the total number of models you have, all right?", "start": 3883.16, "duration": 3.645}, {"text": "And this is just me writing out what I was sort of talking about right up there for bagging.", "start": 3886.805, "duration": 7.395}, {"text": "If you're taking these bootstrap samples and then you're training separate models,", "start": 3894.2, "duration": 3.96}, {"text": "and then you're just aggregating them all together to get this bagging approach.", "start": 3898.16, "duration": 4.51}, {"text": "So if we just do a little bit of analysis from the bias-variance perspective on this,", "start": 3906.79, "duration": 5.335}, {"text": "we can sort of see why this kind of thing might work.", "start": 3912.125, "duration": 2.715}, {"text": "[NOISE]", "start": 3914.84, "duration": 13.38}, {"text": "And so you recall we had this equation up here, right?", "start": 3928.22, "duration": 2.355}, {"text": "The va- variance of the mean is rho sigma squared,", "start": 3930.575, "duration": 3.225}, {"text": "plus 1 minus rho,", "start": 3933.8, "duration": 1.335}, {"text": "over n of sigma squared.", "start": 3935.135, "duration": 1.695}, {"text": "So let me just write that out here.", "start": 3936.83, "duration": 1.2}, {"text": "[NOISE]", "start": 3938.03, "duration": 11.64}, {"text": "And in this case,", "start": 3949.67, "duration": 0.75}, {"text": "our M is actually really uh,", "start": 3950.42, "duration": 2.16}, {"text": "just the number of bootstrap samples.", "start": 3952.58, "duration": 1.35}, {"text": "So we'll just use big M in this case.", "start": 3953.93, "duration": 2.74}, {"text": "And what you're doing is by taking these bootstrap samples,", "start": 3957.67, "duration": 3.16}, {"text": "you're sort of decorrelating the models you're training.", "start": 3960.83, "duration": 2.55}, {"text": "Your bootstrapping [NOISE] is", "start": 3963.38, "duration": 7.68}, {"text": "driving down [NOISE] rho.", "start": 3971.06, "duration": 6.09}, {"text": "Okay. And so by driving this down,", "start": 3977.15, "duration": 5.84}, {"text": "you're sort of making this term get smaller and smaller.", "start": 3982.99, "duration": 2.04}, {"text": "And then your question might be okay,", "start": 3985.03, "duration": 1.08}, {"text": "what about this term here?", "start": 3986.11, "duration": 1.245}, {"text": "And it turns out that basically you can take as many bootstrap samples as you want,", "start": 3987.355, "duration": 5.515}, {"text": "and that will slowly drive down- it increases M and drive down this second term.", "start": 3992.87, "duration": 4.98}, {"text": "And it turns out that one nice thing about bootstrapping,", "start": 3997.85, "duration": 3.075}, {"text": "is that increasing the number of bootstrap models in your training,", "start": 4000.925, "duration": 4.44}, {"text": "doesn't actually cause you to overfit anymore than you were beforehand.", "start": 4005.365, "duration": 4.41}, {"text": "Because all you're doing, is you're driving down this term here.", "start": 4009.775, "duration": 3.525}, {"text": "So more M [NOISE] and it's just less in variance.", "start": 4013.3, "duration": 5.76}, {"text": "[NOISE] All you're doing", "start": 4019.06, "duration": 4.92}, {"text": "is driving down the second term as much", "start": 4023.98, "duration": 2.13}, {"text": "as possible when you're getting more and more bootstrap samples.", "start": 4026.11, "duration": 2.19}, {"text": "So generally, it only improves performance.", "start": 4028.3, "duration": 1.905}, {"text": "And so generally what people will do is they'll sample", "start": 4030.205, "duration": 2.265}, {"text": "more and more models until they see that their error stops going down.", "start": 4032.47, "duration": 3.315}, {"text": "Because that means they basically eliminated this term over here.", "start": 4035.785, "duration": 3.915}, {"text": "So this seems kinda nice, right?", "start": 4039.7, "duration": 3.69}, {"text": "You're decreasing the variance, where is the trade-off coming in? Oh, there is a question there.", "start": 4043.39, "duration": 4.02}, {"text": "[inaudible].", "start": 4047.41, "duration": 5.94}, {"text": "Yeah, there's definitely a bound, right?", "start": 4053.35, "duration": 1.275}, {"text": "Because um, I'm not going to define one formally right now.", "start": 4054.625, "duration": 4.59}, {"text": "Oh, the question is can you define a bound on how much you decrease rho by?", "start": 4059.215, "duration": 4.245}, {"text": "Uh, I'm not- yeah,", "start": 4063.46, "duration": 1.62}, {"text": "so there's definitely a lower bound [NOISE] or, oh yeah,", "start": 4065.08, "duration": 3.615}, {"text": "a lower bound on how far you can decrease rho.", "start": 4068.695, "duration": 3.235}, {"text": "Basically it comes down to your bootstrap samples are still", "start": 4072.42, "duration": 3.25}, {"text": "fairly highly correlated with one another, all right.", "start": 4075.67, "duration": 2.73}, {"text": "Because they're still just drawing it from the same sample set S. Really,", "start": 4078.4, "duration": 4.185}, {"text": "your Z is gonna end up containing about two- each Z is going to contain", "start": 4082.585, "duration": 3.285}, {"text": "about two thirds of S. And so", "start": 4085.87, "duration": 1.92}, {"text": "your Zs are still gonna be fairly highly correlated with each other.", "start": 4087.79, "duration": 2.595}, {"text": "And no, I don't have a formal equation to write down as to", "start": 4090.385, "duration": 2.475}, {"text": "exactly how much that decreases rho by,", "start": 4092.86, "duration": 2.55}, {"text": "or how much that bounds rho by,", "start": 4095.41, "duration": 1.35}, {"text": "you can sort of see intuitively that there is a bound there and that you can't just", "start": 4096.76, "duration": 4.23}, {"text": "magically decrease rho all the way down to 0 and achieve 0 variance.", "start": 4100.99, "duration": 4.32}, {"text": "[NOISE] All right.", "start": 4105.31, "duration": 4.53}, {"text": "So saying that you decrease variance,", "start": 4109.84, "duration": 2.22}, {"text": "that seems very nice.", "start": 4112.06, "duration": 1.305}, {"text": "One issue that comes up with, with uh,", "start": 4113.365, "duration": 2.7}, {"text": "bootstrapping is that in fact you're actually slightly", "start": 4116.065, "duration": 2.265}, {"text": "increasing the bias of your models when you're doing this.", "start": 4118.33, "duration": 3.39}, {"text": "And the reasoning for that", "start": 4121.72, "duration": 1.95}, {"text": "[NOISE] is because of", "start": 4123.67, "duration": 9.08}, {"text": "this sub-sampling that I was talking about here.", "start": 4132.75, "duration": 2.025}, {"text": "Each one of your Zs is now about two-thirds of the", "start": 4134.775, "duration": 2.595}, {"text": "original S. So you're training on less data um,", "start": 4137.37, "duration": 3.12}, {"text": "and so your models are becoming slightly less uh, you know,", "start": 4140.49, "duration": 3.12}, {"text": "complex and so that increases your bias in this case. Yes.", "start": 4143.61, "duration": 4.24}, {"text": "[inaudible]", "start": 4147.85, "duration": 7.02}, {"text": "Yeah, for sure. Um, so the question is,", "start": 4154.87, "duration": 3.6}, {"text": "can you explain the difference between", "start": 4158.47, "duration": 1.875}, {"text": "a random variable and an algorithm in this case, right?", "start": 4160.345, "duration": 2.7}, {"text": "And so you could sorta- at a, at a very high level,", "start": 4163.045, "duration": 2.745}, {"text": "you can think of an algorithm as a classifier- as", "start": 4165.79, "duration": 2.34}, {"text": "a function that's taking in some data and making a prediction.", "start": 4168.13, "duration": 3.315}, {"text": "Right? And if you sort of see those- that whole setup as", "start": 4171.445, "duration": 4.455}, {"text": "sort of like, the probability, the algorithm is", "start": 4175.9, "duration": 1.875}, {"text": "giving some sort of output in the probabilistic perspective,", "start": 4177.775, "duration": 2.505}, {"text": "you can sort of see the algorithm as like a random variable in the case- in this case.", "start": 4180.28, "duration": 5.385}, {"text": "Sort of like, you're basically considering,", "start": 4185.665, "duration": 2.88}, {"text": "sort of the space of possible predictions that", "start": 4188.545, "duration": 2.655}, {"text": "your algorithm can make and that you can sort of see as", "start": 4191.2, "duration": 2.43}, {"text": "a distribution of possible predictions", "start": 4193.63, "duration": 2.64}, {"text": "and that you can approximate that as a random variable.", "start": 4196.27, "duration": 2.865}, {"text": "I mean it is a random variable at some level,", "start": 4199.135, "duration": 1.86}, {"text": "because it's sort of like based on what's training sample you end up with,", "start": 4200.995, "duration": 4.38}, {"text": "your predictions of your output model are gonna change.", "start": 4205.375, "duration": 3.48}, {"text": "And so since you're sampling sort of these random samples from your population set,", "start": 4208.855, "duration": 4.875}, {"text": "you can consider your algorithm as sort of based", "start": 4213.73, "duration": 2.895}, {"text": "on that random sample and therefore a random variable itself.", "start": 4216.625, "duration": 4.015}, {"text": "Okay. So yeah, your bias is slightly increased because [NOISE] of random subsampling,", "start": 4221.97, "duration": 10.18}, {"text": "[NOISE] but generally,", "start": 4232.15, "duration": 9.105}, {"text": "the decrease in variance that you get from doing this,", "start": 4241.255, "duration": 3.045}, {"text": "is much larger than the slight increase in bias you get from,", "start": 4244.3, "duration": 3.48}, {"text": "from doing this randomized subsampling.", "start": 4247.78, "duration": 2.01}, {"text": "So in a lot of cases,", "start": 4249.79, "duration": 1.17}, {"text": "bagging is quite nice.", "start": 4250.96, "duration": 1.41}, {"text": "[NOISE] Okay?", "start": 4252.37, "duration": 2.14}, {"text": "So I've talked a bit about ba- about bagging,", "start": 4268.23, "duration": 4.525}, {"text": "uh, let's talk about decision trees plus bagging now.", "start": 4272.755, "duration": 3.385}, {"text": "Okay. So you recall that decision trees are", "start": 4283.29, "duration": 3.67}, {"text": "high [NOISE] variance,", "start": 4286.96, "duration": 4.45}, {"text": "low bias okay?", "start": 4295.83, "duration": 3.775}, {"text": "And this right here sort of explains why they're a pretty good fit for bagging.", "start": 4299.605, "duration": 4.11}, {"text": "Okay? Because bagging what you're doing,", "start": 4303.715, "duration": 1.575}, {"text": "is you're decreasing the variance of your models for a slight increase in bias.", "start": 4305.29, "duration": 4.215}, {"text": "And since most of your error from", "start": 4309.505, "duration": 1.965}, {"text": "your decision trees is coming from the high variance side of things,", "start": 4311.47, "duration": 3.27}, {"text": "by sort of driving down that variance,", "start": 4314.74, "duration": 2.22}, {"text": "you get a lot more benefit than for a,", "start": 4316.96, "duration": 2.37}, {"text": "a model that would be on the reverse high bias and low variance.", "start": 4319.33, "duration": 4.02}, {"text": "Okay? So, so this makes this like an ideal fit [NOISE] for bagging.", "start": 4323.35, "duration": 7.17}, {"text": "[NOISE]", "start": 4330.52, "duration": 14.055}, {"text": "Okay. [NOISE] So now,", "start": 4344.575, "duration": 2.025}, {"text": "um, this is sort of decision trees plus bagging.", "start": 4346.6, "duration": 3.0}, {"text": "I said that random forests are sort of a version of decision trees plus bagging.", "start": 4349.6, "duration": 4.86}, {"text": "And so what I've described here is actually almost a random forest at this point.", "start": 4354.46, "duration": 4.365}, {"text": "The one key point we're still missing is that random forests", "start": 4358.825, "duration": 3.735}, {"text": "actually introduce even more randomization into each individual decision tree.", "start": 4362.56, "duration": 4.185}, {"text": "And the idea behind that is that- as I had a question from before is this Rho,", "start": 4366.745, "duration": 5.235}, {"text": "you can only drive it down so far through just pure bootstrapping.", "start": 4371.98, "duration": 3.6}, {"text": "But if you can further decorrelate your different random variables,", "start": 4375.58, "duration": 3.27}, {"text": "then you can drive down that variance even further, okay?", "start": 4378.85, "duration": 3.54}, {"text": "Um, and so the idea there is that basically for- at each split for random forests,", "start": 4382.39, "duration": 8.139}, {"text": "at each split, you consider only a fraction", "start": 4398.46, "duration": 11.26}, {"text": "of your total features, right?", "start": 4409.72, "duration": 11.32}, {"text": "So it's sort of like, for that ski example,", "start": 4425.85, "duration": 2.62}, {"text": "maybe like for the first split,", "start": 4428.47, "duration": 1.41}, {"text": "I only let it look at latitude, and then for the second split,", "start": 4429.88, "duration": 2.55}, {"text": "I only let it look at,", "start": 4432.43, "duration": 2.145}, {"text": "uh, the time of the year.", "start": 4434.575, "duration": 1.635}, {"text": "[NOISE] And so this might seem a little bit unintuitive at first,", "start": 4436.21, "duration": 3.78}, {"text": "but you can sort of get the intuition from two ways.", "start": 4439.99, "duration": 2.1}, {"text": "One is that you're decreasing", "start": 4442.09, "duration": 1.259}, {"text": "Rho and then the other one", "start": 4443.349, "duration": 8.056}, {"text": "is you can think that- say you have a classification example,", "start": 4451.405, "duration": 3.135}, {"text": "where you have one very strong predictor that gets you very good performance on its own.", "start": 4454.54, "duration": 4.89}, {"text": "And regardless of what bootstrap sample you select,", "start": 4459.43, "duration": 2.28}, {"text": "your model is probably gonna use that predictor as its first split.", "start": 4461.71, "duration": 3.195}, {"text": "That's gonna cause all your models to be very highly", "start": 4464.905, "duration": 2.265}, {"text": "correlated right at that first split, for example,", "start": 4467.17, "duration": 2.31}, {"text": "and by instead forcing it to,", "start": 4469.48, "duration": 2.67}, {"text": "to sample from different features.", "start": 4472.15, "duration": 2.19}, {"text": "Instead, that's going to increase the,", "start": 4474.34, "duration": 2.61}, {"text": "uh, or decrease the correlation between your models.", "start": 4476.95, "duration": 2.73}, {"text": "And so it's all about decorrelating your models in this case.", "start": 4479.68, "duration": 3.48}, {"text": "[NOISE] Okay.", "start": 4483.16, "duration": 9.765}, {"text": "And that sort of brings to a close a lot of our discussion of bagging.", "start": 4492.925, "duration": 3.03}, {"text": "Are there any questions regarding bagging?", "start": 4495.955, "duration": 2.905}, {"text": "Okay. Now, I've covered bagging.", "start": 4500.7, "duration": 6.22}, {"text": "Let's get a little bit into boosting.", "start": 4506.92, "duration": 2.94}, {"text": "[NOISE] And I'll make this quick.", "start": 4509.86, "duration": 7.065}, {"text": "But basically, whereas bagging we sort of saw in the intuition that", "start": 4516.925, "duration": 7.095}, {"text": "we were decreasing variance,", "start": 4524.02, "duration": 2.34}, {"text": "boosting is sort of actually more of the opposite where", "start": 4526.36, "duration": 2.37}, {"text": "you're decreasing the bias of your models, okay?", "start": 4528.73, "duration": 3.075}, {"text": "So- [NOISE]", "start": 4531.805, "duration": 11.655}, {"text": "and also it- it's basically,", "start": 4543.46, "duration": 1.904}, {"text": "um, more additive in,", "start": 4545.364, "duration": 2.656}, {"text": "um, in how it's doing things.", "start": 4548.02, "duration": 1.74}, {"text": "So versus- [NOISE] you'll recall that for bagging,", "start": 4549.76, "duration": 5.88}, {"text": "you were taking the average of a number of variables.", "start": 4555.64, "duration": 2.28}, {"text": "In boosting, what happens,", "start": 4557.92, "duration": 1.14}, {"text": "you train one model and then you add that prediction into your ensemble.", "start": 4559.06, "duration": 3.495}, {"text": "And then when you turn a new model, you just add that in as a prediction.", "start": 4562.555, "duration": 3.165}, {"text": "And so- and that's a little bit handwavy right now.", "start": 4565.72, "duration": 2.025}, {"text": "So let me actually make that clear through an example.", "start": 4567.745, "duration": 3.045}, {"text": "[NOISE] So say you have a dataset, again, X1,", "start": 4570.79, "duration": 6.255}, {"text": "X2, X2 and you have some data points,", "start": 4577.045, "duration": 4.695}, {"text": "maybe some- that's actually- just call them pluses and minuses.", "start": 4581.74, "duration": 5.28}, {"text": "So you have some more pluses here,", "start": 4587.02, "duration": 2.91}, {"text": "and then maybe a couple of minuses and some pluses here, okay?", "start": 4589.93, "duration": 5.58}, {"text": "And what you- say you're training a size one decision tree.", "start": 4595.51, "duration": 3.48}, {"text": "So decision stumps is what we call them.", "start": 4598.99, "duration": 2.67}, {"text": "And so you only get to ask one question at a time.", "start": 4601.66, "duration": 2.79}, {"text": "And the reason behind this,", "start": 4604.45, "duration": 1.47}, {"text": "just really quickly is that because you're decreasing bias", "start": 4605.92, "duration": 2.685}, {"text": "by restricting your trees to be only depth 1,", "start": 4608.605, "duration": 3.45}, {"text": "you basically are increasing", "start": 4612.055, "duration": 2.19}, {"text": "their amount of bias and decreasing their amount of variance,", "start": 4614.245, "duration": 2.025}, {"text": "which makes them a better fit for boosting kind of methods.", "start": 4616.27, "duration": 3.105}, {"text": "And say that you come up with a,", "start": 4619.375, "duration": 2.64}, {"text": "a decision boundary, okay?", "start": 4622.015, "duration": 1.395}, {"text": "Say this one here, okay?", "start": 4623.41, "duration": 3.24}, {"text": "And what you're gonna do is, on this side you predict positive, right?", "start": 4626.65, "duration": 3.915}, {"text": "And on this side you predict negative.", "start": 4630.565, "duration": 1.32}, {"text": "There's like a reasonable like line that you could draw here,", "start": 4631.885, "duration": 2.745}, {"text": "but it's not perfect, right?", "start": 4634.63, "duration": 1.05}, {"text": "You've made some mistakes.", "start": 4635.68, "duration": 1.05}, {"text": "And in fact, what you can do is you can sort of identify these mistakes.", "start": 4636.73, "duration": 4.625}, {"text": "Now, if we draw this in red, right?", "start": 4641.355, "duration": 3.145}, {"text": "You've got- made these guys as mistakes.", "start": 4644.5, "duration": 2.415}, {"text": "And what boosting does is basically it increases the weights of the mistakes you've made.", "start": 4646.915, "duration": 6.465}, {"text": "And then for the next out- uh,", "start": 4653.38, "duration": 1.725}, {"text": "decision stump that you train,", "start": 4655.105, "duration": 1.8}, {"text": "it's now trained on this modified set.", "start": 4656.905, "duration": 2.145}, {"text": "Which we could, let's just draw it over here.", "start": 4659.05, "duration": 3.22}, {"text": "One. [NOISE] And so now you- these positives,", "start": 4665.34, "duration": 5.59}, {"text": "I'll just draw them much bigger.", "start": 4670.93, "duration": 1.35}, {"text": "You know, you've got big positives here and some small negatives,", "start": 4672.28, "duration": 3.18}, {"text": "and some small positives,", "start": 4675.46, "duration": 1.815}, {"text": "some big negatives here.", "start": 4677.275, "duration": 2.725}, {"text": "And so now your model, to try and get these right,", "start": 4680.22, "duration": 3.22}, {"text": "might pick a decision boundary like this, right?", "start": 4683.44, "duration": 3.18}, {"text": "And this is also basically recursive in that each step, right?", "start": 4686.62, "duration": 3.99}, {"text": "You're gonna be reweighting each of the examples based on how many of", "start": 4690.61, "duration": 2.58}, {"text": "your previous ones have gotten it wrong or right in the past.", "start": 4693.19, "duration": 4.17}, {"text": "[NOISE] And so basically what you're", "start": 4697.36, "duration": 4.08}, {"text": "doing is you can sort of weight each one of these classifiers.", "start": 4701.44, "duration": 4.485}, {"text": "You can determine", "start": 4705.925, "duration": 1.035}, {"text": "[NOISE]", "start": 4706.96, "duration": 5.85}, {"text": "for classifier Gm,", "start": 4712.81, "duration": 7.17}, {"text": "a weight Alpha m,", "start": 4719.98, "duration": 4.78}, {"text": "which is proportional to how many examples you got wrong or right.", "start": 4724.77, "duration": 4.54}, {"text": "So a better classifier, you wanna give it more weight, um, and,", "start": 4729.31, "duration": 3.99}, {"text": "uh, a bad classifier you wanna give it less weight proportional.", "start": 4733.3, "duration": 5.38}, {"text": "And, uh, I think that the exact equation used in AdaBoost, for example,", "start": 4739.71, "duration": 5.11}, {"text": "is just log of 1 minus the error", "start": 4744.82, "duration": 4.304}, {"text": "of your nth model divided with basically log odds, okay?", "start": 4749.124, "duration": 5.251}, {"text": "And then your total classifier is just F of- or let's just call it G of x again.", "start": 4754.375, "duration": 5.145}, {"text": "G of x is just the sum over m of Alpha m,", "start": 4759.52, "duration": 9.465}, {"text": "G of m, right?", "start": 4768.985, "duration": 3.15}, {"text": "And then each G of m is trained", "start": 4772.135, "duration": 2.325}, {"text": "on a weighted- on a reweighted,", "start": 4774.46, "duration": 13.23}, {"text": "actually, reweighted training set.", "start": 4787.69, "duration": 5.62}, {"text": "And so I've glossed over a lot of the details here in interest of time,", "start": 4796.08, "duration": 4.045}, {"text": "but the specifics of an algorithm like this are- will be in the lecture notes.", "start": 4800.125, "duration": 5.565}, {"text": "And this algorithm is actually known as AdaBoost.", "start": 4805.69, "duration": 3.0}, {"text": "[NOISE] And basically through similar techniques,", "start": 4808.69, "duration": 5.025}, {"text": "you can derive algorithms such as XGBoost", "start": 4813.715, "duration": 2.925}, {"text": "or gradient boosting machines that also allow you to", "start": 4816.64, "duration": 3.6}, {"text": "basically reweight the examples you're getting right", "start": 4820.24, "duration": 2.175}, {"text": "or wrong in this sort of dynamic fashion", "start": 4822.415, "duration": 2.235}, {"text": "and slowly adding them in this additive fashion to your composite model.", "start": 4824.65, "duration": 4.44}, {"text": "[NOISE] And that about finishes it for today.", "start": 4829.09, "duration": 2.88}, {"text": "Uh, thanks for coming.", "start": 4831.97, "duration": 0.96}, {"text": "Um, yeah, a great rest of your week.", "start": 4832.93, "duration": 4.21}]