[{"text": "Hi, I\u2019m Carrie Anne and welcome to CrashCourse\nComputer Science!", "start": 2.98, "duration": 3.02}, {"text": "As we\u2019ve discussed throughout the series,\ncomputers have come a long way from mechanical", "start": 6.0, "duration": 3.71}, {"text": "devices capable of maybe one calculation per second, to CPUs running at kilohertz and megahertz speeds.", "start": 9.71, "duration": 5.49}, {"text": "The device you\u2019re watching this video on\nright now is almost certainly running at Gigahertz", "start": 15.36, "duration": 3.86}, {"text": "speeds - that\u2019s billions of instructions\nexecuted every second.", "start": 19.22, "duration": 3.39}, {"text": "Which, trust me, is a lot of computation!", "start": 22.61, "duration": 2.37}, {"text": "In the early days of electronic computing,\nprocessors were typically made faster by improving", "start": 24.98, "duration": 3.99}, {"text": "the switching time of the transistors inside\nthe chip - the ones that make up all the logic", "start": 28.97, "duration": 4.17}, {"text": "gates, ALUs and other stuff we\u2019ve talked\nabout over the past few episodes.", "start": 33.14, "duration": 3.3}, {"text": "But just making transistors faster and more\nefficient only went so far, so processor designers", "start": 36.44, "duration": 4.639}, {"text": "have developed various techniques to boost\nperformance allowing not only simple instructions", "start": 41.079, "duration": 4.461}, {"text": "to run fast, but also performing much more\nsophisticated operations.", "start": 45.54, "duration": 3.76}, {"text": "INTRO", "start": 49.3, "duration": 9.18}, {"text": "Last episode, we created a small program for\nour CPU that allowed us to divide two numbers.", "start": 58.48, "duration": 5.2}, {"text": "We did this by doing many subtractions in\na row... so, for example, 16 divided by 4", "start": 63.69, "duration": 4.55}, {"text": "could be broken down into the smaller problem\nof 16 minus 4, minus 4, minus 4, minus 4.", "start": 68.25, "duration": 5.52}, {"text": "When we hit zero, or a negative number, we\nknew that we we\u2019re done.", "start": 73.77, "duration": 3.549}, {"text": "But this approach gobbles up a lot of clock\ncycles, and isn\u2019t particularly efficient.", "start": 77.319, "duration": 3.55}, {"text": "So most computer processors today have divide\nas one of the instructions that the ALU can", "start": 80.869, "duration": 4.151}, {"text": "perform in hardware.", "start": 85.02, "duration": 1.299}, {"text": "Of course, this extra circuitry makes the\nALU bigger and more complicated to design,", "start": 86.32, "duration": 4.42}, {"text": "but also more capable - a complexity-for-speed\ntradeoff that has been made many times in", "start": 90.74, "duration": 4.68}, {"text": "computing history.", "start": 95.42, "duration": 1.0}, {"text": "For instance, modern computer processors now\nhave special circuits for things like graphics", "start": 96.42, "duration": 4.269}, {"text": "operations, decoding compressed video, and\nencrypting files - all of which are operations", "start": 100.689, "duration": 4.5}, {"text": "that would take many many many clock cycles\nto perform with standard operations.", "start": 105.189, "duration": 3.61}, {"text": "You may have even heard of processors with\nMMX, 3DNow!, or SSE.", "start": 108.8, "duration": 4.62}, {"text": "These are processors with additional, fancy\ncircuits that allow them to execute additional,", "start": 113.42, "duration": 4.24}, {"text": "fancy instructions - for things like gaming\nand encryption.", "start": 117.67, "duration": 3.13}, {"text": "These extensions to the instruction set have\ngrown, and grown over time, and once people", "start": 120.81, "duration": 3.599}, {"text": "have written programs to take advantage of\nthem, it\u2019s hard to remove them.", "start": 124.409, "duration": 3.45}, {"text": "So instruction sets tend to keep getting larger\nand larger keeping all the old opcodes around", "start": 127.859, "duration": 4.371}, {"text": "for backwards compatibility.", "start": 132.23, "duration": 1.42}, {"text": "The Intel 4004, the first truly integrated\nCPU, had 46 instructions - which was enough", "start": 133.65, "duration": 6.08}, {"text": "to build a fully functional computer.", "start": 139.73, "duration": 1.86}, {"text": "But a modern computer processor has thousands\nof different instructions, which utilize all", "start": 141.59, "duration": 4.52}, {"text": "sorts of clever and complex internal circuitry.", "start": 146.11, "duration": 2.439}, {"text": "Now, high clock speeds and fancy instruction\nsets lead to another problem - getting data", "start": 148.549, "duration": 5.16}, {"text": "in and out of the CPU quickly enough.", "start": 153.709, "duration": 1.851}, {"text": "It\u2019s like having a powerful steam locomotive,\nbut no way to shovel in coal fast enough.", "start": 155.56, "duration": 4.959}, {"text": "In this case, the bottleneck is RAM.", "start": 160.519, "duration": 1.8}, {"text": "RAM is typically a memory module that lies\noutside the CPU.", "start": 162.319, "duration": 3.37}, {"text": "This means that data has to be transmitted\nto and from RAM along sets of data wires,", "start": 165.689, "duration": 3.92}, {"text": "called a bus.", "start": 169.609, "duration": 1.341}, {"text": "This bus might only be a few centimeters long,\nand remember those electrical signals are", "start": 170.95, "duration": 3.5}, {"text": "traveling near the speed of light, but when\nyou are operating at gigahertz speeds \u2013 that\u2019s", "start": 174.45, "duration": 3.88}, {"text": "billionths of a second \u2013 even this small\ndelay starts to become problematic.", "start": 178.33, "duration": 4.57}, {"text": "It also takes time for RAM itself to lookup\nthe address, retrieve the data, and configure", "start": 182.9, "duration": 4.13}, {"text": "itself for output.", "start": 187.03, "duration": 1.41}, {"text": "So a \u201cload from RAM\u201d instruction might take\ndozens of clock cycles to complete, and during", "start": 188.46, "duration": 4.05}, {"text": "this time the processor is just sitting there\nidly waiting for the data.", "start": 192.51, "duration": 3.53}, {"text": "One solution is to put a little piece of RAM\nright on the CPU -- called a cache.", "start": 196.04, "duration": 4.27}, {"text": "There isn\u2019t a lot of space on a processor\u2019s\nchip, so most caches are just kilobytes or", "start": 200.31, "duration": 3.58}, {"text": "maybe megabytes in size, where RAM is usually\ngigabytes.", "start": 203.89, "duration": 3.41}, {"text": "Having a cache speeds things up in a clever\nway.", "start": 207.3, "duration": 2.22}, {"text": "When the CPU requests a memory location from\nRAM, the RAM can transmit not just one single", "start": 209.53, "duration": 4.95}, {"text": "value, but a whole block of data.", "start": 214.499, "duration": 2.07}, {"text": "This takes only a little bit more time than\ntransmitting a single value, but it allows", "start": 216.569, "duration": 2.09}, {"text": "this data block to be saved into the cache.", "start": 218.659, "duration": 2.521}, {"text": "This tends to be really useful because computer\ndata is often arranged and processed sequentially.", "start": 221.18, "duration": 4.74}, {"text": "For example, let say the processor is totalling\nup daily sales for a restaurant.", "start": 225.92, "duration": 4.319}, {"text": "It starts by fetching the first transaction\nfrom RAM at memory location 100.", "start": 230.239, "duration": 3.961}, {"text": "The RAM, instead of sending back just that\none value, sends a block of data, from memory", "start": 234.2, "duration": 4.679}, {"text": "location 100 through 200, which are then all\ncopied into the cache.", "start": 238.879, "duration": 3.961}, {"text": "Now, when the processor requests the next\ntransaction to add to its running total, the", "start": 242.84, "duration": 3.811}, {"text": "value at address 101, the cache will say \u201cOh,\nI\u2019ve already got that value right here,", "start": 246.651, "duration": 4.208}, {"text": "so I can give it to you right away!\u201d", "start": 250.859, "duration": 1.38}, {"text": "And there\u2019s no need to go all the way to\nRAM.", "start": 252.239, "duration": 2.491}, {"text": "Because the cache is so close to the processor,\nit can typically provide the data in a single", "start": 254.73, "duration": 3.759}, {"text": "clock cycle -- no waiting required.", "start": 258.489, "duration": 2.55}, {"text": "This speeds things up tremendously over having\nto go back and forth to RAM every single time.", "start": 261.039, "duration": 3.951}, {"text": "When data requested in RAM is already stored\nin the cache like this it\u2019s called a cache", "start": 264.99, "duration": 3.45}, {"text": "hit,", "start": 268.44, "duration": 1.0}, {"text": "and if the data requested isn\u2019t in the cache,\nso you have to go to RAM, it\u2019s a called", "start": 269.44, "duration": 3.53}, {"text": "a cache miss.", "start": 272.97, "duration": 1.12}, {"text": "The cache can also be used like a scratch\nspace, storing intermediate values when performing", "start": 274.09, "duration": 4.329}, {"text": "a longer, or more complicated calculation.", "start": 278.42, "duration": 2.7}, {"text": "Continuing our restaurant example, let\u2019s\nsay the processor has finished totalling up", "start": 281.12, "duration": 3.46}, {"text": "all of the sales for the day, and wants to\nstore the result in memory address 150.", "start": 284.59, "duration": 4.4}, {"text": "Like before, instead of going back all the\nway to RAM to save that value, it can be stored", "start": 288.99, "duration": 4.329}, {"text": "in cached copy, which is faster to save to,\nand also faster to access later if more calculations", "start": 293.319, "duration": 5.72}, {"text": "are needed.", "start": 299.04, "duration": 0.68}, {"text": "But this introduces an interesting problem\n-- the cache\u2019s copy of the data is now different", "start": 299.72, "duration": 4.28}, {"text": "to the real version stored in RAM.", "start": 304.009, "duration": 1.891}, {"text": "This mismatch has to be recorded, so that\nat some point everything can get synced up.", "start": 305.9, "duration": 3.97}, {"text": "For this purpose, the cache has a special\nflag for each block of memory it stores, called", "start": 309.87, "duration": 4.09}, {"text": "the dirty bit -- which might just be the best\nterm computer scientists have ever invented.", "start": 313.96, "duration": 4.86}, {"text": "Most often this synchronization happens when\nthe cache is full, but a new block of memory", "start": 318.82, "duration": 4.24}, {"text": "is being requested by the processor.", "start": 323.06, "duration": 1.9}, {"text": "Before the cache erases the old block to free\nup space, it checks its dirty bit, and if", "start": 324.96, "duration": 4.26}, {"text": "it\u2019s dirty, the old block of data is written\nback to RAM before loading in the new block.", "start": 329.22, "duration": 4.04}, {"text": "Another trick to boost cpu performance is\ncalled instruction pipelining.", "start": 333.26, "duration": 3.9}, {"text": "Imagine you have to wash an entire hotel\u2019s\nworth of sheets, but you\u2019ve only got one", "start": 337.169, "duration": 3.271}, {"text": "washing machine and one dryer.", "start": 340.44, "duration": 1.58}, {"text": "One option is to do it all sequentially: put\na batch of sheets in the washer and wait 30", "start": 342.02, "duration": 3.77}, {"text": "minutes for it to finish.", "start": 345.79, "duration": 1.15}, {"text": "Then take the wet sheets out and put them\nin the dryer and wait another 30 minutes for", "start": 346.94, "duration": 3.24}, {"text": "that to finish.", "start": 350.18, "duration": 1.13}, {"text": "This allows you to do one batch of sheets\nevery hour.", "start": 351.31, "duration": 2.4}, {"text": "Side note: if you have a dryer that can dry\na load of laundry in 30 minutes, please tell", "start": 353.71, "duration": 3.799}, {"text": "me the brand and model in the comments, because\nI\u2019m living with 90 minute dry times, minimum.", "start": 357.509, "duration": 3.991}, {"text": "But, even with this magic clothes dryer, you\ncan speed things up even more if you parallelize", "start": 361.5, "duration": 4.76}, {"text": "your operation.", "start": 366.26, "duration": 1.01}, {"text": "As before, you start off putting one batch\nof sheets in the washer.", "start": 367.27, "duration": 3.16}, {"text": "You wait 30 minutes for it to finish.", "start": 370.43, "duration": 1.829}, {"text": "Then you take the wet sheets out and put them\nin the dryer.", "start": 372.259, "duration": 2.571}, {"text": "But this time, instead of just waiting 30\nminutes for the dryer to finish, you simultaneously", "start": 374.83, "duration": 4.209}, {"text": "start another load in the washing machine.", "start": 379.04, "duration": 2.24}, {"text": "Now you\u2019ve got both machines going at once.", "start": 381.28, "duration": 2.26}, {"text": "Wait 30 minutes, and one batch is now done,\none batch is half done, and another is ready", "start": 383.54, "duration": 4.119}, {"text": "to go in.", "start": 387.659, "duration": 1.0}, {"text": "This effectively doubles your throughput.", "start": 388.66, "duration": 1.52}, {"text": "Processor designs can apply the same idea.", "start": 390.22, "duration": 2.16}, {"text": "In episode 7, our example processor performed\nthe fetch-decode-execute cycle sequentially", "start": 392.38, "duration": 5.17}, {"text": "and in a continuous loop: Fetch-decode-execute,\nfetch-decode-execute, fetch-decode-execute,", "start": 397.55, "duration": 4.17}, {"text": "and so on.", "start": 401.72, "duration": 1.53}, {"text": "This meant our design required three clock\ncycles to execute one instruction.", "start": 403.25, "duration": 2.8}, {"text": "But each of these stages uses a different\npart of the CPU, meaning there is an opportunity", "start": 406.05, "duration": 4.19}, {"text": "to parallelize!", "start": 410.24, "duration": 1.0}, {"text": "While one instruction is getting executed,\nthe next instruction could be getting decoded,", "start": 411.24, "duration": 4.06}, {"text": "and the instruction beyond that fetched from\nmemory.", "start": 415.3, "duration": 2.54}, {"text": "All of these separate processes can overlap\nso that all parts of the CPU are active at", "start": 417.84, "duration": 3.789}, {"text": "any given time.", "start": 421.629, "duration": 1.31}, {"text": "In this pipelined design, an instruction is\nexecuted every single clock cycle which triples", "start": 422.939, "duration": 4.521}, {"text": "the throughput.", "start": 427.46, "duration": 1.0}, {"text": "But just like with caching this can lead to\nsome tricky problems.", "start": 428.46, "duration": 2.6}, {"text": "A big hazard is a dependency in the instructions.", "start": 431.06, "duration": 3.05}, {"text": "For example, you might fetch something that\nthe currently executing instruction is just", "start": 434.11, "duration": 3.649}, {"text": "about to modify, which means you\u2019ll end\nup with the old value in the pipeline.", "start": 437.759, "duration": 3.431}, {"text": "To compensate for this, pipelined processors\nhave to look ahead for data dependencies,", "start": 441.19, "duration": 4.3}, {"text": "and if necessary, stall their pipelines to\navoid problems.", "start": 445.49, "duration": 2.85}, {"text": "High end processors, like those found in laptops\nand smartphones, go one step further and can", "start": 448.34, "duration": 4.38}, {"text": "dynamically reorder instructions with dependencies\nin order to minimize stalls and keep the pipeline", "start": 452.72, "duration": 5.12}, {"text": "moving, which is called out-of-order execution.", "start": 457.84, "duration": 2.579}, {"text": "As you might imagine, the circuits that figure\nthis all out are incredibly complicated.", "start": 460.42, "duration": 3.82}, {"text": "Nonetheless, pipelining is tremendously effective\nand almost all processors implement it today.", "start": 464.24, "duration": 5.06}, {"text": "Another big hazard are conditional jump instructions\n-- we talked about one example, a JUMP NEGATIVE,", "start": 469.3, "duration": 4.96}, {"text": "last episode.", "start": 474.27, "duration": 0.99}, {"text": "These instructions can change the execution\nflow of a program depending on a value.", "start": 475.27, "duration": 3.98}, {"text": "A simple pipelined processor will perform\na long stall when it sees a jump instruction,", "start": 479.25, "duration": 4.25}, {"text": "waiting for the value to be finalized.", "start": 483.5, "duration": 2.02}, {"text": "Only once the jump outcome is known, does\nthe processor start refilling its pipeline.", "start": 485.53, "duration": 4.07}, {"text": "But, this can produce long delays, so high-end\nprocessors have some tricks to deal with this", "start": 489.61, "duration": 4.32}, {"text": "problem too.", "start": 493.93, "duration": 1.0}, {"text": "Imagine an upcoming jump instruction as a\nfork in a road - a branch.", "start": 494.93, "duration": 3.6}, {"text": "Advanced CPUs guess which way they are going\nto go, and start filling their pipeline with", "start": 498.53, "duration": 3.43}, {"text": "instructions based off that guess \u2013 a technique\ncalled speculative execution.", "start": 501.98, "duration": 5.24}, {"text": "When the jump instruction is finally resolved,\nif the CPU guessed correctly, then the pipeline", "start": 507.22, "duration": 4.27}, {"text": "is already full of the correct instructions\nand it can motor along without delay.", "start": 511.49, "duration": 3.59}, {"text": "However, if the CPU guessed wrong, it has\nto discard all its speculative results and", "start": 515.08, "duration": 3.71}, {"text": "perform a pipeline flush - sort of like when\nyou miss a turn and have to do a u-turn to", "start": 518.79, "duration": 4.07}, {"text": "get back on route, and stop your GPS\u2019s insistent\nshouting.", "start": 522.86, "duration": 3.42}, {"text": "To minimize the effects of these flushes,\nCPU manufacturers have developed sophisticated", "start": 526.28, "duration": 4.49}, {"text": "ways to guess which way branches will go,\ncalled branch prediction.", "start": 530.77, "duration": 3.43}, {"text": "Instead of being a 50/50 guess, today\u2019s\nprocessors can often guess with over 90% accuracy!", "start": 534.2, "duration": 5.22}, {"text": "In an ideal case, pipelining lets you complete\none instruction every single clock cycle,", "start": 539.42, "duration": 4.01}, {"text": "but then superscalar processors came along\nwhich can execute more than one instruction", "start": 543.43, "duration": 4.66}, {"text": "per clock cycle.", "start": 548.09, "duration": 0.99}, {"text": "During the execute phase even in a pipelined design, whole areas of the processor might", "start": 549.08, "duration": 4.06}, {"text": "be totally idle.", "start": 553.14, "duration": 1.5}, {"text": "For example, while executing an instruction\nthat fetches a value from memory, the ALU", "start": 554.64, "duration": 4.32}, {"text": "is just going to be sitting there, not doing\na thing.", "start": 558.96, "duration": 2.69}, {"text": "So why not fetch-and-decode several instructions\nat once, and whenever possible, execute instructions", "start": 561.65, "duration": 4.74}, {"text": "that require different parts of the CPU all\nat the same time!?", "start": 566.39, "duration": 3.25}, {"text": "But we can take this\none step further and add duplicate circuitry", "start": 569.64, "duration": 3.22}, {"text": "for popular instructions.", "start": 572.86, "duration": 1.66}, {"text": "For example, many processors will have four,\neight or more identical ALUs, so they can", "start": 574.52, "duration": 4.57}, {"text": "execute many mathematical instructions all\nin parallel!", "start": 579.09, "duration": 3.09}, {"text": "Ok, the techniques we\u2019ve discussed so far\nprimarily optimize the execution throughput", "start": 582.18, "duration": 4.04}, {"text": "of a single stream of instructions, but another\nway to increase performance is to run several", "start": 586.22, "duration": 4.47}, {"text": "streams of instructions at once with multi-core\nprocessors.", "start": 590.69, "duration": 3.48}, {"text": "You might have heard of dual core or quad\ncore processors.", "start": 594.17, "duration": 2.91}, {"text": "This means there are multiple independent\nprocessing units inside of a single CPU chip.", "start": 597.08, "duration": 4.6}, {"text": "In many ways, this is very much like having\nmultiple separate CPUs, but because they\u2019re", "start": 601.68, "duration": 4.09}, {"text": "tightly integrated, they can share some resources,\nlike cache, allowing the cores to work together", "start": 605.77, "duration": 4.83}, {"text": "on shared computations.", "start": 610.6, "duration": 1.29}, {"text": "But, when more cores just isn\u2019t enough,\nyou can build computers with multiple independent", "start": 611.89, "duration": 4.43}, {"text": "CPUs!", "start": 616.32, "duration": 1.0}, {"text": "High end computers, like the servers streaming\nthis video from YouTube\u2019s datacenter, often", "start": 617.32, "duration": 4.31}, {"text": "need the extra horsepower to keep it silky\nsmooth for the hundreds of people watching", "start": 621.63, "duration": 3.79}, {"text": "simultaneously.", "start": 625.42, "duration": 1.0}, {"text": "Two- and four-processor configuration are\nthe most common right now, but every now and", "start": 626.42, "duration": 3.58}, {"text": "again even that much processing power isn\u2019t\nenough.", "start": 630.0, "duration": 2.7}, {"text": "So we humans get extra ambitious and build\nourselves a supercomputer!", "start": 632.7, "duration": 4.24}, {"text": "If you\u2019re looking to do some really monster\ncalculations \u2013 like simulating the formation", "start": 636.94, "duration": 3.48}, {"text": "of the universe - you\u2019ll need some pretty\nserious compute power.", "start": 640.42, "duration": 3.52}, {"text": "A few extra processors in a desktop computer\njust isn\u2019t going to cut it.", "start": 643.94, "duration": 3.21}, {"text": "You\u2019re going to need a lot of processors.", "start": 647.15, "duration": 2.53}, {"text": "No.. no... even more than that.", "start": 649.68, "duration": 2.24}, {"text": "A lot more!", "start": 651.92, "duration": 1.0}, {"text": "When this video was made, the world\u2019s fastest\ncomputer was located in The National Supercomputing", "start": 652.92, "duration": 3.84}, {"text": "Center in Wuxi, China.", "start": 656.76, "duration": 1.36}, {"text": "The Sunway TaihuLight contains a brain-melting\n40,960 CPUs, each with 256 cores!", "start": 658.12, "duration": 8.47}, {"text": "Thats over ten million cores in total... and\neach one of those cores runs at 1.45 gigahertz.", "start": 666.59, "duration": 5.03}, {"text": "In total, this machine can process 93 Quadrillion\n-- that\u2019s 93 million-billions -- floating", "start": 671.62, "duration": 5.47}, {"text": "point math operations per second, knows as\nFLOPS.", "start": 677.09, "duration": 3.22}, {"text": "And trust me, that\u2019s a lot of FLOPS!!", "start": 680.31, "duration": 1.54}, {"text": "No word on whether it can run Crysis at max\nsettings, but I suspect it might.", "start": 681.85, "duration": 3.82}, {"text": "So long story short, not only have computer\nprocessors gotten a lot faster over the years,", "start": 685.67, "duration": 4.4}, {"text": "but also a lot more sophisticated, employing\nall sorts of clever tricks to squeeze out", "start": 690.07, "duration": 3.92}, {"text": "more and more computation per clock cycle.", "start": 693.99, "duration": 2.47}, {"text": "Our job is to wield that incredible processing\npower to do cool and useful things.", "start": 696.46, "duration": 4.12}, {"text": "That\u2019s the essence of programming, which\nwe\u2019ll start discussing next episode.", "start": 700.58, "duration": 4.02}, {"text": "See you next week.", "start": 704.64, "duration": 1.4}]