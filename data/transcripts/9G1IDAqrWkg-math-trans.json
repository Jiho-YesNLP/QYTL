[{"text": "The following content is\nprovided under a Creative", "start": 0.09, "duration": 2.41}, {"text": "Commons license.", "start": 2.5, "duration": 1.519}, {"text": "Your support will help\nMIT OpenCourseWare", "start": 4.019, "duration": 2.341}, {"text": "continue to offer high-quality\neducational resources for free.", "start": 6.36, "duration": 4.37}, {"text": "To make a donation or\nview additional materials", "start": 10.73, "duration": 2.6}, {"text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare", "start": 13.33, "duration": 3.88}, {"text": "at ocw.mit.edu.", "start": 17.21, "duration": 0.625}, {"text": "PROFESSOR: We introduced\nthe data last time.", "start": 21.65, "duration": 2.38}, {"text": "These were some\nmacroeconomic variables", "start": 24.03, "duration": 3.67}, {"text": "that can be used for forecasting\nthe economy in terms of growth", "start": 27.7, "duration": 6.29}, {"text": "and factors such as\ninflation or unemployment.", "start": 33.99, "duration": 5.34}, {"text": "The case note goes through\nanalyzing just three", "start": 39.33, "duration": 4.69}, {"text": "of these economic time\nseries-- the unemployment rate,", "start": 44.02, "duration": 3.67}, {"text": "the federal funds rate,\nand a measure of the CPI,", "start": 47.69, "duration": 3.67}, {"text": "or Consumer Price Index.", "start": 51.36, "duration": 1.17}, {"text": "When one fits a vector\nautoregression model", "start": 56.45, "duration": 4.07}, {"text": "to this data, it turns\nout that the roots", "start": 60.52, "duration": 8.42}, {"text": "of the characteristic polynomial\nare 1.002, then 0.9863.", "start": 68.94, "duration": 7.86}, {"text": "And you recall when our\ndiscussion of vector", "start": 76.8, "duration": 2.29}, {"text": "autoregressive models, there's\na characteristic equation", "start": 79.09, "duration": 4.05}, {"text": "sort of in matrix\nform, the determinant", "start": 83.14, "duration": 2.285}, {"text": "is just like the univariate\nautoregressive case.", "start": 85.425, "duration": 4.295}, {"text": "And in order for the process\nto be invertible, basically,", "start": 89.72, "duration": 14.4}, {"text": "the roots of the\ncharacteristic polynomial", "start": 104.12, "duration": 2.03}, {"text": "need to be less\nthan 1 in magnitude.", "start": 106.15, "duration": 4.22}, {"text": "In this implementation of the\nvector autoregression model,", "start": 110.37, "duration": 3.74}, {"text": "the characteristic\nroots are the inverses", "start": 114.11, "duration": 3.11}, {"text": "of the characteristic roots\nthat we've been discussing.", "start": 117.22, "duration": 2.4}, {"text": "So anyway, this particular fit\nof the vector autoregression", "start": 119.62, "duration": 4.15}, {"text": "model suggests that the\nprocess is non-stationary.", "start": 123.77, "duration": 7.6}, {"text": "And so one should be\nconsidering different series", "start": 131.37, "duration": 6.21}, {"text": "to model this as a\nstationary time series.", "start": 137.58, "duration": 2.82}, {"text": "But in terms of interpreting\nthe regression model,", "start": 140.4, "duration": 6.12}, {"text": "one can see-- to accommodate\nthe non-stationarity,", "start": 146.52, "duration": 9.8}, {"text": "we can take differences\nof all the series", "start": 156.32, "duration": 4.7}, {"text": "and fit the vector\nautoregression", "start": 161.02, "duration": 2.34}, {"text": "to the difference series.", "start": 163.36, "duration": 2.19}, {"text": "So one way of eliminating any\nnon-stationarity in time series", "start": 165.55, "duration": 3.66}, {"text": "models, basically\neliminate the random walk", "start": 169.21, "duration": 3.6}, {"text": "aspect of the processes, is to\nbe modeling first differences.", "start": 172.81, "duration": 4.48}, {"text": "And so doing that with\nthis series-- let's see.", "start": 177.29, "duration": 8.89}, {"text": "Here is just a graph of\nthe time series properties", "start": 186.18, "duration": 4.04}, {"text": "of the difference series.", "start": 190.22, "duration": 1.58}, {"text": "So with our original series, we\ntake differences and eliminate", "start": 195.21, "duration": 3.97}, {"text": "missing values in this R code.", "start": 199.18, "duration": 3.64}, {"text": "And this\nautocorrelation function", "start": 202.82, "duration": 2.48}, {"text": "shows us basically\nthe correlations", "start": 205.3, "duration": 5.8}, {"text": "and autocorrelations\nof individual series", "start": 211.1, "duration": 2.32}, {"text": "and the cross-correlations\nacross the different series.", "start": 213.42, "duration": 3.53}, {"text": "So along the diagonals are\nthe autocorrelation function.", "start": 216.95, "duration": 4.73}, {"text": "And one can see\nthat every series", "start": 221.68, "duration": 2.12}, {"text": "is correlation one with itself.", "start": 223.8, "duration": 3.48}, {"text": "But then at the first\nlag, positive for the Fed", "start": 227.28, "duration": 5.1}, {"text": "funds and the CPI measure.", "start": 232.38, "duration": 4.07}, {"text": "And there's also some\ncross-correlations", "start": 236.45, "duration": 2.53}, {"text": "that are strong.", "start": 238.98, "duration": 2.57}, {"text": "And whether or not a\ncorrelation is strong or not", "start": 241.55, "duration": 2.63}, {"text": "depends upon how much\nuncertainty there", "start": 244.18, "duration": 1.945}, {"text": "is in our estimate\nof the correlation.", "start": 246.125, "duration": 2.125}, {"text": "And these dashed\nlines here correspond", "start": 248.25, "duration": 3.5}, {"text": "to plus or minus two standard\ndeviations of the correlation", "start": 251.75, "duration": 5.23}, {"text": "coefficient when the correlation\ncoefficient is equal to 0.", "start": 256.98, "duration": 6.46}, {"text": "So any correlations that sort\nof go beyond those bounds", "start": 263.44, "duration": 5.03}, {"text": "is statistically significant.", "start": 268.47, "duration": 1.245}, {"text": "The partial autocorrelation\nfunction is graphed here.", "start": 273.18, "duration": 6.03}, {"text": "And let's say our\ntime series problem", "start": 279.21, "duration": 3.52}, {"text": "set goes through some discussion\nof the partial autocorrelation", "start": 282.73, "duration": 3.31}, {"text": "coefficients and the\ninterpretation of those.", "start": 286.04, "duration": 2.56}, {"text": "The partial autocorrelation\ncoefficients", "start": 288.6, "duration": 3.31}, {"text": "are the correlation\nbetween one variable", "start": 291.91, "duration": 5.54}, {"text": "and the lag of another\nafter explaining", "start": 297.45, "duration": 1.88}, {"text": "for all lower degree lags.", "start": 299.33, "duration": 2.78}, {"text": "So it's like the incremental\ncorrelation of a variable", "start": 302.11, "duration": 4.37}, {"text": "with a lag term that exists.", "start": 306.48, "duration": 4.28}, {"text": "And so if we are actually\nfitting regression models where", "start": 310.76, "duration": 3.07}, {"text": "we include extra lags\nof a given variable,", "start": 313.83, "duration": 4.63}, {"text": "that partial\nautocorrelation coefficient", "start": 318.46, "duration": 2.11}, {"text": "is essentially the correlation\nassociated with the addition", "start": 320.57, "duration": 4.69}, {"text": "of the final lagged variable.", "start": 325.26, "duration": 2.36}, {"text": "So here, we can see that\neach of these series", "start": 327.62, "duration": 2.61}, {"text": "is quite strongly\ncorrelated with itself.", "start": 330.23, "duration": 3.72}, {"text": "But there are also\nsome cross-correlations", "start": 333.95, "duration": 3.52}, {"text": "with, like, the unemployment\nrate and the Fed funds rate.", "start": 337.47, "duration": 5.28}, {"text": "Basically, the Fed\nfunds rate tends", "start": 342.75, "duration": 3.95}, {"text": "to go down when the\nunemployment rate goes up.", "start": 346.7, "duration": 3.7}, {"text": "And so this data is\nindicating the association", "start": 350.4, "duration": 4.21}, {"text": "between these\nmacroeconomic variables", "start": 354.61, "duration": 2.03}, {"text": "and the evidence\nof that behavior.", "start": 356.64, "duration": 2.46}, {"text": "In terms of modeling the\nactual structural relations", "start": 359.1, "duration": 3.0}, {"text": "between these, we need\nseveral, up to about 10", "start": 362.1, "duration": 3.83}, {"text": "or 12 variables more\nthan these three.", "start": 365.93, "duration": 2.45}, {"text": "And then one can have\na better understanding", "start": 368.38, "duration": 4.33}, {"text": "of the drivers of various\nmacroeconomic features.", "start": 372.71, "duration": 3.04}, {"text": "But this sort of\nillustrates the use", "start": 375.75, "duration": 1.5}, {"text": "of these methods with this\nreduced variable case.", "start": 377.25, "duration": 2.7}, {"text": "Let me also go\ndown here and just", "start": 382.83, "duration": 2.82}, {"text": "comment on the unemployment\nrate or the Fed funds rate.", "start": 385.65, "duration": 8.06}, {"text": "When fitting these vector\nautoregressive models", "start": 406.05, "duration": 2.41}, {"text": "with the packages\nthat exist in R,", "start": 408.46, "duration": 3.61}, {"text": "they give us output which\nprovides the specification", "start": 412.07, "duration": 4.25}, {"text": "of each of the\nautoregressive models", "start": 416.32, "duration": 5.12}, {"text": "for the different dependent\nvariables, the different series", "start": 421.44, "duration": 3.82}, {"text": "of the process.", "start": 425.26, "duration": 2.36}, {"text": "And so here is the case of the\nregression model for Fed funds", "start": 427.62, "duration": 5.99}, {"text": "as a function of\nunemployment rate lagged,", "start": 433.61, "duration": 4.11}, {"text": "Fed funds rate lagged,\nand CPI lagged.", "start": 437.72, "duration": 3.32}, {"text": "These are all on\nthe different scale.", "start": 441.04, "duration": 4.2}, {"text": "When you're looking at\nthese results, what's", "start": 445.24, "duration": 2.49}, {"text": "important is\nbasically how strong", "start": 447.73, "duration": 3.61}, {"text": "the signal-to-noise\nratio is for estimating", "start": 451.34, "duration": 2.51}, {"text": "these autoregressive\nparameters, vector", "start": 453.85, "duration": 3.74}, {"text": "autoregressive parameters.", "start": 457.59, "duration": 1.54}, {"text": "And so with the Fed funds,\nyou can look at the t values.", "start": 459.13, "duration": 4.41}, {"text": "And t values that\nare larger than 2", "start": 463.54, "duration": 2.38}, {"text": "are certainly quite significant.", "start": 465.92, "duration": 3.29}, {"text": "And you can see that basically\nwhen the unemployment rate", "start": 469.21, "duration": 4.33}, {"text": "coefficient is a negative\n0.71, so if the unemployment", "start": 473.54, "duration": 5.71}, {"text": "rate goes up, we expect to\nsee the Fed rate going down", "start": 479.25, "duration": 6.02}, {"text": "the next month.", "start": 485.27, "duration": 1.81}, {"text": "And the Fed funds rate for the\nlag 1 has a t value of 7.97.", "start": 487.08, "duration": 8.57}, {"text": "So these are now models\non the differences.", "start": 495.65, "duration": 3.14}, {"text": "So if the Fed funds\nrate was increased", "start": 498.79, "duration": 2.69}, {"text": "last month or last quarter, it's\nlikely to be increased again.", "start": 501.48, "duration": 4.4}, {"text": "And that's partly a factor\nof how slow the economy is", "start": 505.88, "duration": 5.68}, {"text": "in reacting to changes\nand how the Fed doesn't", "start": 511.56, "duration": 2.489}, {"text": "want to shock the economy with\nlarge changes in their policy", "start": 514.049, "duration": 6.151}, {"text": "rates.", "start": 520.2, "duration": 2.709}, {"text": "Another thing to notice here\nis that there's actually", "start": 522.909, "duration": 3.691}, {"text": "a negative coefficient\non the lag 2", "start": 526.6, "duration": 3.63}, {"text": "Fed funds term, a negative 0.17.", "start": 530.23, "duration": 4.26}, {"text": "And in interpreting\nthese kinds of models,", "start": 534.49, "duration": 4.38}, {"text": "I think it's helpful\njust to think of,", "start": 538.87, "duration": 3.64}, {"text": "if you have Fed\nfunds sub t, that's", "start": 542.51, "duration": 3.7}, {"text": "equal to minus 0.71 times the\nunemployment rate at t minus 1.", "start": 546.21, "duration": 7.76}, {"text": "And then we have plus 0.37 times\nthe Fed funds, so t minus 1.", "start": 553.97, "duration": 10.08}, {"text": "And this is delta.", "start": 564.05, "duration": 0.77}, {"text": "And then minus 1.8\ntimes the Fed funds.", "start": 564.82, "duration": 6.51}, {"text": "So t minus 2.", "start": 571.33, "duration": 3.67}, {"text": "In interpreting\nthese coefficients,", "start": 575.0, "duration": 4.29}, {"text": "notice that these\ntwo terms correspond", "start": 579.29, "duration": 3.73}, {"text": "to 0.19 times the Fed funds\nchange 1 lag ago plus 0.18", "start": 583.02, "duration": 14.09}, {"text": "times the change in that rate.", "start": 597.11, "duration": 2.335}, {"text": "So when you see\nmultiple lags coming", "start": 603.55, "duration": 2.81}, {"text": "into play in these models,\nthe interpretation of them", "start": 606.36, "duration": 5.36}, {"text": "can be made by considering\ndifferent transformations", "start": 611.72, "duration": 5.84}, {"text": "essentially of the\nunderlying variables.", "start": 617.56, "duration": 2.65}, {"text": "In this form, you can see\nthat OK, the Fed funds", "start": 620.21, "duration": 2.92}, {"text": "tends to change the way it\nchanged the previous month.", "start": 623.13, "duration": 7.05}, {"text": "But it also may change\ndepending on the double change", "start": 630.18, "duration": 8.464}, {"text": "in the previous month.", "start": 638.644, "duration": 0.916}, {"text": "So there's a degree of\nacceleration in the Fed funds", "start": 639.56, "duration": 3.06}, {"text": "that is being captured here.", "start": 642.62, "duration": 1.83}, {"text": "So the interpretation\nof these models", "start": 644.45, "duration": 3.19}, {"text": "sometimes requires some care.", "start": 647.64, "duration": 4.29}, {"text": "This kind of analysis,\nI find it quite useful.", "start": 651.93, "duration": 3.63}, {"text": "So let's push on\nto the next topic.", "start": 662.6, "duration": 7.11}, {"text": "So today's topics are going\nto begin with a discussion", "start": 669.71, "duration": 3.52}, {"text": "of cointegration.", "start": 673.23, "duration": 2.41}, {"text": "Cointegration is a major topic\nin time series analysis, which", "start": 675.64, "duration": 3.34}, {"text": "is dealing with the analysis\nof non-stationary time series.", "start": 678.98, "duration": 5.0}, {"text": "And in the previous\ndiscussion, we", "start": 683.98, "duration": 4.08}, {"text": "addressed\nnon-stationarity of series", "start": 688.06, "duration": 1.85}, {"text": "by taking first\ndifferences to eliminate", "start": 689.91, "duration": 2.304}, {"text": "that non-stationarity.", "start": 692.214, "duration": 0.916}, {"text": "But we may be losing\nsome information", "start": 696.44, "duration": 3.7}, {"text": "with that differencing.", "start": 700.14, "duration": 1.31}, {"text": "And cointegration\nprovides a framework", "start": 701.45, "duration": 3.49}, {"text": "within which we\ncharacterize all available", "start": 704.94, "duration": 2.5}, {"text": "information for\nstatistical modeling,", "start": 707.44, "duration": 2.24}, {"text": "in a very systematic way.", "start": 709.68, "duration": 3.24}, {"text": "So let's introduce the\ncontext within which", "start": 712.92, "duration": 5.66}, {"text": "cointegration is relevant.", "start": 718.58, "duration": 2.05}, {"text": "It's relevant when we\nhave a stochastic process,", "start": 720.63, "duration": 5.18}, {"text": "a multivariate\nstochastic process, which", "start": 725.81, "duration": 2.81}, {"text": "is integrated of some order d.", "start": 728.62, "duration": 3.44}, {"text": "And to be integrated\nof order d means", "start": 732.06, "duration": 3.75}, {"text": "that if we take the\nd-th difference,", "start": 735.81, "duration": 3.11}, {"text": "then that d-th\ndifference is stationary.", "start": 738.92, "duration": 2.475}, {"text": "So and if you look\nat a time series", "start": 743.98, "duration": 9.74}, {"text": "and you plot that over time,\nwell, OK, a stationary time", "start": 753.72, "duration": 4.91}, {"text": "series we know should be\nsomething that basically", "start": 758.63, "duration": 4.38}, {"text": "has a constant mean over time.", "start": 763.01, "duration": 2.0}, {"text": "There's some steady\nmean which that has.", "start": 765.01, "duration": 3.57}, {"text": "And the variability\nis also constant.", "start": 768.58, "duration": 2.89}, {"text": "With some other time series,\nit might increase linearly", "start": 771.47, "duration": 7.53}, {"text": "over time.", "start": 779.0, "duration": 1.94}, {"text": "And a series that increases\nlinearly over time, well,", "start": 780.94, "duration": 2.66}, {"text": "if you take first\ndifferences, that", "start": 783.6, "duration": 1.47}, {"text": "tends to take out\nthat linear trend.", "start": 785.07, "duration": 2.58}, {"text": "If there are higher order\ndifferencing is required, then", "start": 787.65, "duration": 2.58}, {"text": "that means that there's some\ncurvature, quadratic say,", "start": 790.23, "duration": 3.93}, {"text": "that may exist in the data\nthat is being taken out.", "start": 794.16, "duration": 4.6}, {"text": "So this differencing is required\nto result in stationarity.", "start": 798.76, "duration": 6.7}, {"text": "If the process does have vector\nautoregressive representation", "start": 805.46, "duration": 6.97}, {"text": "in spite of its\nnon-stationarity,", "start": 812.43, "duration": 2.9}, {"text": "then it can be represented by\na polynomial lag of the x's is", "start": 815.33, "duration": 8.59}, {"text": "equal to white noise epsilon.", "start": 823.92, "duration": 4.77}, {"text": "And the polynomial\nphi of L going", "start": 828.69, "duration": 4.9}, {"text": "to have a factor term\nin there of 1 minus L,", "start": 833.59, "duration": 5.59}, {"text": "basically the first\ndifference to the d power.", "start": 839.18, "duration": 2.92}, {"text": "So if taking these the\nd-th order difference", "start": 842.1, "duration": 4.2}, {"text": "reduces it to\nstationarity, then we", "start": 846.3, "duration": 6.13}, {"text": "can express this vector\nautoregression in this way.", "start": 852.43, "duration": 4.2}, {"text": "So the phi star of L\nbasically represents", "start": 856.63, "duration": 9.99}, {"text": "the stationary vector\nautoregressive process", "start": 866.62, "duration": 4.49}, {"text": "on the d-th difference series.", "start": 871.11, "duration": 2.145}, {"text": "Now, as it says here, each\nof the component series", "start": 887.73, "duration": 5.05}, {"text": "may be non-stationary and\nintegrated, say of order one.", "start": 892.78, "duration": 4.31}, {"text": "But the process itself may\nnot be jointly integrated.", "start": 897.09, "duration": 5.68}, {"text": "In that it may be that there\nare linear combinations", "start": 902.77, "duration": 6.13}, {"text": "of our multivariate series\nwhich are stationary.", "start": 908.9, "duration": 4.9}, {"text": "And so these linear\ncombinations basically", "start": 913.8, "duration": 6.77}, {"text": "represent the stationary\nfeatures of the process.", "start": 920.57, "duration": 4.48}, {"text": "And those features can be\napparent without looking", "start": 925.05, "duration": 6.11}, {"text": "at differences.", "start": 931.16, "duration": 1.33}, {"text": "So in a sense, if\nyou just focused", "start": 932.49, "duration": 2.86}, {"text": "on differences of these\nnon-stationary multivariate", "start": 935.35, "duration": 3.53}, {"text": "series, you would be\nlosing out on information", "start": 938.88, "duration": 4.68}, {"text": "of the stationary structure\nof contemporaneous components", "start": 943.56, "duration": 6.34}, {"text": "of the multivariate series.", "start": 949.9, "duration": 2.33}, {"text": "And so cointegration\ndeals with this situation", "start": 952.23, "duration": 3.9}, {"text": "where some linear combinations\nof the multivariate series", "start": 956.13, "duration": 5.35}, {"text": "in fact are stationary.", "start": 961.48, "duration": 1.516}, {"text": "So how do we represent\nthat mathematically?", "start": 968.81, "duration": 6.28}, {"text": "Well, we say that this\nmultivariate time series", "start": 975.09, "duration": 3.93}, {"text": "process is cointegrated if\nthere exists an m-vector beta", "start": 979.02, "duration": 5.34}, {"text": "such that, defining linear\nweights on the x's, and", "start": 984.36, "duration": 5.11}, {"text": "beta prime X_t is a\nstationary process.", "start": 989.47, "duration": 2.755}, {"text": "The cointegration vector of\nbeta can be scaled arbitrarily.", "start": 997.92, "duration": 4.69}, {"text": "So it's common\npractice, if one has", "start": 1002.61, "duration": 6.5}, {"text": "an interest, some primary\ninterest, perhaps,", "start": 1009.11, "duration": 2.09}, {"text": "in the first component\nseries of process,", "start": 1011.2, "duration": 2.38}, {"text": "to set that equal to 1.", "start": 1013.58, "duration": 3.1}, {"text": "And the expression\nbasically says", "start": 1016.68, "duration": 4.34}, {"text": "that our time t value\nof the first series", "start": 1021.02, "duration": 5.45}, {"text": "is related in a stationary\nway to a linear combination", "start": 1026.47, "duration": 5.46}, {"text": "of the other m minus 1 series.", "start": 1031.93, "duration": 3.62}, {"text": "And this is a long-run\nequilibrium type relationship.", "start": 1035.55, "duration": 6.309}, {"text": "How does this arise?", "start": 1041.859, "duration": 3.651}, {"text": "Well, it arises in many, many\nways in economics and finance.", "start": 1045.51, "duration": 5.06}, {"text": "The term structure of interest\nrates, purchase power parity.", "start": 1053.1, "duration": 2.9}, {"text": "In the terms structure\nof interest rates,", "start": 1058.82, "duration": 3.84}, {"text": "basically the differences\nbetween yields", "start": 1062.66, "duration": 4.44}, {"text": "on interest rates over\ndifferent maturities,", "start": 1067.1, "duration": 3.16}, {"text": "those differences\nmight be stationary.", "start": 1070.26, "duration": 2.34}, {"text": "The overall level of interest\nmight not be stationary,", "start": 1072.6, "duration": 4.18}, {"text": "but the spreads ought\nto be stationary.", "start": 1076.78, "duration": 4.57}, {"text": "The purchase power parity\nin foreign exchange,", "start": 1081.35, "duration": 3.33}, {"text": "if you look at the\nvalue of currencies", "start": 1084.68, "duration": 6.26}, {"text": "for different countries,\nbasically different countries", "start": 1090.94, "duration": 3.89}, {"text": "ought to be able to purchase\nthe same goods for roughly", "start": 1094.83, "duration": 4.88}, {"text": "the same price.", "start": 1099.71, "duration": 1.01}, {"text": "And so if there are\ndisparities in currency values,", "start": 1100.72, "duration": 3.14}, {"text": "purchase power parity suggests\nthat things will revert back", "start": 1103.86, "duration": 3.88}, {"text": "to some norm where everybody\nis paying on average over time", "start": 1107.74, "duration": 5.16}, {"text": "the same amount for\ndifferent goods.", "start": 1112.9, "duration": 2.06}, {"text": "Otherwise, there\nwould be arbitrage.", "start": 1114.96, "duration": 2.5}, {"text": "Money demand, covered\ninterest rate parity,", "start": 1120.03, "duration": 1.86}, {"text": "law of one price,\nspot and futures.", "start": 1121.89, "duration": 2.45}, {"text": "Let me show you\nanother example that", "start": 1124.34, "duration": 4.13}, {"text": "will be in the case\nstudy for this chapter.", "start": 1128.47, "duration": 6.35}, {"text": "View, full screen.", "start": 1140.29, "duration": 6.12}, {"text": "Let's think about\nenergy futures.", "start": 1146.41, "duration": 3.49}, {"text": "In fact, next Tuesday's\ntalk from Morgan Stanley", "start": 1149.9, "duration": 3.55}, {"text": "is going to be an expert in\ncommodity futures and options.", "start": 1153.45, "duration": 5.04}, {"text": "And that should be\nvery interesting.", "start": 1158.49, "duration": 2.6}, {"text": "Anyway, here, I'm\nlooking at energy futures", "start": 1161.09, "duration": 7.83}, {"text": "from the Energy\nInformation Administration.", "start": 1168.92, "duration": 2.216}, {"text": "Actually, for this\ncourse, trying", "start": 1171.136, "duration": 1.374}, {"text": "to get data that's freely\navailable to students", "start": 1172.51, "duration": 4.46}, {"text": "is one of the things we do.", "start": 1176.97, "duration": 3.59}, {"text": "So this data is actually\navailable from the Energy", "start": 1180.56, "duration": 2.086}, {"text": "Information Administration\nof the government, which", "start": 1182.646, "duration": 2.124}, {"text": "is now open, so I guess\nthat'll be updated over time.", "start": 1184.77, "duration": 4.19}, {"text": "But basically these\nenergy futures", "start": 1188.96, "duration": 3.11}, {"text": "are traded on the Chicago\nMercantile Exchange.", "start": 1192.07, "duration": 3.5}, {"text": "And basically CL is crude,\nWest Texas intermediate crude,", "start": 1195.57, "duration": 7.72}, {"text": "light crude, which we have\nhere, a time series from 2006", "start": 1203.29, "duration": 5.47}, {"text": "to basically yesterday.", "start": 1208.76, "duration": 3.91}, {"text": "And you can see how at the\nstart of the period around $60", "start": 1212.67, "duration": 3.67}, {"text": "and then went up\nto close to $140,", "start": 1216.34, "duration": 2.74}, {"text": "and then it dropped\ndown to around $40.", "start": 1219.08, "duration": 3.36}, {"text": "And it's been hovering\naround $100 lately.", "start": 1222.44, "duration": 3.67}, {"text": "The second series here is\ngasoline, RBOB gasoline.", "start": 1226.11, "duration": 6.93}, {"text": "Always have to look this up.", "start": 1233.04, "duration": 3.2}, {"text": "This is that reformulated blend\nstock for oxygenated blending", "start": 1236.24, "duration": 6.45}, {"text": "gasoline.", "start": 1242.69, "duration": 0.56}, {"text": "Anyway, futures on this product\nare traded at the CME as well.", "start": 1243.25, "duration": 4.78}, {"text": "And then heating oil.", "start": 1248.03, "duration": 2.72}, {"text": "And what's happening\nwith these data", "start": 1250.75, "duration": 6.03}, {"text": "is that we have basically\na refinery which processes", "start": 1256.78, "duration": 12.1}, {"text": "crude oil as an input.", "start": 1268.88, "duration": 7.11}, {"text": "And it basically\nrefines it, distills it,", "start": 1275.99, "duration": 4.19}, {"text": "and generates outputs, which\ninclude heating oil, gasoline,", "start": 1280.18, "duration": 16.42}, {"text": "and various other things\nlike jet fuel and others.", "start": 1296.6, "duration": 5.08}, {"text": "So if we're looking\nat the prices,", "start": 1301.68, "duration": 4.78}, {"text": "the futures prices of, say,\ngasoline and heating oil,", "start": 1306.46, "duration": 3.05}, {"text": "relating those to crude\noil, well, certainly,", "start": 1309.51, "duration": 6.2}, {"text": "the cost of producing these\nproducts should depend", "start": 1315.71, "duration": 3.43}, {"text": "on the cost of the input .", "start": 1319.14, "duration": 2.68}, {"text": "So I've got in the next plot,\na translation of these futures", "start": 1321.82, "duration": 8.66}, {"text": "contracts into their\nprice per barrel.", "start": 1330.48, "duration": 5.03}, {"text": "Turns out crude is quoted\nin dollars per barrel.", "start": 1335.51, "duration": 3.81}, {"text": "And the gasoline heating\noil are in cents per gallon.", "start": 1339.32, "duration": 5.07}, {"text": "So one multiplies.", "start": 1344.39, "duration": 2.1}, {"text": "There are 42\ngallons in a barrel.", "start": 1346.49, "duration": 1.82}, {"text": "So you multiply those\nprevious years by 42.", "start": 1348.31, "duration": 2.65}, {"text": "And this shows the plot of\nthe prices of the futures", "start": 1350.96, "duration": 2.589}, {"text": "where we're looking at\nessentially the same units", "start": 1353.549, "duration": 2.041}, {"text": "of output relative to input.", "start": 1355.59, "duration": 5.01}, {"text": "And what's evident here is that\nwhile the futures for gasoline,", "start": 1360.6, "duration": 5.1}, {"text": "the blue, is consistently above\nthe green, the input, and same", "start": 1365.7, "duration": 4.75}, {"text": "for heating oil.", "start": 1370.45, "duration": 2.07}, {"text": "And those vary depending\non which is greater.", "start": 1372.52, "duration": 3.16}, {"text": "So if we look at the\ndifference between, say,", "start": 1375.68, "duration": 6.92}, {"text": "the price of the heating\noil future and the crude oil", "start": 1382.6, "duration": 4.42}, {"text": "future, what does\nthat represent?", "start": 1387.02, "duration": 4.605}, {"text": "That's the spread in value of\nthe output minus the input.", "start": 1394.38, "duration": 6.4}, {"text": "Ray?", "start": 1400.78, "duration": 0.766}, {"text": "AUDIENCE: [INAUDIBLE] cost\nof running the refinery?", "start": 1401.546, "duration": 2.736}, {"text": "PROFESSOR: So cost of refining.", "start": 1407.146, "duration": 4.794}, {"text": "So let's look at, say,\nheating oil minus CL and, say,", "start": 1411.94, "duration": 7.76}, {"text": "this RBOB minus CL.", "start": 1419.7, "duration": 4.23}, {"text": "So it's cost of refining.", "start": 1423.93, "duration": 2.74}, {"text": "What else could\nbe a factor here?", "start": 1426.67, "duration": 2.817}, {"text": "AUDIENCE: Supply and demand\ncharacteristics [INAUDIBLE].", "start": 1429.487, "duration": 2.333}, {"text": "PROFESSOR: Definitely.", "start": 1431.82, "duration": 0.916}, {"text": "Supply and demand.", "start": 1432.736, "duration": 1.429}, {"text": "If one product is demanded\na lot more than another.", "start": 1434.165, "duration": 2.125}, {"text": "Supply and demand.", "start": 1438.28, "duration": 0.75}, {"text": "Anything else?", "start": 1445.82, "duration": 2.395}, {"text": "AUDIENCE: Maybe for\nthe outputs, if you", "start": 1448.215, "duration": 1.625}, {"text": "were to find the difference\nbetween the outputs,", "start": 1449.84, "duration": 1.5}, {"text": "it would be something cyclical.", "start": 1451.34, "duration": 1.72}, {"text": "For example, in the\nwinter, heating oil", "start": 1453.06, "duration": 2.58}, {"text": "is going to get far more\nvaluable as gasoline,", "start": 1455.64, "duration": 2.2}, {"text": "because people drive less\nand people demand more", "start": 1457.84, "duration": 2.0}, {"text": "for heating homes.", "start": 1459.84, "duration": 1.11}, {"text": "PROFESSOR: Absolutely.", "start": 1460.95, "duration": 1.13}, {"text": "That's a very significant\nfactor with these.", "start": 1462.08, "duration": 3.59}, {"text": "There are seasonal effects\nthat drive supply and demand.", "start": 1465.67, "duration": 3.56}, {"text": "And so we can put\nseasonal effects in there", "start": 1469.23, "duration": 6.23}, {"text": "as affecting supply and demand.", "start": 1475.46, "duration": 1.52}, {"text": "But certainly, you might expect\nto see seasonal structure here.", "start": 1476.98, "duration": 3.3}, {"text": "Anything else?", "start": 1480.28, "duration": 3.44}, {"text": "Put on your traders hat.", "start": 1483.72, "duration": 3.35}, {"text": "Profit, yes.", "start": 1487.07, "duration": 2.24}, {"text": "The refinery needs\nto make some profit.", "start": 1489.31, "duration": 3.85}, {"text": "So there has to be some\nlevel of profit that's", "start": 1493.16, "duration": 5.36}, {"text": "acceptable and appropriate.", "start": 1498.52, "duration": 3.72}, {"text": "So we have all these\nthings driving basically", "start": 1502.24, "duration": 3.01}, {"text": "these differences.", "start": 1505.25, "duration": 2.38}, {"text": "Let's just take a look\nat those differences.", "start": 1507.63, "duration": 2.59}, {"text": "These are actually\ncalled the crack spreads.", "start": 1510.22, "duration": 4.66}, {"text": "Cracking in the\nbusiness of refining", "start": 1514.88, "duration": 4.37}, {"text": "is basically the\nbreaking down of oil", "start": 1519.25, "duration": 2.97}, {"text": "into components, products.", "start": 1522.22, "duration": 4.03}, {"text": "And on the top is the\ngasoline crack spread.", "start": 1526.25, "duration": 5.55}, {"text": "And the bottom is the\nheating oil crack spread.", "start": 1531.8, "duration": 3.66}, {"text": "And one can see\nthat as time series,", "start": 1535.46, "duration": 2.26}, {"text": "these actually look stationary.", "start": 1537.72, "duration": 4.14}, {"text": "There certainly doesn't appear\nto be a linear trend up.", "start": 1541.86, "duration": 4.06}, {"text": "But there are, of course, many\nfactors that could affect this.", "start": 1545.92, "duration": 5.47}, {"text": "So with that as motivation, how\nwould we model such a series?", "start": 1551.39, "duration": 7.72}, {"text": "So let's go back to\nour lecture here.", "start": 1559.11, "duration": 2.12}, {"text": "All right, View, full size.", "start": 1566.42, "duration": 2.355}, {"text": "This is going to be a\nvery technical discussion,", "start": 1575.76, "duration": 2.67}, {"text": "but it's, at the end of the day,\nI think fairly straightforward.", "start": 1578.43, "duration": 7.03}, {"text": "And the objective\nactually of this lecture", "start": 1585.46, "duration": 1.75}, {"text": "is to provide an introduction\nto the notation here, which", "start": 1587.21, "duration": 4.03}, {"text": "should make it seem like it's a\nvery straightforward derivation", "start": 1591.24, "duration": 4.62}, {"text": "process of these models.", "start": 1595.86, "duration": 1.94}, {"text": "So let's begin with just a recap\nof the vector autoregressive", "start": 1597.8, "duration": 5.09}, {"text": "model of order p.", "start": 1602.89, "duration": 2.46}, {"text": "This is the extension of\nthe univariate case where", "start": 1605.35, "duration": 2.22}, {"text": "we have a vector C of\nconstants, m constants,", "start": 1607.57, "duration": 5.3}, {"text": "and matrices phi_1 to\nphi_p corresponding", "start": 1612.87, "duration": 4.09}, {"text": "to basically how the\nautoregression of one series", "start": 1616.96, "duration": 4.69}, {"text": "depends on all the other series.", "start": 1621.65, "duration": 3.16}, {"text": "And then there's multivariate\nwhite noise eta_t,", "start": 1624.81, "duration": 3.46}, {"text": "which has mean 0 and some\ncovariance structure in it.", "start": 1628.27, "duration": 5.36}, {"text": "And the stationarity-- if\nthis series were stationary,", "start": 1633.63, "duration": 6.2}, {"text": "then the determinant of\nthis matrix polynomial", "start": 1639.83, "duration": 8.22}, {"text": "would have roots outside the\nunit circle for complex z.", "start": 1648.05, "duration": 5.31}, {"text": "And if it's not stationary,\nthen some of those roots", "start": 1653.36, "duration": 5.93}, {"text": "will be on the unit\ncircle or beyond.", "start": 1659.29, "duration": 2.39}, {"text": "So let's actually go to\nthat non-stationary case", "start": 1661.68, "duration": 3.445}, {"text": "and suppose that the process\nis integrated of order one.", "start": 1665.125, "duration": 5.415}, {"text": "So if we were to take\nfirst differences,", "start": 1670.54, "duration": 2.51}, {"text": "we would have stationarity.", "start": 1673.05, "duration": 1.125}, {"text": "Well, the derivation\nof the model", "start": 1682.69, "duration": 3.81}, {"text": "proceeds by converting the\noriginal vector autoregressive", "start": 1686.5, "duration": 5.65}, {"text": "equation into an\nequation that's mostly", "start": 1692.15, "duration": 3.9}, {"text": "relating to differences but\nwith also some extra terms.", "start": 1696.05, "duration": 3.51}, {"text": "So let's begin the process\nby just subtracting", "start": 1699.56, "duration": 4.57}, {"text": "the lagged value of\nthe multivariate vector", "start": 1704.13, "duration": 2.49}, {"text": "from the original series.", "start": 1706.62, "duration": 2.41}, {"text": "So we subtract X_(t-1)\nfrom both sides,", "start": 1709.03, "duration": 2.26}, {"text": "and we get delta X_t is equal to\nC plus phi_1 minus I_m X_(t-1)", "start": 1711.29, "duration": 6.04}, {"text": "plus the rest.", "start": 1717.33, "duration": 0.87}, {"text": "So that's a very simple step.", "start": 1718.2, "duration": 3.76}, {"text": "We're just subtracting the\nlagged multivariate series", "start": 1721.96, "duration": 4.26}, {"text": "from both sides.", "start": 1726.22, "duration": 3.15}, {"text": "Now, what we want\nto do is convert", "start": 1729.37, "duration": 3.92}, {"text": "the second term in the middle\nline into a difference term.", "start": 1733.29, "duration": 6.64}, {"text": "So what do we do?", "start": 1739.93, "duration": 1.06}, {"text": "Well, we can subtract and add\nphi_1 minus I_m times X_(t-2).", "start": 1740.99, "duration": 6.91}, {"text": "If we do that,\nsubtract and add that,", "start": 1747.9, "duration": 2.54}, {"text": "we then get the delta X_t is\nC plus a multiple of delta", "start": 1750.44, "duration": 3.37}, {"text": "X_(t-1) plus this\nmultiple of X_(t-2).", "start": 1753.81, "duration": 5.72}, {"text": "So we basically\nreduced the equations", "start": 1759.53, "duration": 2.71}, {"text": "to differences in\nthe first two terms", "start": 1762.24, "duration": 3.05}, {"text": "or in the current\nseries and the lagged.", "start": 1765.29, "duration": 4.23}, {"text": "But then we have the original\nseries for lags t minus 2.", "start": 1769.52, "duration": 4.03}, {"text": "We can continue this\nprocess with the third.", "start": 1773.55, "duration": 5.11}, {"text": "And then at the\nend of the day, we", "start": 1778.66, "duration": 3.8}, {"text": "end up getting this equation\nfor the difference of the series", "start": 1782.46, "duration": 3.69}, {"text": "is equal to a constant\nplus a matrix multiple", "start": 1786.15, "duration": 3.15}, {"text": "of the first difference\nmultivariate series,", "start": 1789.3, "duration": 4.58}, {"text": "plus another matrix times\nthe second difference,", "start": 1793.88, "duration": 3.04}, {"text": "all the way down to\nthe p-th difference,", "start": 1796.92, "duration": 4.8}, {"text": "or the p minus first difference.", "start": 1801.72, "duration": 2.04}, {"text": "But at the end,\nwe're left with terms", "start": 1803.76, "duration": 3.64}, {"text": "at p lags that have no\ndifferences in them.", "start": 1807.4, "duration": 3.92}, {"text": "So we've been able to\nrepresent this series", "start": 1811.32, "duration": 3.12}, {"text": "as an autoregressive\nfunction of differences.", "start": 1814.44, "duration": 4.65}, {"text": "But there's also a term on\nthe undifferenced series", "start": 1819.09, "duration": 4.92}, {"text": "at the end that's left over.", "start": 1824.01, "duration": 3.46}, {"text": "And or this argument\ncan actually", "start": 1827.47, "duration": 7.43}, {"text": "proceed by eliminating\ndifferences in the reverse way,", "start": 1834.9, "duration": 3.43}, {"text": "starting with the\np-th lag and going up.", "start": 1838.33, "duration": 4.32}, {"text": "And one then can represent\nthis as delta X_t", "start": 1842.65, "duration": 4.55}, {"text": "is C plus some\nmatrix times just the", "start": 1847.2, "duration": 2.97}, {"text": "lagged series plus various\nmatrices times the differences", "start": 1850.17, "duration": 5.83}, {"text": "going back p minus 1 lags.", "start": 1856.0, "duration": 2.88}, {"text": "And so at the end of\nthe day, this model", "start": 1865.46, "duration": 4.74}, {"text": "basically for delta\nX_t is a constant", "start": 1870.2, "duration": 4.07}, {"text": "plus a matrix times the\nprevious lagged series", "start": 1874.27, "duration": 6.49}, {"text": "or the first lag of the\nmultivariate time series,", "start": 1880.76, "duration": 4.9}, {"text": "plus various autoregressive\nlags of the differenced series.", "start": 1885.66, "duration": 4.66}, {"text": "So these notes give you\nthe formulas for those,", "start": 1892.96, "duration": 3.17}, {"text": "and they're very easy to\nverify if you go through them", "start": 1896.13, "duration": 4.71}, {"text": "one by one.", "start": 1900.84, "duration": 0.754}, {"text": "And when we look at this\nexpression for the model,", "start": 1905.73, "duration": 6.03}, {"text": "this expresses the\nstochastic process model", "start": 1911.76, "duration": 5.51}, {"text": "for the difference series.", "start": 1917.27, "duration": 2.29}, {"text": "This difference\nseries is stationary.", "start": 1919.56, "duration": 4.22}, {"text": "We've eliminated\nthe non-stationarity", "start": 1923.78, "duration": 2.19}, {"text": "in the process.", "start": 1925.97, "duration": 0.66}, {"text": "So that means the\nright-hand side", "start": 1926.63, "duration": 2.53}, {"text": "has to be stationary as well.", "start": 1929.16, "duration": 3.73}, {"text": "And so while the terms which\nare matrix multiples of lags", "start": 1932.89, "duration": 7.0}, {"text": "of the differenced\nseries, those are", "start": 1939.89, "duration": 1.5}, {"text": "going to be stationary\nbecause we're just", "start": 1941.39, "duration": 2.36}, {"text": "taking lags of the\nstationary multivariate time", "start": 1943.75, "duration": 3.93}, {"text": "series, the difference series.", "start": 1947.68, "duration": 1.86}, {"text": "But this pi X_t term has\nto be stationary as well.", "start": 1949.54, "duration": 7.34}, {"text": "So this pi X_t contains\nthe cointegrating terms.", "start": 1956.88, "duration": 4.76}, {"text": "And fitting a sort of\ncointegrated vector", "start": 1961.64, "duration": 4.96}, {"text": "autoregression model involves\nidentifying this term, pi X_t.", "start": 1966.6, "duration": 6.89}, {"text": "And given that the original\nseries had unit roots,", "start": 1973.49, "duration": 7.38}, {"text": "it has to be the case that\npi, the matrix, is singular.", "start": 1980.87, "duration": 5.325}, {"text": "So it's basically\na transformation", "start": 1989.55, "duration": 2.53}, {"text": "of the data that\neliminates that unit", "start": 1992.08, "duration": 3.23}, {"text": "root in the overall series.", "start": 1995.31, "duration": 4.57}, {"text": "So the matrix pi\nis of reduced rank,", "start": 1999.88, "duration": 4.56}, {"text": "and it's either rank\nzero, in which case", "start": 2004.44, "duration": 3.236}, {"text": "there's no cointegrating\nrelationships,", "start": 2007.676, "duration": 1.624}, {"text": "or its rank is less than m.", "start": 2009.3, "duration": 5.2}, {"text": "And the matrix pi does\ndefine the cointegrating", "start": 2014.5, "duration": 4.56}, {"text": "relationships.", "start": 2019.06, "duration": 1.49}, {"text": "Now, these cointegrating\nrelationships", "start": 2020.55, "duration": 2.53}, {"text": "are the relationships in the\nprocess that are stationary.", "start": 2023.08, "duration": 5.91}, {"text": "And so basically there's\na lot of information", "start": 2028.99, "duration": 4.21}, {"text": "in that multivariate series\nwith contemporaneous values", "start": 2033.2, "duration": 4.68}, {"text": "of the series.", "start": 2037.88, "duration": 1.59}, {"text": "There is stationary structure\nat every single time", "start": 2039.47, "duration": 3.03}, {"text": "point, which can be the\ntarget of the modeling.", "start": 2042.5, "duration": 5.699}, {"text": "So this matrix pi is\nof rank r less than m.", "start": 2048.199, "duration": 8.051}, {"text": "And so it can be expressed\nas basically alpha beta", "start": 2056.25, "duration": 5.85}, {"text": "prime, where these matrices\nare of rank r, alpha and beta.", "start": 2062.1, "duration": 8.44}, {"text": "And the columns of beta define\nlinearly independent vectors", "start": 2070.54, "duration": 2.659}, {"text": "which cointegrate x.", "start": 2073.199, "duration": 1.571}, {"text": "And the decomposition\nof pi isn't unique.", "start": 2074.77, "duration": 3.139}, {"text": "You can basically, for any\ninvertible r by r matrix g,", "start": 2077.909, "duration": 5.48}, {"text": "define another set of\ncointegrating relationships.", "start": 2083.389, "duration": 2.961}, {"text": "So in the linear algebra\nstructure of these problems,", "start": 2086.35, "duration": 3.99}, {"text": "there's basically an\nr-dimensional space", "start": 2090.34, "duration": 2.46}, {"text": "where the process is\nstationary, and how", "start": 2092.8, "duration": 3.56}, {"text": "you define the coordinate system\nin that space is up to you", "start": 2096.36, "duration": 5.66}, {"text": "or subject to some choice.", "start": 2102.02, "duration": 6.11}, {"text": "So how do we estimate\nthese models?", "start": 2108.13, "duration": 1.65}, {"text": "Well, rather nice result\nof Sims, Stock, and Watson.", "start": 2109.78, "duration": 5.74}, {"text": "Actually, Sims,\nChristopher Sims,", "start": 2115.52, "duration": 2.28}, {"text": "he got the Nobel Prize a\nfew years ago for his work", "start": 2117.8, "duration": 3.99}, {"text": "in econometrics.", "start": 2121.79, "duration": 1.94}, {"text": "And so this is a rather\nsignificant work that he did.", "start": 2123.73, "duration": 10.12}, {"text": "Anyway, he, together\nwith Stock and Watson,", "start": 2133.85, "duration": 2.89}, {"text": "prove that if you're estimating\na vector autoregression model,", "start": 2136.74, "duration": 4.38}, {"text": "then the least squares\nestimator of the original model", "start": 2141.12, "duration": 4.37}, {"text": "is basically sufficient\nto do an analysis", "start": 2145.49, "duration": 3.66}, {"text": "of this cointegrated vector\nautoregression process.", "start": 2149.15, "duration": 7.45}, {"text": "The parameter estimates\nfrom just fitting", "start": 2156.6, "duration": 2.36}, {"text": "the vector autoregression are\nconsistent for the underlying", "start": 2158.96, "duration": 4.65}, {"text": "parameters.", "start": 2163.61, "duration": 1.047}, {"text": "And they have\nasymptotic distributions", "start": 2164.657, "duration": 1.583}, {"text": "that are identical to those of\nmaximum likelihood estimators.", "start": 2166.24, "duration": 3.74}, {"text": "And so what ends up happening\nis the least squares estimates", "start": 2169.98, "duration": 8.38}, {"text": "of the vector autoregression\nparameters lead", "start": 2178.36, "duration": 3.6}, {"text": "to an estimation\nof the pi matrix.", "start": 2181.96, "duration": 5.31}, {"text": "And the constraints on the pi\nmatrix which are basically pi", "start": 2187.27, "duration": 13.02}, {"text": "is of reduced rank, those\nwill hold asymptotically.", "start": 2200.29, "duration": 4.14}, {"text": "So let's just go back\nto the equation before,", "start": 2204.43, "duration": 4.81}, {"text": "to see if that\nlooks familiar here.", "start": 2209.24, "duration": 5.25}, {"text": "So what that work says\nis that if we basically", "start": 2218.93, "duration": 4.14}, {"text": "fit the linear regression\nmodel regressing the difference", "start": 2223.07, "duration": 4.04}, {"text": "series on the lag of the series\nplus lags of differences,", "start": 2227.11, "duration": 6.82}, {"text": "the least squares estimates\nof these underlying parameters", "start": 2233.93, "duration": 4.66}, {"text": "will give us asymptotically\nefficient estimates", "start": 2238.59, "duration": 3.1}, {"text": "of this overall process.", "start": 2241.69, "duration": 2.37}, {"text": "So we don't need to use any new\ntools to specify these models.", "start": 2244.06, "duration": 7.575}, {"text": "There's an advanced literature\non estimation methods", "start": 2263.8, "duration": 4.31}, {"text": "for these models.", "start": 2268.11, "duration": 1.84}, {"text": "Johansen does describe\nmaximum likelihood estimation", "start": 2269.95, "duration": 5.1}, {"text": "when the innovation terms\nare normally distributed.", "start": 2275.05, "duration": 6.21}, {"text": "And that methodology applies\nreduced rank regression", "start": 2281.26, "duration": 6.01}, {"text": "methodology and\nyields tests for what", "start": 2287.27, "duration": 5.88}, {"text": "the rank is of the\ncointegrating relationship.", "start": 2293.15, "duration": 3.98}, {"text": "And these methods are\nimplemented in our packages.", "start": 2297.13, "duration": 3.14}, {"text": "Let's see.", "start": 2305.71, "duration": 0.71}, {"text": "Let me just go back now\nto the-- so let's see.", "start": 2306.42, "duration": 14.47}, {"text": "The case study on\nthe crack spread data", "start": 2320.89, "duration": 6.8}, {"text": "actually goes through sort of\ntesting for non-stationarity", "start": 2327.69, "duration": 3.68}, {"text": "in these underlying series.", "start": 2331.37, "duration": 2.67}, {"text": "And actually, why don't\nI just show you that?", "start": 2334.04, "duration": 4.32}, {"text": "Let's go back here.", "start": 2338.36, "duration": 1.09}, {"text": "If you can see this, for\nthe crack spread data,", "start": 2357.522, "duration": 5.938}, {"text": "looking at the\ncrude oil futures,", "start": 2363.46, "duration": 1.77}, {"text": "basically the crude oil\nfuture can be evaluated", "start": 2365.23, "duration": 3.22}, {"text": "to see if it's non-stationary.", "start": 2368.45, "duration": 2.34}, {"text": "And there's this augmented\nDickey-Fuller test", "start": 2370.79, "duration": 3.01}, {"text": "for non-stationarity.", "start": 2373.8, "duration": 2.55}, {"text": "And it basically has a null\nhypothesis that the model", "start": 2376.35, "duration": 6.81}, {"text": "or the series is non-stationary,\nor it has a unit root,", "start": 2383.16, "duration": 3.69}, {"text": "versus the alternative\nthat it doesn't.", "start": 2386.85, "duration": 2.19}, {"text": "And so testing that\nnull hypothesis", "start": 2389.04, "duration": 3.14}, {"text": "that it's non-stationary\nyields a p-value of 0.164", "start": 2392.18, "duration": 3.941}, {"text": "for CLC1, the first\nnearest contract,", "start": 2396.121, "duration": 5.569}, {"text": "near month contract of\nthe futures for crude.", "start": 2401.69, "duration": 5.71}, {"text": "And so the data\nsuggests that crude", "start": 2407.4, "duration": 3.83}, {"text": "has a distribution that's\nnon-stationary, integrated", "start": 2411.23, "duration": 2.83}, {"text": "order 1.", "start": 2414.06, "duration": 2.43}, {"text": "And the HOC1 also basically\nhas a test for-- p-value", "start": 2416.49, "duration": 7.46}, {"text": "for non-stationarity of 0.3265.", "start": 2423.95, "duration": 3.6}, {"text": "So we can't reject\nnon-stationarity or unit root", "start": 2427.55, "duration": 3.45}, {"text": "in those series with\nthese test statistics.", "start": 2431.0, "duration": 3.15}, {"text": "In analyzing the data, this\nsuggests that we basically", "start": 2434.15, "duration": 5.11}, {"text": "need to accommodate that\nnon-stationarity when", "start": 2439.26, "duration": 2.12}, {"text": "we specify the models.", "start": 2441.38, "duration": 1.77}, {"text": "Let me just see if\nthere's some results here.", "start": 2446.925, "duration": 2.205}, {"text": "For this series,\nactually the case notes", "start": 2515.18, "duration": 3.88}, {"text": "will go through actually\nconducting this Johansen", "start": 2519.06, "duration": 2.21}, {"text": "procedure for\ntesting for the rank", "start": 2521.27, "duration": 2.09}, {"text": "of the cointegrated process.", "start": 2523.36, "duration": 2.34}, {"text": "And that test basically has\ndifferent test statistic", "start": 2525.7, "duration": 5.93}, {"text": "for testing whether the rank is\n0, 1, less than or equal to 1,", "start": 2531.63, "duration": 3.63}, {"text": "or less than or equal to 2.", "start": 2535.26, "duration": 1.61}, {"text": "And one can see that\nthere's marginal-- the test", "start": 2536.87, "duration": 2.78}, {"text": "statistic is almost\nsignificant at the 10% level", "start": 2539.65, "duration": 6.28}, {"text": "for the overall series.", "start": 2545.93, "duration": 3.85}, {"text": "It's not significant\nfor the rank", "start": 2549.78, "duration": 2.89}, {"text": "being less than or equal to 1.", "start": 2552.67, "duration": 1.79}, {"text": "And so these results, it\ndoesn't suggest there's", "start": 2554.46, "duration": 3.93}, {"text": "strong non-stationarity.", "start": 2558.39, "duration": 2.49}, {"text": "But certainly with\nthat non-stationarity", "start": 2560.88, "duration": 4.48}, {"text": "is no more than rank\none for the series.", "start": 2565.36, "duration": 3.26}, {"text": "And the eigenvector\ncorresponding", "start": 2568.62, "duration": 3.41}, {"text": "to the stationary\nrelationship is", "start": 2572.03, "duration": 2.04}, {"text": "given by these coefficients\nof 1 on the crude oil future,", "start": 2574.07, "duration": 6.87}, {"text": "1.3 on the RBOB and minus\n1.7 on the heating oil.", "start": 2580.94, "duration": 4.77}, {"text": "So what this suggests\nis that there's", "start": 2588.64, "duration": 4.72}, {"text": "considerable variability in\nthese energy futures contracts.", "start": 2593.36, "duration": 7.52}, {"text": "What appears to be stationary\nis some linear combination", "start": 2600.88, "duration": 3.51}, {"text": "of crude plus gasoline\nminus heating oil.", "start": 2604.39, "duration": 4.28}, {"text": "And in terms of why does\nit combine that way,", "start": 2608.67, "duration": 4.42}, {"text": "well, there are all\nkinds of factors", "start": 2613.09, "duration": 2.19}, {"text": "that we went through-- cost of\nrefining, supply and demand,", "start": 2615.28, "duration": 3.48}, {"text": "seasonality, which\naffect things.", "start": 2618.76, "duration": 2.61}, {"text": "And so when analyzed, sort\nof ignoring seasonality,", "start": 2621.37, "duration": 4.6}, {"text": "these would be the linear\ncombinations that appear", "start": 2625.97, "duration": 4.03}, {"text": "to be stationary over time.", "start": 2630.0, "duration": 1.312}, {"text": "Yeah?", "start": 2631.312, "duration": 0.5}, {"text": "AUDIENCE: Why did you\nchoose to use the futures", "start": 2633.722, "duration": 1.958}, {"text": "prices as opposed to the spot?", "start": 2635.68, "duration": 1.249}, {"text": "And how did you combine the\ndata with actual [INAUDIBLE]?", "start": 2636.929, "duration": 3.241}, {"text": "PROFESSOR: I chose this\nbecause if refiners are wanting", "start": 2640.17, "duration": 7.65}, {"text": "to hedge their risks, then they\nwill go to the futures market", "start": 2647.82, "duration": 4.31}, {"text": "to hedge those.", "start": 2652.13, "duration": 1.93}, {"text": "And so working with\nthese data, one", "start": 2654.06, "duration": 3.03}, {"text": "can then consider problems of\nhedging refinery production", "start": 2657.09, "duration": 7.28}, {"text": "risks.", "start": 2664.37, "duration": 1.09}, {"text": "And so that's why.", "start": 2665.46, "duration": 3.16}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 2668.62, "duration": 2.34}, {"text": "PROFESSOR: OK, well, the Energy\nInformation Administration", "start": 2670.96, "duration": 2.84}, {"text": "provides historical data\nwhich gives the first month,", "start": 2673.8, "duration": 5.47}, {"text": "the second month, the third\nmonth available for each", "start": 2679.27, "duration": 2.76}, {"text": "of these contracts.", "start": 2682.03, "duration": 1.37}, {"text": "And so I chose the\nfirst month contract", "start": 2683.4, "duration": 4.32}, {"text": "for each of these features.", "start": 2687.72, "duration": 1.96}, {"text": "Those 10 are the most liquid.", "start": 2689.68, "duration": 2.3}, {"text": "Depending on what\none is hedging,", "start": 2691.98, "duration": 2.46}, {"text": "one would use perhaps\nlonger periods for those.", "start": 2694.44, "duration": 4.11}, {"text": "There's some very\nnice finance problems", "start": 2698.55, "duration": 3.9}, {"text": "dealing with hedging,\nhedging these kinds of risks,", "start": 2702.45, "duration": 2.24}, {"text": "and as well as trading\nthese kinds of risk.", "start": 2704.69, "duration": 2.46}, {"text": "Traders can try to exploit\nshort term movements in these.", "start": 2707.15, "duration": 3.88}, {"text": "Anyway, I'll let you\nlook through these,", "start": 2729.87, "duration": 1.95}, {"text": "the case note later.", "start": 2731.82, "duration": 0.94}, {"text": "And it does provide some detail\non the coefficient estimates.", "start": 2732.76, "duration": 4.05}, {"text": "And one can basically\nget a handle", "start": 2736.81, "duration": 2.309}, {"text": "on how these things\nare being specified.", "start": 2739.119, "duration": 1.666}, {"text": "So let's go back.", "start": 2743.98, "duration": 2.19}, {"text": "The next topic I want to cover\nis linear state-space models.", "start": 2758.26, "duration": 8.23}, {"text": "It turns out that many\nof these time series", "start": 2766.49, "duration": 6.235}, {"text": "models appropriate in\neconomics and finance", "start": 2772.725, "duration": 2.365}, {"text": "can be expressed as a\nlinear state-space model.", "start": 2775.09, "duration": 5.2}, {"text": "I'm going to introduce the\ngeneral notation first and then", "start": 2788.59, "duration": 3.66}, {"text": "provide illustrations\nof this general notation", "start": 2792.25, "duration": 2.85}, {"text": "with a number of\ndifferent examples.", "start": 2795.1, "duration": 3.38}, {"text": "So the formulation is we have\nbasically an observation vector", "start": 2798.48, "duration": 7.725}, {"text": "at time t, y_t.", "start": 2806.205, "duration": 1.215}, {"text": "This is our multivariate time\nseries that we're modeling.", "start": 2807.42, "duration": 3.31}, {"text": "Now, I've chosen it\nto be k-dimensional", "start": 2810.73, "duration": 3.2}, {"text": "for the observations.", "start": 2813.93, "duration": 3.97}, {"text": "There's an underlying\nstate vector", "start": 2817.9, "duration": 2.82}, {"text": "that's of m dimensions,\nwhich basically characterizes", "start": 2820.72, "duration": 3.67}, {"text": "the state of the\nprocess at time t.", "start": 2824.39, "duration": 7.35}, {"text": "There's an observation error\nvector at time t, epsilon_t.", "start": 2831.74, "duration": 3.5}, {"text": "So it's k by 1 as well,\ncorresponding to y.", "start": 2835.24, "duration": 3.59}, {"text": "And there's a state transition\ninnovation error vector,", "start": 2838.83, "duration": 3.37}, {"text": "which is n by 1,\nwhich actually can", "start": 2842.2, "duration": 9.04}, {"text": "be different from m, the\ndimension of the state vector.", "start": 2851.24, "duration": 4.8}, {"text": "So we have-- in the state\nspace specification,", "start": 2856.04, "duration": 5.26}, {"text": "we're going to specify\ntwo equations, one", "start": 2861.3, "duration": 2.42}, {"text": "for how the states evolve\nover time and another for how", "start": 2863.72, "duration": 3.92}, {"text": "the observations or\nmeasurements evolve,", "start": 2867.64, "duration": 2.45}, {"text": "depending on the\nunderlying states.", "start": 2870.09, "duration": 1.82}, {"text": "So let's first focus\non a state equation", "start": 2871.91, "duration": 3.49}, {"text": "which describes how\nthe state progresses", "start": 2875.4, "duration": 3.09}, {"text": "from the state at time t to\nthe state at time t plus 1.", "start": 2878.49, "duration": 7.19}, {"text": "Because this is a linear\nstate-space model,", "start": 2885.68, "duration": 3.35}, {"text": "basically the state\nat t plus 1 is", "start": 2889.03, "duration": 1.68}, {"text": "going to be some linear\nfunction of the states at time", "start": 2890.71, "duration": 2.69}, {"text": "t plus some noise.", "start": 2893.4, "duration": 3.24}, {"text": "And that noise is\ngiven by eta_t,", "start": 2896.64, "duration": 5.93}, {"text": "being independent identically\ndistributed white noise,", "start": 2902.57, "duration": 4.1}, {"text": "or normally distributed\nwith some covariance matrix", "start": 2906.67, "duration": 4.93}, {"text": "Q_t, positive definite.", "start": 2911.6, "duration": 2.31}, {"text": "And R_t is some\nlinear transformation", "start": 2913.91, "duration": 3.83}, {"text": "of those, which\ncharacterize the uncertainty", "start": 2917.74, "duration": 3.44}, {"text": "in the particular states.", "start": 2921.18, "duration": 1.7}, {"text": "So there's a great\ndeal of flexibility", "start": 2922.88, "duration": 2.28}, {"text": "here in how things\ndepend on each other.", "start": 2925.16, "duration": 2.67}, {"text": "And right now, it will appear\njust like a lot of notation.", "start": 2927.83, "duration": 5.26}, {"text": "But as we see it\nin different cases,", "start": 2933.09, "duration": 1.61}, {"text": "you'll see how these\nterms come into play.", "start": 2934.7, "duration": 3.05}, {"text": "And they're very\nstraightforward.", "start": 2937.75, "duration": 1.51}, {"text": "So we're considering simple\nlinear transformations", "start": 2942.51, "duration": 2.29}, {"text": "of the states plus noise.", "start": 2944.8, "duration": 2.28}, {"text": "And then the observation\nequation or measurement", "start": 2947.08, "duration": 2.61}, {"text": "equation is a linear\ntransformation", "start": 2949.69, "duration": 3.39}, {"text": "of the underlying\nstates plus noise.", "start": 2953.08, "duration": 1.585}, {"text": "So the matrix Z_t is the\nobservation coefficients", "start": 2957.23, "duration": 3.0}, {"text": "matrix.", "start": 2960.23, "duration": 1.27}, {"text": "And the noise or innovations\nepsilon_t are, we'll assume,", "start": 2961.5, "duration": 4.292}, {"text": "independent\nidentically distributed", "start": 2965.792, "duration": 1.458}, {"text": "normal, multivariate\nnormal random variables", "start": 2967.25, "duration": 1.833}, {"text": "with some covariance matrix H_t.", "start": 2969.083, "duration": 4.467}, {"text": "To be fully general,\nthe subscript t", "start": 2973.55, "duration": 2.21}, {"text": "means the covariance\ncan depend on time t.", "start": 2975.76, "duration": 5.04}, {"text": "It doesn't have to, but it can.", "start": 2980.8, "duration": 3.98}, {"text": "These two equations\ncan be written together", "start": 2984.78, "duration": 3.82}, {"text": "in a joint equation where\nwe see that the underlying", "start": 2988.6, "duration": 4.23}, {"text": "state at time t, s, gets\ntransformed with T sub t", "start": 2992.83, "duration": 6.54}, {"text": "to the state at t plus 1 plus\nresidual innovation term.", "start": 2999.37, "duration": 5.18}, {"text": "And the observation equation\ny_t is Z_t s_t plus that.", "start": 3004.55, "duration": 4.17}, {"text": "So we're representing how\nthe states evolve over time", "start": 3008.72, "duration": 3.71}, {"text": "and how the observations\ndepend on the underlying", "start": 3012.43, "duration": 2.48}, {"text": "states in this joint equation.", "start": 3014.91, "duration": 1.905}, {"text": "And the structure of\nbasically this sort", "start": 3019.77, "duration": 4.18}, {"text": "of linear function of states\nplus error, the error term u_t", "start": 3023.95, "duration": 4.45}, {"text": "here is normally distributed\nwith covariance matrix omega,", "start": 3028.4, "duration": 5.34}, {"text": "which has this structure.", "start": 3033.74, "duration": 2.95}, {"text": "It's a block diagonal.", "start": 3036.69, "duration": 2.16}, {"text": "We have the covariance\nof the epsilons as the H.", "start": 3038.85, "duration": 4.092}, {"text": "And the covariance of R_t\neta_t is R_t Q_t R_t transpose.", "start": 3042.942, "duration": 5.918}, {"text": "So you may recall when we\ntake a covariance matrix", "start": 3048.86, "duration": 5.8}, {"text": "of linear function of random\nvariables given by a matrix,", "start": 3054.66, "duration": 6.55}, {"text": "then it's that linear function\nR times the covariance matrix", "start": 3061.21, "duration": 4.1}, {"text": "times the transpose.", "start": 3065.31, "duration": 2.66}, {"text": "So that term comes into play.", "start": 3067.97, "duration": 4.94}, {"text": "So let's see how a\ncapital asset pricing", "start": 3072.91, "duration": 3.95}, {"text": "model with time-varying\nbetas can be represented", "start": 3076.86, "duration": 2.86}, {"text": "as a linear state-space model.", "start": 3079.72, "duration": 1.82}, {"text": "You'll recall, we discussed\nthis model a few lectures ago,", "start": 3084.22, "duration": 4.96}, {"text": "where we have the excess\nreturn of a given stock, r_t,", "start": 3089.18, "duration": 4.69}, {"text": "is a linear function of the\nexcess return of the market", "start": 3093.87, "duration": 5.28}, {"text": "portfolio, r_(m,t), plus error.", "start": 3099.15, "duration": 4.56}, {"text": "What we're going to do now\nis extend that previous model", "start": 3103.71, "duration": 4.6}, {"text": "by adding time dependence, t,\nto the regression parameters.", "start": 3108.31, "duration": 5.86}, {"text": "The alpha is not a constant.", "start": 3114.17, "duration": 2.15}, {"text": "It is going to vary by time.", "start": 3116.32, "duration": 1.74}, {"text": "And the beta is also\ngoing to very by time.", "start": 3118.06, "duration": 4.64}, {"text": "And how will they vary by time?", "start": 3122.7, "duration": 2.11}, {"text": "Well, we're going to\nassume that the alpha_t is", "start": 3124.81, "duration": 5.22}, {"text": "a Gaussian random walk.", "start": 3130.03, "duration": 3.49}, {"text": "And the beta is also a\nGaussian random walk.", "start": 3133.52, "duration": 4.462}, {"text": "And with that set up, we\nhave the following expression", "start": 3148.81, "duration": 4.86}, {"text": "for the state equation.", "start": 3153.67, "duration": 1.78}, {"text": "OK, the state equation, which\nis just the unknown parameters--", "start": 3155.45, "duration": 3.01}, {"text": "it's the alpha and the\nbeta at given time t.", "start": 3158.46, "duration": 2.53}, {"text": "The state at time\nt gets adjusted", "start": 3163.66, "duration": 2.06}, {"text": "to the state at time t plus 1\nby just adding these random walk", "start": 3165.72, "duration": 3.62}, {"text": "terms to it.", "start": 3169.34, "duration": 0.76}, {"text": "So it's a very simple process.", "start": 3170.1, "duration": 2.19}, {"text": "We have the identity\ntimes the previous state", "start": 3172.29, "duration": 2.98}, {"text": "plus the identity times this\nvector of these innovations.", "start": 3175.27, "duration": 3.66}, {"text": "So s_(t+1) is equal to\nT_t s_t plus R_t eta_t,", "start": 3178.93, "duration": 5.19}, {"text": "where this matrix, T sub\nt and R sub t are trivial;", "start": 3184.12, "duration": 4.6}, {"text": "they're just the identity.", "start": 3188.72, "duration": 1.57}, {"text": "And eta_t has a\ncovariance matrix", "start": 3190.29, "duration": 5.42}, {"text": "which is just given by\nQ_t, sigma squared nu,", "start": 3195.71, "duration": 3.275}, {"text": "sigma squared epsilon.", "start": 3198.985, "duration": 3.575}, {"text": "This is a complex way, perhaps,\nof representing this model.", "start": 3202.56, "duration": 6.12}, {"text": "But it puts this simple model\ninto that linear state-space", "start": 3208.68, "duration": 3.93}, {"text": "framework.", "start": 3212.61, "duration": 0.5}, {"text": "Now, the observation equation\nis given by this expression", "start": 3216.67, "duration": 8.99}, {"text": "defining the Z_t matrix as the\nunit element and r_(m,t) So", "start": 3225.66, "duration": 6.59}, {"text": "it's basically a row vector, or\na row matrix, one-row matrix.", "start": 3232.25, "duration": 5.9}, {"text": "And epsilon_t is the\nwhite noise process.", "start": 3238.15, "duration": 4.03}, {"text": "Now, putting these\nequations together,", "start": 3242.18, "duration": 3.39}, {"text": "we basically have the equation\nfor the state transition", "start": 3245.57, "duration": 3.7}, {"text": "and the observation\nequation together.", "start": 3249.27, "duration": 3.96}, {"text": "We have this form for that.", "start": 3253.23, "duration": 2.89}, {"text": "So now, let's\nconsider a second case", "start": 3265.78, "duration": 2.742}, {"text": "of linear regression\nmodels where", "start": 3268.522, "duration": 2.838}, {"text": "we have a time varying beta.", "start": 3271.36, "duration": 2.42}, {"text": "In a way, this case\nwe just looked at", "start": 3273.78, "duration": 3.36}, {"text": "is a simple case of that.", "start": 3277.14, "duration": 2.859}, {"text": "But let's look at\na more general case", "start": 3279.999, "duration": 1.541}, {"text": "where we have p independent\nvariables, which", "start": 3281.54, "duration": 3.73}, {"text": "could be time-varying.", "start": 3285.27, "duration": 1.92}, {"text": "So we have a\nregression model almost", "start": 3287.19, "duration": 4.48}, {"text": "as we've considered\nit previously.", "start": 3291.67, "duration": 2.37}, {"text": "y_t is equal to x_t transpose\nbeta_t plus epsilon_t.", "start": 3294.04, "duration": 4.36}, {"text": "The difference now is our\nregression coefficients", "start": 3298.4, "duration": 2.45}, {"text": "beta are allowed to\nchange over time.", "start": 3300.85, "duration": 2.73}, {"text": "How do they change over time?", "start": 3309.88, "duration": 1.3}, {"text": "Well, we're going to\nassume that those also", "start": 3311.18, "duration": 2.94}, {"text": "follow independent random\nwalks with variances", "start": 3314.12, "duration": 5.0}, {"text": "of the random walks that\nmay depend on the component.", "start": 3319.12, "duration": 3.97}, {"text": "So the joint\nstate-space equation", "start": 3323.09, "duration": 1.68}, {"text": "here is given by the identity\ntimes s_t plus eta_t.", "start": 3324.77, "duration": 7.76}, {"text": "That's basically the random\nwalk process for the underlying", "start": 3332.53, "duration": 3.83}, {"text": "regression parameters.", "start": 3336.36, "duration": 1.24}, {"text": "And y_t is equal\nto x_t transpose", "start": 3337.6, "duration": 4.76}, {"text": "times the same regression\nparameters plus the observation", "start": 3342.36, "duration": 3.721}, {"text": "error.", "start": 3346.081, "duration": 0.499}, {"text": "I guess needless to say, if we\nconsider the special case where", "start": 3356.48, "duration": 3.29}, {"text": "the random walk\nprocess is degenerate", "start": 3359.77, "duration": 4.84}, {"text": "and they're basically\nsteps of size zero,", "start": 3364.61, "duration": 2.71}, {"text": "then we get the normal linear\nregression model coming out", "start": 3367.32, "duration": 3.09}, {"text": "of this.", "start": 3370.41, "duration": 1.46}, {"text": "If we were to be specifying\nthe linear state-space", "start": 3371.87, "duration": 6.08}, {"text": "implementation of this model and\nconsider successive estimates", "start": 3377.95, "duration": 4.86}, {"text": "of the model\nparameters over time,", "start": 3382.81, "duration": 2.46}, {"text": "then these equations would\ngive us recursive estimates", "start": 3385.27, "duration": 3.7}, {"text": "for updating\nregressions as we add", "start": 3388.97, "duration": 5.11}, {"text": "additional values to the\ndata, additional observations", "start": 3394.08, "duration": 3.42}, {"text": "to the data.", "start": 3397.5, "duration": 0.5}, {"text": "Let's look at autoregressive\nmodels of order p.", "start": 3403.88, "duration": 6.08}, {"text": "The autoregressive model of\norder p for a univariate time", "start": 3409.96, "duration": 5.82}, {"text": "series has the setup given here.", "start": 3415.78, "duration": 5.89}, {"text": "It's a polynomial\nlag of the response", "start": 3421.67, "duration": 5.8}, {"text": "variable y_t is equal to\nthe innovation epsilon_t.", "start": 3427.47, "duration": 3.47}, {"text": "And we can define\nthe state vector", "start": 3430.94, "duration": 5.19}, {"text": "to be equal to the vector of\np values, p successive values", "start": 3436.13, "duration": 8.85}, {"text": "of the process.", "start": 3444.98, "duration": 2.67}, {"text": "And so we basically\nget a combination", "start": 3447.65, "duration": 6.06}, {"text": "here of the observation equation\nand state equation joining", "start": 3453.71, "duration": 4.99}, {"text": "where basically\none of the states", "start": 3458.7, "duration": 8.02}, {"text": "is actually equal\nto the observation.", "start": 3466.72, "duration": 2.04}, {"text": "And basically, with\nthis definition", "start": 3468.76, "duration": 3.84}, {"text": "for a state of the vector\nat the next time point t,", "start": 3472.6, "duration": 6.56}, {"text": "that is equal to this\nlinear transformation", "start": 3479.16, "duration": 4.57}, {"text": "of the lagged state vector\nplus that innovation term.", "start": 3483.73, "duration": 5.384}, {"text": "I dropped the mic.", "start": 3489.114, "duration": 1.494}, {"text": "So the notation here\nshows the structure", "start": 3496.6, "duration": 4.88}, {"text": "for how this linear\nstate-space model is evolving.", "start": 3501.48, "duration": 4.76}, {"text": "Basically, the\nobservation equation", "start": 3506.24, "duration": 2.85}, {"text": "is the linear\ncombination of the five", "start": 3509.09, "duration": 3.32}, {"text": "multiples of lags of the\nvalues plus the residual.", "start": 3512.41, "duration": 4.09}, {"text": "And the previous\nlags of the states", "start": 3516.5, "duration": 3.74}, {"text": "are just simply the identities\ntimes those values, shifted.", "start": 3520.24, "duration": 5.96}, {"text": "So it's a very simple structure\nfor the autoregressive process", "start": 3526.2, "duration": 5.49}, {"text": "as a linear state-space model.", "start": 3531.69, "duration": 1.741}, {"text": "We have, as I was just saying,\nfor the transition matrix T sub", "start": 3536.66, "duration": 5.81}, {"text": "t, this matrix and the\nobservation equation", "start": 3542.47, "duration": 7.28}, {"text": "is essentially picking out\nthe first element of the state", "start": 3549.75, "duration": 3.98}, {"text": "vector, which has no\nmeasurement error.", "start": 3553.73, "duration": 2.81}, {"text": "So that simplifies that.", "start": 3556.54, "duration": 1.95}, {"text": "The moving average\nmodel of order q", "start": 3561.94, "duration": 5.27}, {"text": "could also be expressed as\na linear state-space model.", "start": 3567.21, "duration": 2.49}, {"text": "Remember, the\nmoving average model", "start": 3577.24, "duration": 1.58}, {"text": "is one where our response\nvariable, y, is simply", "start": 3578.82, "duration": 4.21}, {"text": "some linear combination\nof innovations,", "start": 3583.03, "duration": 5.26}, {"text": "q past innovations.", "start": 3588.29, "duration": 2.21}, {"text": "And this state\nvector, if we consider", "start": 3590.5, "duration": 4.85}, {"text": "the state vector just\nbeing basically q", "start": 3595.35, "duration": 4.83}, {"text": "lags of the innovations,\nthen the transition", "start": 3600.18, "duration": 4.22}, {"text": "of those underlying states is\ngiven by this expression here.", "start": 3604.4, "duration": 4.38}, {"text": "And we have a state equation,\nan observation equation,", "start": 3614.69, "duration": 3.08}, {"text": "which has these forms for these\nvarious transition matrices", "start": 3617.77, "duration": 5.73}, {"text": "and for how the innovation\nterms are related.", "start": 3623.5, "duration": 7.115}, {"text": "Let me just finish\nup with example", "start": 3640.84, "duration": 2.32}, {"text": "showing with the autoregressive\nmoving average model.", "start": 3643.16, "duration": 4.62}, {"text": "And many years ago,\nit was actually", "start": 3647.78, "duration": 1.56}, {"text": "very difficult to\nspecify the estimation", "start": 3649.34, "duration": 6.15}, {"text": "methods for autoregressive\nmoving average models.", "start": 3655.49, "duration": 3.412}, {"text": "But the implementation\nof these models", "start": 3658.902, "duration": 1.898}, {"text": "as linear state-space models\nfacilitated that greatly.", "start": 3660.8, "duration": 4.79}, {"text": "And with the ARMA model,\nthe setup basically", "start": 3665.59, "duration": 7.44}, {"text": "is a combination of\nthe autoregressive", "start": 3673.03, "duration": 1.7}, {"text": "moving average processes.", "start": 3674.73, "duration": 2.17}, {"text": "We have an\nautoregression of the y's", "start": 3676.9, "duration": 3.38}, {"text": "is equal to a moving\naverage of the residuals", "start": 3680.28, "duration": 4.439}, {"text": "or the innovations.", "start": 3684.719, "duration": 0.791}, {"text": "And it's convenient in the setup\nfor linear state-space models", "start": 3688.17, "duration": 4.38}, {"text": "to define the dimension m,\nwhich is the maximum of p and q", "start": 3692.55, "duration": 5.17}, {"text": "plus 1, and think of having\nbasically a possibly m order", "start": 3697.72, "duration": 8.14}, {"text": "polynomial lag for each\nof those two series.", "start": 3705.86, "duration": 5.0}, {"text": "And we can basically\nconstrain those values", "start": 3710.86, "duration": 4.2}, {"text": "to be 0 if m is greater than\np or m is greater than q.", "start": 3715.06, "duration": 4.074}, {"text": "And Harvey, in a very\nimportant work in '93,", "start": 3726.88, "duration": 4.36}, {"text": "actually defined a particular\nstate-space representation", "start": 3731.24, "duration": 5.84}, {"text": "for this process.", "start": 3737.08, "duration": 2.27}, {"text": "And I guess it's\nimportant to know", "start": 3739.35, "duration": 1.63}, {"text": "that with these linear\nstate-space models,", "start": 3740.98, "duration": 3.33}, {"text": "we're dealing with\ncharacterizing structure", "start": 3744.31, "duration": 4.72}, {"text": "in m-dimensional space.", "start": 3749.03, "duration": 2.72}, {"text": "There's often some choice in how\nyou represent your underlying", "start": 3751.75, "duration": 3.76}, {"text": "states.", "start": 3755.51, "duration": 2.16}, {"text": "You can basically\nre-parametrize the models", "start": 3757.67, "duration": 4.76}, {"text": "by considering invertible\nlinear transformations", "start": 3762.43, "duration": 4.65}, {"text": "of the underlying states.", "start": 3767.08, "duration": 2.68}, {"text": "So let me go back here.", "start": 3769.76, "duration": 3.06}, {"text": "In expressing the state\nequation generally", "start": 3776.7, "duration": 3.29}, {"text": "is T sub t s_t plus R_t eta_t.", "start": 3779.99, "duration": 4.2}, {"text": "This matrix T sub t\nand st-- basically s_t", "start": 3784.19, "duration": 4.35}, {"text": "can be replaced by a linear\ntransformation of s_t,", "start": 3788.54, "duration": 2.74}, {"text": "so long as we multiply\nthe T sub t by the inverse", "start": 3791.28, "duration": 5.45}, {"text": "of that transformation.", "start": 3796.73, "duration": 1.12}, {"text": "So there's flexibility\nin the choice", "start": 3797.85, "duration": 1.96}, {"text": "of our linear state-space\nspecification.", "start": 3799.81, "duration": 2.53}, {"text": "And so there really are many\ndifferent equivalent linear", "start": 3802.34, "duration": 6.48}, {"text": "state-space models for a\ngiven process depending", "start": 3808.82, "duration": 4.56}, {"text": "on exactly how you\ndefine the states", "start": 3813.38, "duration": 2.22}, {"text": "and the underlying\ntransformation matrix T.", "start": 3815.6, "duration": 3.89}, {"text": "And the beauty of Harvey's\nwork was coming up", "start": 3819.49, "duration": 5.41}, {"text": "with a nice representation\nfor the states,", "start": 3824.9, "duration": 2.59}, {"text": "where we had very simple forms\nfor the various matrices.", "start": 3827.49, "duration": 5.61}, {"text": "And the lecture notes here\ngo through the derivation", "start": 3833.1, "duration": 3.9}, {"text": "of that for the ARMA process.", "start": 3837.0, "duration": 2.43}, {"text": "And this derivation\nis-- I just want", "start": 3839.43, "duration": 5.06}, {"text": "to go through the\nfirst case just", "start": 3844.49, "duration": 3.75}, {"text": "to highlight how\nthe argument goes.", "start": 3848.24, "duration": 2.78}, {"text": "We basically have this equation,\nwhich is the original equation", "start": 3851.02, "duration": 4.07}, {"text": "for an ARMA(p,q) process.", "start": 3855.09, "duration": 2.255}, {"text": "And Harvey says, well,\ndefine the first--", "start": 3860.18, "duration": 5.63}, {"text": "or the state at time t to\nbe equal to the observation", "start": 3865.81, "duration": 3.65}, {"text": "at time t.", "start": 3869.46, "duration": 2.36}, {"text": "If we do that, then how\ndoes this equation relate", "start": 3871.82, "duration": 6.43}, {"text": "to the basically-- this is the\nstate at the next time point, t", "start": 3878.25, "duration": 7.75}, {"text": "plus 1, is equal to phi_1\ntimes the state at time t,", "start": 3886.0, "duration": 4.61}, {"text": "plus a second state at time\nt and a residual innovation", "start": 3890.61, "duration": 9.73}, {"text": "eta_t.", "start": 3900.34, "duration": 1.08}, {"text": "So by choosing the first state\nto be the observation value", "start": 3901.42, "duration": 7.69}, {"text": "at that time, we can then\nsolve for the second state,", "start": 3909.11, "duration": 7.57}, {"text": "which is given by\nthis expression,", "start": 3916.68, "duration": 3.13}, {"text": "just by rewriting our model\nequation in terms of s_(1,t),", "start": 3919.81, "duration": 5.92}, {"text": "s_(2,t) and eta_t.", "start": 3925.73, "duration": 2.15}, {"text": "So this s_(2,t) is this function\nof the observations and eta_t.", "start": 3927.88, "duration": 9.07}, {"text": "So it's a very\nsimple specification", "start": 3936.95, "duration": 2.49}, {"text": "of the second state.", "start": 3939.44, "duration": 2.38}, {"text": "Just what is that\nsecond state element", "start": 3941.82, "duration": 6.2}, {"text": "given this definition\nof the first one?", "start": 3948.02, "duration": 2.5}, {"text": "And one can do this\nprocess iteratively", "start": 3950.52, "duration": 4.13}, {"text": "getting rid of the\nobservations and replacing them", "start": 3954.65, "duration": 4.53}, {"text": "by underlying states.", "start": 3959.18, "duration": 2.11}, {"text": "And at the end of\nthe day, you end up", "start": 3961.29, "duration": 2.48}, {"text": "with this very simple form\nfor the transition matrix T.", "start": 3963.77, "duration": 5.72}, {"text": "Basically, the T has the\nautoregressive components", "start": 3969.49, "duration": 4.46}, {"text": "as the first column\nof the T matrix.", "start": 3973.95, "duration": 2.46}, {"text": "And this R matrix has\nthis vector of the moving", "start": 3976.41, "duration": 4.03}, {"text": "average components.", "start": 3980.44, "duration": 2.11}, {"text": "So it's a very nice way\nto represent the model.", "start": 3982.55, "duration": 5.78}, {"text": "Coming up with it was something\nvery clever that he did.", "start": 3988.33, "duration": 4.66}, {"text": "But what one can see is\nthat this basic model where", "start": 3992.99, "duration": 3.59}, {"text": "you have the states\ntransitioning according", "start": 3996.58, "duration": 5.04}, {"text": "to a linear transformation of\nthe previous state plus error,", "start": 4001.62, "duration": 3.92}, {"text": "and the observation being some\nfunction of the current states,", "start": 4005.54, "duration": 4.37}, {"text": "plus error or not, depending\non the formulation,", "start": 4009.91, "duration": 4.209}, {"text": "is the representation.", "start": 4014.119, "duration": 0.916}, {"text": "Now, with all of\nthese models, a reason", "start": 4018.2, "duration": 5.57}, {"text": "why linear state-space\nmodeling is in fact effective", "start": 4023.77, "duration": 5.09}, {"text": "is that their specification is\nfully specified with the Kalman", "start": 4028.86, "duration": 10.851}, {"text": "filter.", "start": 4039.711, "duration": 0.499}, {"text": "So with this formulation of\nlinear state-space models,", "start": 4042.73, "duration": 9.37}, {"text": "the Kalman filter\nas a methodology is", "start": 4052.1, "duration": 4.9}, {"text": "the recursive computation\nof the probability density", "start": 4057.0, "duration": 4.38}, {"text": "functions for the underlying\nstates at basically", "start": 4061.38, "duration": 7.155}, {"text": "t plus 1 given\ninformation up to time t,", "start": 4068.535, "duration": 3.885}, {"text": "as well as the joint\ndensity of the future state", "start": 4072.42, "duration": 4.29}, {"text": "and the future observation at\nt plus 1, given information up", "start": 4076.71, "duration": 3.09}, {"text": "to time t.", "start": 4079.8, "duration": 2.57}, {"text": "And also just the\nmarginal distribution", "start": 4082.37, "duration": 3.15}, {"text": "of the next observation given\nthe information up to time t.", "start": 4085.52, "duration": 4.86}, {"text": "So what I want to do is\njust go through with you", "start": 4100.49, "duration": 6.02}, {"text": "how the Kalman filter is\nimplemented and defined.", "start": 4106.51, "duration": 5.04}, {"text": "And the implementation\nof the Kalman filter", "start": 4111.55, "duration": 3.82}, {"text": "requires us to have some\nnotation that's a bit involved,", "start": 4115.37, "duration": 5.569}, {"text": "but we'll hopefully explain it\nso it's very straightforward.", "start": 4120.939, "duration": 5.771}, {"text": "There are basically conditional\nmeans of the states.", "start": 4126.71, "duration": 2.764}, {"text": "s sub t given t\nis the mean value", "start": 4132.09, "duration": 3.36}, {"text": "of the state at time t given\nthe information up to time t.", "start": 4135.45, "duration": 4.06}, {"text": "If we condition\non t minus 1, then", "start": 4139.51, "duration": 2.559}, {"text": "it's the expectation\nof the state", "start": 4142.069, "duration": 1.431}, {"text": "at time t given the\ninformation up to t minus 1.", "start": 4143.5, "duration": 2.8}, {"text": "And then y t t minus\n1 is the expectation", "start": 4149.46, "duration": 2.64}, {"text": "of the observation given\ninformation up to t minus 1.", "start": 4152.1, "duration": 4.78}, {"text": "There's also\nconditional covariances", "start": 4156.88, "duration": 1.9}, {"text": "and mean squared errors.", "start": 4158.78, "duration": 3.48}, {"text": "All these covariances\nare determined by omegas.", "start": 4162.26, "duration": 4.36}, {"text": "The subscript corresponds to\nstates s, or observation y.", "start": 4166.62, "duration": 6.62}, {"text": "And basically, the\nconditioning set", "start": 4173.24, "duration": 1.82}, {"text": "is either information up to\ntime t, t minus 1 or t minus 1", "start": 4175.06, "duration": 4.089}, {"text": "in the second case.", "start": 4179.149, "duration": 1.33}, {"text": "And we want to compute\nbasically the covariance matrix", "start": 4180.479, "duration": 4.891}, {"text": "of the states given whatever\nthe information is, information", "start": 4185.37, "duration": 4.629}, {"text": "up to time t, t minus 1.", "start": 4189.999, "duration": 2.44}, {"text": "So these covariance\nmatrices are the expectation", "start": 4192.439, "duration": 5.371}, {"text": "of the state minus\ntheir expectation", "start": 4197.81, "duration": 4.18}, {"text": "under the conditioning times\nthe state minus the expectation", "start": 4201.99, "duration": 4.86}, {"text": "transpose.", "start": 4206.85, "duration": 1.1}, {"text": "That's the definition of\nthat covariance matrix.", "start": 4207.95, "duration": 2.86}, {"text": "So the different\ndefinitions here", "start": 4210.81, "duration": 1.42}, {"text": "correspond to just\nwhether we're conditioning", "start": 4212.23, "duration": 2.07}, {"text": "on different information.", "start": 4214.3, "duration": 1.045}, {"text": "And then the observation\ninnovations or residuals", "start": 4217.9, "duration": 5.27}, {"text": "are the difference\nbetween an observation y_t", "start": 4223.17, "duration": 6.34}, {"text": "and its estimate given\ninformation up to t minus 1.", "start": 4229.51, "duration": 4.337}, {"text": "So the residuals in this process\nare the innovation residuals,", "start": 4237.19, "duration": 4.18}, {"text": "one period ahead.", "start": 4241.37, "duration": 2.83}, {"text": "And the Kalman filter\nconsists of four steps.", "start": 4244.2, "duration": 6.58}, {"text": "We basically want to, first,\npredict the state vector", "start": 4250.78, "duration": 10.02}, {"text": "one step ahead.", "start": 4260.8, "duration": 0.98}, {"text": "So given our estimate of the\nstate vector at time t minus 1,", "start": 4261.78, "duration": 8.36}, {"text": "we want to predict this\nstate vector at time t.", "start": 4270.14, "duration": 4.66}, {"text": "And we also want to\npredict the observation", "start": 4274.8, "duration": 3.42}, {"text": "at time t given our estimate\nat state vector time t minus 1.", "start": 4278.22, "duration": 5.6}, {"text": "And so at time t minus 1, we\ncan estimate these quantities.", "start": 4283.82, "duration": 7.854}, {"text": "[INAUDIBLE]", "start": 4291.674, "duration": 0.5}, {"text": "At t minus 1, we can\nbasically predict", "start": 4295.646, "duration": 5.323}, {"text": "what the state is going\nto and predict what", "start": 4300.969, "duration": 1.791}, {"text": "the observation is going to be.", "start": 4302.76, "duration": 1.99}, {"text": "And we can estimate\nhow much error there's", "start": 4304.75, "duration": 2.416}, {"text": "going to be in those estimates,\nby these covariance matrices.", "start": 4307.166, "duration": 2.541}, {"text": "The second step is\nupdating these predictions", "start": 4319.42, "duration": 5.72}, {"text": "to get our estimate of the state\ngiven the observation at time t", "start": 4325.14, "duration": 6.76}, {"text": "and to update our uncertainty\nabout that state given", "start": 4331.9, "duration": 3.58}, {"text": "this new observation.", "start": 4335.48, "duration": 0.9}, {"text": "So basically, our estimate\nof the state at time t", "start": 4336.38, "duration": 4.97}, {"text": "is an adjustment to our\nestimate given information up", "start": 4341.35, "duration": 3.96}, {"text": "to t minus 1, plus a function of\nthe difference between what we", "start": 4345.31, "duration": 5.854}, {"text": "observed and what we predicted.", "start": 4351.164, "duration": 1.291}, {"text": "And this T_t function matrix is\ncalled the filter gain matrix.", "start": 4355.02, "duration": 7.85}, {"text": "And basically, it\ncharacterizes how", "start": 4362.87, "duration": 2.25}, {"text": "do we adjust our prediction\nof the underlying state", "start": 4365.12, "duration": 4.95}, {"text": "depending on what happened.", "start": 4370.07, "duration": 2.69}, {"text": "So that's the\nfilter gain matrix.", "start": 4372.76, "duration": 1.68}, {"text": "So we actually do\ngain information", "start": 4377.15, "duration": 3.32}, {"text": "with each observation about what\nthe new value of the process", "start": 4380.47, "duration": 2.69}, {"text": "is.", "start": 4383.16, "duration": 1.16}, {"text": "And that information\nis characterized", "start": 4384.32, "duration": 2.51}, {"text": "by filter gain matrix.", "start": 4386.83, "duration": 2.36}, {"text": "You'll notice that\nthe uncertainty", "start": 4389.19, "duration": 2.39}, {"text": "in the state at time t, this\nomega_s of t given t, that's", "start": 4391.58, "duration": 4.14}, {"text": "equal to the covariance\nmatrix given t minus 1.", "start": 4395.72, "duration": 3.91}, {"text": "So it's our beginning level\nof uncertainty adjusted", "start": 4399.63, "duration": 3.7}, {"text": "by a term that tells us\nhow much information did we", "start": 4403.33, "duration": 4.46}, {"text": "get from that new information.", "start": 4407.79, "duration": 1.79}, {"text": "So notice that there's\na minus sign there.", "start": 4409.58, "duration": 4.01}, {"text": "We're basically\nreducing our uncertainty", "start": 4413.59, "duration": 2.01}, {"text": "about the state given the\ninformation in the innovation", "start": 4415.6, "duration": 9.002}, {"text": "that we now have observed.", "start": 4424.602, "duration": 1.083}, {"text": "Then, there's a\nforecasting step which", "start": 4428.8, "duration": 3.07}, {"text": "is used to forecast the\nstate one period forward,", "start": 4431.87, "duration": 7.44}, {"text": "is simply given by this\nlinear transformation", "start": 4439.31, "duration": 2.09}, {"text": "of the previous state.", "start": 4441.4, "duration": 1.77}, {"text": "And we can also update\nour covariance matrix", "start": 4443.17, "duration": 2.72}, {"text": "for future states given\nthe previous state", "start": 4445.89, "duration": 3.69}, {"text": "by applying this formula\nwhich is a recursive formula", "start": 4449.58, "duration": 3.95}, {"text": "for estimating covariances.", "start": 4453.53, "duration": 4.05}, {"text": "So we have\nforecasting algorithms", "start": 4457.58, "duration": 7.18}, {"text": "that are simple linear\nfunctions of these estimates.", "start": 4464.76, "duration": 4.76}, {"text": "And then finally,\nthere's a smoothing step", "start": 4469.52, "duration": 6.13}, {"text": "which is characterizing\nthe conditional expectation", "start": 4475.65, "duration": 8.31}, {"text": "of underlying states, given\ninformation in the whole time", "start": 4483.96, "duration": 5.99}, {"text": "series.", "start": 4489.95, "duration": 1.2}, {"text": "And so ordinarily with Kalman\nfilters, Kalman filters", "start": 4491.15, "duration": 4.29}, {"text": "are applied\nsequentially over time", "start": 4495.44, "duration": 2.77}, {"text": "where one basically\nis predicting ahead", "start": 4498.21, "duration": 2.88}, {"text": "one step, updating\nthat prediction,", "start": 4501.09, "duration": 2.46}, {"text": "predicting ahead another\nstep, updating the information", "start": 4503.55, "duration": 4.77}, {"text": "on the states.", "start": 4508.32, "duration": 2.61}, {"text": "And that overall\nprocess is the process", "start": 4510.93, "duration": 8.48}, {"text": "of actually computing\nthe likelihood", "start": 4519.41, "duration": 2.14}, {"text": "function for these linear\nstate-space models.", "start": 4521.55, "duration": 3.66}, {"text": "And so the Kalman filter is\nbasically ultimately applied", "start": 4525.21, "duration": 6.93}, {"text": "for successive\nforecasting of the process", "start": 4532.14, "duration": 2.87}, {"text": "but also for helping us identify\nwhat the underlying model", "start": 4535.01, "duration": 4.59}, {"text": "parameters are using\nmaximum likelihood methods.", "start": 4539.6, "duration": 3.83}, {"text": "And so the likelihood function\nfor the linear state-space", "start": 4543.43, "duration": 4.86}, {"text": "model is basically the--\nor the log-likelihood", "start": 4548.29, "duration": 3.76}, {"text": "is the log-likelihood of\nthe entire data series,", "start": 4552.05, "duration": 2.87}, {"text": "give the unknown parameters.", "start": 4554.92, "duration": 2.06}, {"text": "But that can be\nexpressed as the product", "start": 4556.98, "duration": 3.04}, {"text": "of the conditional distributions\nof each successive observation,", "start": 4560.02, "duration": 4.27}, {"text": "given the history.", "start": 4564.29, "duration": 2.86}, {"text": "And so basically, the\nlikelihood of theta", "start": 4567.15, "duration": 2.6}, {"text": "is the likelihood of\nthe first observation", "start": 4569.75, "duration": 2.64}, {"text": "times the density of the\nsecond observation given", "start": 4572.39, "duration": 2.85}, {"text": "the first times and so\nforth for the whole series.", "start": 4575.24, "duration": 3.75}, {"text": "And so the likelihood\nfunction is basically", "start": 4578.99, "duration": 3.66}, {"text": "a function of all these\nterms that we were computing", "start": 4582.65, "duration": 2.84}, {"text": "with the Kalman filter.", "start": 4585.49, "duration": 1.0}, {"text": "And with the Kalman\nfilter, it basically", "start": 4589.26, "duration": 4.21}, {"text": "provides all the terms\nnecessary for this estimation.", "start": 4593.47, "duration": 3.29}, {"text": "If the error terms are\nnormally distributed,", "start": 4596.76, "duration": 5.51}, {"text": "then the means and\nvariances of these estimates", "start": 4602.27, "duration": 4.28}, {"text": "are in fact characterizing\nthe exact distributions", "start": 4606.55, "duration": 6.2}, {"text": "of the process.", "start": 4612.75, "duration": 1.55}, {"text": "Basically, we're taking--\nif the innovation series are", "start": 4614.3, "duration": 2.55}, {"text": "all normal random\nvariables, then", "start": 4616.85, "duration": 2.44}, {"text": "the linear\nstate-space model, all", "start": 4619.29, "duration": 1.69}, {"text": "it's doing is taking linear\ncombinations of normals", "start": 4620.98, "duration": 2.77}, {"text": "for the underlying states and\nfor the actual observations.", "start": 4623.75, "duration": 3.66}, {"text": "And normal\ndistributions are fully", "start": 4627.41, "duration": 1.48}, {"text": "characterized by\ntheir mean vectors", "start": 4628.89, "duration": 1.72}, {"text": "and covariance matrices.", "start": 4630.61, "duration": 1.7}, {"text": "And the Kalman\nfilter provides a way", "start": 4632.31, "duration": 1.74}, {"text": "to update these distributions\nfor all these features", "start": 4634.05, "duration": 7.52}, {"text": "of a model, the\nunderlying states", "start": 4641.57, "duration": 1.43}, {"text": "as well as the distributions\nof the observations.", "start": 4643.0, "duration": 3.52}, {"text": "So that's a brief introduction\nthe Kalman filter.", "start": 4646.52, "duration": 8.73}, {"text": "Let's finish there.", "start": 4655.25, "duration": 1.69}, {"text": "Thank you.", "start": 4656.94, "duration": 1.55}]