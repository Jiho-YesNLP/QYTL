[{"text": "Hi, I\u2019m Carrie Anne, and welcome to Crash\nCourse Computer Science!", "start": 2.96, "duration": 2.94}, {"text": "As we\u2019ve touched on many times in this series,\ncomputers are incredible at storing, organizing,", "start": 5.9, "duration": 5.18}, {"text": "fetching and processing huge volumes of data.", "start": 11.08, "duration": 2.429}, {"text": "That\u2019s perfect for things like e-commerce\nwebsites with millions of items for sale,", "start": 13.509, "duration": 4.131}, {"text": "and for storing billions of health records\nfor quick access by doctors.", "start": 17.64, "duration": 3.12}, {"text": "But what if we want to use computers not just\nto fetch and display data, but to actually", "start": 20.76, "duration": 4.0}, {"text": "make decisions about data?", "start": 24.76, "duration": 2.03}, {"text": "This is the essence of machine learning \u2013 algorithms\nthat give computers the ability to learn from", "start": 26.79, "duration": 4.48}, {"text": "data, and then make predictions and decisions.", "start": 31.27, "duration": 2.86}, {"text": "Computer programs with this ability are extremely\nuseful in answering questions like Is an email", "start": 34.13, "duration": 4.61}, {"text": "spam?", "start": 38.74, "duration": 0.5}, {"text": "Does a person\u2019s heart have arrhythmia?", "start": 39.24, "duration": 1.84}, {"text": "What video should youtube recommend after\nthis one?", "start": 41.09, "duration": 2.25}, {"text": "While useful, we probably wouldn\u2019t describe\nthese programs as \u201cintelligent\u201d in the", "start": 43.35, "duration": 3.24}, {"text": "same way we think of human intelligence.", "start": 46.59, "duration": 2.0}, {"text": "So, even though the terms are often interchanged,\nmost computer scientists would say that machine", "start": 48.59, "duration": 4.33}, {"text": "learning is a set of techniques that sits\ninside the even more ambitious goal of Artificial", "start": 52.92, "duration": 4.451}, {"text": "Intelligence, or AI for short.", "start": 57.38, "duration": 1.96}, {"text": "INTRO", "start": 59.34, "duration": 8.98}, {"text": "Machine Learning and AI algorithms tend to\nbe pretty sophisticated.", "start": 68.32, "duration": 3.8}, {"text": "So rather than wading into the mechanics of\nhow they work, we're going to focus on what", "start": 72.12, "duration": 3.98}, {"text": "the algorithms do conceptually.", "start": 76.1, "duration": 1.84}, {"text": "Let\u2019s start with a simple example: deciding\nif a moth is a Luna Moth or an Emperor Moth.", "start": 77.94, "duration": 5.06}, {"text": "This decision process is called classification,\nand an algorithm that does it is called a", "start": 83.009, "duration": 4.03}, {"text": "classifier.", "start": 87.039, "duration": 1.0}, {"text": "Although there are techniques that can use\nraw data for training \u2013 like photos and", "start": 88.039, "duration": 3.19}, {"text": "sounds \u2013 many algorithms reduce the complexity\nof real world objects and phenomena into what", "start": 91.229, "duration": 4.771}, {"text": "are called features.", "start": 96.0, "duration": 1.38}, {"text": "Features are values that usefully characterize\nthe things we wish to classify.", "start": 97.38, "duration": 3.88}, {"text": "For our moth example, we\u2019re going to use\ntwo features: \u201cwingspan\u201d and \u201cmass\u201d.", "start": 101.26, "duration": 3.98}, {"text": "In order to train our machine learning classifier\nto make good predictions, we\u2019re going to", "start": 105.24, "duration": 3.809}, {"text": "need training data.", "start": 109.049, "duration": 1.39}, {"text": "To get that, we\u2019d send an entomologist out\ninto a forest to collect data for both luna", "start": 110.439, "duration": 4.47}, {"text": "and emperor moths.", "start": 114.909, "duration": 1.39}, {"text": "These experts can recognize different moths,\nso they not only record the feature values,", "start": 116.299, "duration": 4.35}, {"text": "but also label that data with the actual moth\nspecies.", "start": 120.649, "duration": 2.83}, {"text": "This is called labeled data.", "start": 123.479, "duration": 1.771}, {"text": "Because we only have two features, it\u2019s\neasy to visualize this data in a scatterplot.", "start": 125.25, "duration": 4.31}, {"text": "Here, I\u2019ve plotted data for 100 Emperor\nMoths in red and 100 Luna Moths in blue.", "start": 129.56, "duration": 4.78}, {"text": "We can see that the species make two groupings,\nbut\u2026.", "start": 134.34, "duration": 3.05}, {"text": "there\u2019s some overlap in the middle\u2026 so\nit\u2019s not entirely obvious how to best separate", "start": 137.39, "duration": 4.14}, {"text": "the two.", "start": 141.53, "duration": 1.0}, {"text": "That\u2019s what machine learning algorithms\ndo \u2013 find optimal separations!", "start": 142.53, "duration": 3.59}, {"text": "I\u2019m just going to eyeball it and say anything\nless than 45 millimeters in wingspan is likely", "start": 146.12, "duration": 4.649}, {"text": "to be an Emperor Moth.", "start": 150.769, "duration": 1.131}, {"text": "We can add another division that says additionally\nmass must be less than .75 in order for our", "start": 151.9, "duration": 5.4}, {"text": "guess to be Emperor Moth.", "start": 157.3, "duration": 1.18}, {"text": "These lines that chop up the decision space\nare called decision boundaries.", "start": 158.48, "duration": 3.54}, {"text": "If we look closely at our data, we can see\nthat 86 emperor moths would correctly end", "start": 162.02, "duration": 4.72}, {"text": "up inside the emperor decision region, but\n14 would end up incorrectly in luna moth territory.", "start": 166.74, "duration": 5.609}, {"text": "On the other hand, 82 luna moths would be\ncorrect, with 18 falling onto the wrong side.", "start": 172.349, "duration": 4.961}, {"text": "A table, like this, showing where a classifier\ngets things right and wrong is called a confusion", "start": 177.31, "duration": 4.769}, {"text": "matrix... which probably should have also\nbeen the title of the last two movies in the", "start": 182.079, "duration": 3.041}, {"text": "Matrix Trilogy!", "start": 185.12, "duration": 1.22}, {"text": "Notice that there\u2019s no way for us to draw\nlines that give us 100% accuracy.", "start": 186.34, "duration": 3.879}, {"text": "If we lower our wingspan decision boundary,\nwe misclassify more Emperor moths as Lunas.", "start": 190.219, "duration": 4.8}, {"text": "If we raise it, we misclassify more Luna moths.", "start": 195.02, "duration": 2.51}, {"text": "The job of machine learning algorithms, at\na high level, is to maximize correct classifications", "start": 197.53, "duration": 4.47}, {"text": "while minimizing errors", "start": 202.02, "duration": 1.77}, {"text": "On our training data, we get 168 moths correct,\nand 32 moths wrong, for an average classification", "start": 203.79, "duration": 6.07}, {"text": "accuracy of 84%.", "start": 209.86, "duration": 1.68}, {"text": "Now, using these decision boundaries, if we\ngo out into the forest and encounter an unknown", "start": 211.54, "duration": 4.02}, {"text": "moth, we can measure its features and plot\nit onto our decision space.", "start": 215.569, "duration": 3.601}, {"text": "This is unlabeled data.", "start": 219.17, "duration": 1.56}, {"text": "Our decision boundaries offer a guess as to\nwhat species the moth is.", "start": 220.73, "duration": 3.66}, {"text": "In this case, we\u2019d predict it\u2019s a Luna Moth.", "start": 224.39, "duration": 2.4}, {"text": "This simple approach, of dividing the decision\nspace up into boxes, can be represented by", "start": 226.79, "duration": 4.05}, {"text": "what\u2019s called a decision tree, which would\nlook like this pictorially or could be written", "start": 230.84, "duration": 3.819}, {"text": "in code using If-Statements, like this.", "start": 234.659, "duration": 2.09}, {"text": "A machine learning algorithm that produces\ndecision trees needs to choose what features", "start": 236.749, "duration": 4.261}, {"text": "to divide on\u2026and then for each of those\nfeatures, what values to use for the division.", "start": 241.01, "duration": 4.839}, {"text": "Decision Trees are just one basic example\nof a machine learning technique.", "start": 245.849, "duration": 3.48}, {"text": "There are hundreds of algorithms in computer\nscience literature today.", "start": 249.329, "duration": 2.72}, {"text": "And more are being published all the time.", "start": 252.049, "duration": 2.121}, {"text": "A few algorithms even use many decision trees\nworking together to make a prediction.", "start": 254.17, "duration": 4.87}, {"text": "Computer scientists smugly call those Forests\u2026\nbecause they contain lots of trees.", "start": 259.04, "duration": 3.85}, {"text": "There are also non-tree-based approaches,\nlike Support Vector Machines, which essentially", "start": 262.89, "duration": 4.35}, {"text": "slice up the decision space using arbitrary\nlines.", "start": 267.24, "duration": 2.89}, {"text": "And these don\u2019t have to be straight lines;\nthey can be polynomials or some other fancy", "start": 270.13, "duration": 3.53}, {"text": "mathematical function.", "start": 273.66, "duration": 1.47}, {"text": "Like before, it\u2019s the machine learning algorithm's\njob to figure out the best lines to provide", "start": 275.13, "duration": 3.86}, {"text": "the most accurate decision boundaries.", "start": 278.99, "duration": 1.58}, {"text": "So far, my examples have only had two features,\nwhich is easy enough for a human to figure", "start": 280.57, "duration": 4.75}, {"text": "out.", "start": 285.32, "duration": 0.68}, {"text": "If we add a third feature, let\u2019s say, length\nof antennae, then our 2D lines become 3D planes,", "start": 286.0, "duration": 5.12}, {"text": "creating decision boundaries in three dimensions.", "start": 291.12, "duration": 2.56}, {"text": "These planes don\u2019t have to be straight either.", "start": 293.68, "duration": 2.38}, {"text": "Plus, a truly useful classifier would contend\nwith many different moth species.", "start": 296.06, "duration": 3.94}, {"text": "Now I think you\u2019d agree this is getting\ntoo complicated to figure out by hand\u2026", "start": 300.0, "duration": 3.67}, {"text": "But even this is a very basic example \u2013 just three features", "start": 303.67, "duration": 3.45}, {"text": "and five moth species.", "start": 307.13, "duration": 1.51}, {"text": "We can still show it in this 3D scatter plot.", "start": 308.65, "duration": 2.16}, {"text": "Unfortunately, there\u2019s no good way to visualize\nfour features at once, or twenty features,", "start": 310.81, "duration": 4.33}, {"text": "let alone hundreds or even thousands of features.", "start": 315.14, "duration": 2.74}, {"text": "But that\u2019s what many real-world machine\nlearning problems face.", "start": 317.88, "duration": 3.15}, {"text": "Can YOU imagine trying to figure out the equation for a hyperplane rippling through a thousand-dimensional", "start": 321.03, "duration": 4.38}, {"text": "decision space?", "start": 325.41, "duration": 1.25}, {"text": "Probably not, but computers, with clever machine\nlearning algorithms can\u2026 and they do, all", "start": 326.66, "duration": 4.28}, {"text": "day long, on computers at places like Google,\nFacebook, Microsoft and Amazon.", "start": 330.94, "duration": 4.28}, {"text": "Techniques like Decision Trees and Support\nVector Machines are strongly rooted in the", "start": 335.22, "duration": 3.56}, {"text": "field of statistics, which has dealt with\nmaking confident decisions, using data, long", "start": 338.79, "duration": 4.25}, {"text": "before computers ever existed.", "start": 343.04, "duration": 1.91}, {"text": "There\u2019s a very large class of widely used\nstatistical machine learning techniques, but", "start": 344.95, "duration": 4.16}, {"text": "there are also some approaches with no origins\nin statistics.", "start": 349.11, "duration": 3.84}, {"text": "Most notable are artificial neural networks,\nwhich were inspired by neurons in our brains!", "start": 352.95, "duration": 4.84}, {"text": "For a primer of biological neurons, check\nout our three-part overview here, but basically", "start": 357.79, "duration": 4.71}, {"text": "neurons are cells that process and transmit\nmessages using electrical and chemical signals.", "start": 362.5, "duration": 4.83}, {"text": "They take one or more inputs from other cells,\nprocess those signals, and then emit their", "start": 367.33, "duration": 4.3}, {"text": "own signal.", "start": 371.63, "duration": 1.13}, {"text": "These form into huge interconnected networks\nthat are able to process complex information.", "start": 372.76, "duration": 4.88}, {"text": "Just like your brain watching this youtube\nvideo.", "start": 377.64, "duration": 2.36}, {"text": "Artificial Neurons are very similar.", "start": 380.0, "duration": 1.94}, {"text": "Each takes a series of inputs, combines them,\nand emits a signal.", "start": 381.94, "duration": 3.28}, {"text": "Rather than being electrical or chemical signals,\nartificial neurons take numbers in, and spit", "start": 385.22, "duration": 4.52}, {"text": "numbers out.", "start": 389.75, "duration": 1.0}, {"text": "They are organized into layers that are connected\nby links, forming a network of neurons, hence", "start": 390.75, "duration": 4.16}, {"text": "the name.", "start": 394.91, "duration": 0.59}, {"text": "Let\u2019s return to our moth example to see\nhow neural nets can be used for classification.", "start": 395.5, "duration": 4.8}, {"text": "Our first layer \u2013 the input layer \u2013 provides\ndata from a single moth needing classification.", "start": 400.3, "duration": 4.66}, {"text": "Again, we\u2019ll use mass and wingspan.", "start": 404.96, "duration": 2.12}, {"text": "At the other end, we have an output layer,\nwith two neurons: one for Emperor Moth and", "start": 407.08, "duration": 4.51}, {"text": "another for Luna Moth.", "start": 411.59, "duration": 1.31}, {"text": "The most excited neuron will be our classification\ndecision.", "start": 412.9, "duration": 3.03}, {"text": "In between, we have a hidden layer, that transforms\nour inputs into outputs, and does the hard", "start": 415.93, "duration": 4.76}, {"text": "work of classification.", "start": 420.69, "duration": 1.0}, {"text": "To see how this is done, let\u2019s zoom into\none neuron in the hidden layer.", "start": 421.69, "duration": 3.75}, {"text": "The first thing a neuron does is multiply\neach of its inputs by a specific weight, let\u2019s", "start": 425.44, "duration": 4.12}, {"text": "say 2.8 for its first input, and .1 for it\u2019s\nsecond input.", "start": 429.56, "duration": 3.43}, {"text": "Then, it sums these weighted inputs together,\nwhich is in this case, is a grand total of", "start": 432.99, "duration": 4.63}, {"text": "9.74.", "start": 437.62, "duration": 0.5}, {"text": "The neuron then applies a bias to this result\n- in other words, it adds or subtracts a fixed", "start": 438.2, "duration": 4.94}, {"text": "value, for example, minus six, for a new value\nof 3.74.", "start": 443.15, "duration": 3.87}, {"text": "These bias and inputs weights are initially\nset to random values when a neural network", "start": 447.03, "duration": 4.1}, {"text": "is created.", "start": 451.13, "duration": 1.0}, {"text": "Then, an algorithm goes in, and starts tweaking\nall those values to train the neural network,", "start": 452.13, "duration": 4.48}, {"text": "using labeled data for training and testing.", "start": 456.61, "duration": 2.55}, {"text": "This happens over many interactions, gradually\nimproving accuracy \u2013 a process very much", "start": 459.16, "duration": 4.55}, {"text": "like human learning.", "start": 463.71, "duration": 1.21}, {"text": "Finally, neurons have an activation function,\nalso called a transfer function, that gets", "start": 464.92, "duration": 4.58}, {"text": "applied to the output, performing a final\nmathematical modification to the result.", "start": 469.51, "duration": 4.42}, {"text": "For example, limiting the value to a range\nfrom negative one and positive one, or setting", "start": 473.93, "duration": 4.63}, {"text": "any negative values to 0.", "start": 478.56, "duration": 1.79}, {"text": "We\u2019ll use a linear transfer function that\npasses the value through unchanged, so 3.74", "start": 480.35, "duration": 5.39}, {"text": "stays as 3.74.", "start": 485.74, "duration": 1.77}, {"text": "So for our example neuron, given the inputs\n.55 and 82, the output would be 3.74.", "start": 487.51, "duration": 6.13}, {"text": "This is just one neuron, but this process\nof weighting, summing, biasing and applying", "start": 493.64, "duration": 4.31}, {"text": "an activation function is computed for all\nneurons in a layer, and the values propagate", "start": 497.95, "duration": 4.76}, {"text": "forward in the network, one layer at a time.", "start": 502.71, "duration": 2.24}, {"text": "In this example, the output neuron with the\nhighest value is our decision: Luna Moth.", "start": 504.95, "duration": 4.64}, {"text": "Importantly, the hidden layer doesn\u2019t have\nto be just one layer\u2026 it can be many layers", "start": 509.59, "duration": 3.93}, {"text": "deep.", "start": 513.52, "duration": 0.66}, {"text": "This is where the term deep learning comes\nfrom.", "start": 514.18, "duration": 2.4}, {"text": "Training these more complicated networks takes\na lot more computation and data.", "start": 516.59, "duration": 4.23}, {"text": "Despite the fact that neural networks were\ninvented over fifty years ago, deep neural", "start": 520.82, "duration": 3.95}, {"text": "nets have only been practical very recently,\nthanks to powerful processors, but even more", "start": 524.77, "duration": 5.05}, {"text": "so, wicked fast GPUs.", "start": 529.82, "duration": 1.59}, {"text": "So, thank you gamers for being so demanding\nabout silky smooth framerates!", "start": 531.41, "duration": 3.8}, {"text": "A couple of years ago, Google and Facebook\ndemonstrated deep neural nets that could find", "start": 535.21, "duration": 4.25}, {"text": "faces in photos as well as humans \u2013 and\nhumans are really good at this!", "start": 539.46, "duration": 4.06}, {"text": "It was a huge milestone.", "start": 543.52, "duration": 1.85}, {"text": "Now deep neural nets are driving cars, translating\nhuman speech, diagnosing medical conditions", "start": 545.37, "duration": 5.03}, {"text": "and much more.", "start": 550.4, "duration": 1.02}, {"text": "These algorithms are very sophisticated, but\nit\u2019s less clear if they should be described", "start": 551.42, "duration": 3.47}, {"text": "as \u201cintelligent\u201d.", "start": 554.89, "duration": 1.0}, {"text": "They can really only do one thing like classify\nmoths, find faces, or translate languages.", "start": 555.89, "duration": 5.13}, {"text": "This type of AI is called Weak AI or Narrow\nAI.", "start": 561.02, "duration": 2.79}, {"text": "It\u2019s only intelligent at specific tasks.", "start": 563.81, "duration": 2.02}, {"text": "But that doesn\u2019t mean it\u2019s not useful;\nI mean medical devices that can make diagnoses,", "start": 565.83, "duration": 4.53}, {"text": "and cars that can drive themselves are amazing!", "start": 570.36, "duration": 2.13}, {"text": "But do we need those computers to compose\nmusic and look up delicious recipes in their", "start": 572.49, "duration": 3.9}, {"text": "free time?", "start": 576.39, "duration": 1.22}, {"text": "Probably not.", "start": 577.61, "duration": 1.0}, {"text": "Although that would be kinda cool.", "start": 578.61, "duration": 1.28}, {"text": "Truly general-purpose AI, one as smart and\nwell-rounded as a human, is called Strong", "start": 579.89, "duration": 4.18}, {"text": "AI.", "start": 584.07, "duration": 1.02}, {"text": "No one has demonstrated anything close to\nhuman-level artificial intelligence yet.", "start": 585.09, "duration": 4.16}, {"text": "Some argue it\u2019s impossible, but many people\npoint to the explosion of digitized knowledge", "start": 589.25, "duration": 3.9}, {"text": "\u2013 like Wikipedia articles, web pages, and\nYoutube videos \u2013 as the perfect kindling", "start": 593.15, "duration": 4.37}, {"text": "for Strong AI.", "start": 597.52, "duration": 1.1}, {"text": "Although you can only watch a maximum of 24\nhours of youtube a day, a computer can watch", "start": 598.62, "duration": 4.13}, {"text": "millions of hours.", "start": 602.75, "duration": 1.5}, {"text": "For example, IBM\u2019s Watson consults and synthesizes\ninformation from 200 million pages of content,", "start": 604.25, "duration": 5.88}, {"text": "including the full text of Wikipedia.", "start": 610.13, "duration": 1.67}, {"text": "While not a Strong AI, Watson is pretty smart,\nand it crushed its human competition in Jeopardy", "start": 611.8, "duration": 5.32}, {"text": "way back in 2011.", "start": 617.12, "duration": 1.61}, {"text": "Not only can AIs gobble up huge volumes of\ninformation, but they can also learn over", "start": 618.73, "duration": 4.24}, {"text": "time, often much faster than humans.", "start": 622.97, "duration": 2.09}, {"text": "In 2016, Google debuted AlphaGo, a Narrow\nAI that plays the fiendishly complicated board", "start": 625.06, "duration": 5.2}, {"text": "game Go.", "start": 630.26, "duration": 1.0}, {"text": "One of the ways it got so good and able to\nbeat the very best human players, was by playing", "start": 631.26, "duration": 3.82}, {"text": "clones of itself millions and millions of\ntimes.", "start": 635.08, "duration": 2.32}, {"text": "It learned what worked and what didn\u2019t,\nand along the way, discovered successful strategies", "start": 637.4, "duration": 4.22}, {"text": "all by itself.", "start": 641.62, "duration": 1.18}, {"text": "This is called Reinforcement Learning, and\nit\u2019s a super powerful approach.", "start": 642.8, "duration": 3.14}, {"text": "In fact, it\u2019s very similar to how humans\nlearn.", "start": 645.94, "duration": 2.77}, {"text": "People don\u2019t just magically acquire the\nability to walk... it takes thousands of hours", "start": 648.71, "duration": 3.62}, {"text": "of trial and error to figure it out.", "start": 652.33, "duration": 2.01}, {"text": "Computers are now on the cusp of learning\nby trial and error, and for many narrow problems,", "start": 654.34, "duration": 4.36}, {"text": "reinforcement learning is already widely used.", "start": 658.7, "duration": 1.92}, {"text": "What will be interesting to see, is if these\ntypes of learning techniques can be applied", "start": 660.62, "duration": 3.59}, {"text": "more broadly, to create human-like, Strong\nAIs that learn much like how kids learn, but", "start": 664.21, "duration": 4.851}, {"text": "at super accelerated rates.", "start": 669.061, "duration": 1.699}, {"text": "If that happens, there are some pretty big\nchanges in store for humanity \u2013 a topic", "start": 670.76, "duration": 4.59}, {"text": "we\u2019ll revisit later.", "start": 675.35, "duration": 1.5}, {"text": "Thanks for watching.", "start": 676.85, "duration": 1.0}, {"text": "See you next week.", "start": 677.85, "duration": 1.01}]