[{"text": "Okay. Happy Halloween.", "start": 3.89, "duration": 2.29}, {"text": "Um, what I want to do today is share with you advice for applying machine learning.", "start": 6.18, "duration": 5.79}, {"text": "And, and you've heard me allude to this before,", "start": 11.97, "duration": 1.89}, {"text": "but, um, uh, yeah,", "start": 13.86, "duration": 2.04}, {"text": "I think over the last several weeks,", "start": 15.9, "duration": 1.77}, {"text": "you've learned a lot about the mechanics of how to build different learning algorithms.", "start": 17.67, "duration": 4.65}, {"text": "Everything from linear regression,", "start": 22.32, "duration": 1.26}, {"text": "logistic regression, SVMs, uh,", "start": 23.58, "duration": 1.56}, {"text": "uh, Random Forest, is it, uh, uh, neural networks.", "start": 25.14, "duration": 3.825}, {"text": "And what I want to do today is share with you some", "start": 28.965, "duration": 2.865}, {"text": "principles for helping you become efficient at how", "start": 31.83, "duration": 2.7}, {"text": "you apply all of these things to solve", "start": 34.53, "duration": 2.13}, {"text": "whatever application problem you might want to work on.", "start": 36.66, "duration": 3.585}, {"text": "Um, and so, uh,", "start": 40.245, "duration": 2.865}, {"text": "a lot of today's material is actually not that mathematical.", "start": 43.11, "duration": 2.81}, {"text": "There's also some of the hardest materials as we're in,", "start": 45.92, "duration": 3.09}, {"text": "in, in, in this class to understand.", "start": 49.01, "duration": 2.24}, {"text": "Um, it turns out that when you give advice", "start": 51.25, "duration": 2.92}, {"text": "on how to apply a learning algorithm such as, you know,", "start": 54.17, "duration": 3.165}, {"text": "\"Don't waste lots of time collecting data unless you,", "start": 57.335, "duration": 3.115}, {"text": "you, you have confidence it's useful to actually spend all that time.\"", "start": 60.45, "duration": 3.395}, {"text": "It turns out when I say things like that,", "start": 63.845, "duration": 1.86}, {"text": "people, you know, easily agree.", "start": 65.705, "duration": 1.755}, {"text": "They say, \"Of course, you shouldn't waste time collecting lots of data", "start": 67.46, "duration": 2.67}, {"text": "unless you have some confidence it's actually a good use of your time.\"", "start": 70.13, "duration": 3.16}, {"text": "That's a very easy thing to agree with.", "start": 73.29, "duration": 2.24}, {"text": "Um, but the hard thing is when you go", "start": 75.53, "duration": 3.36}, {"text": "home today and you're actually working on your class project,", "start": 78.89, "duration": 3.52}, {"text": "right, uh, uh, to apply the principles we talked about today.", "start": 82.41, "duration": 4.19}, {"text": "When you're actually on the ground talking to a teammate saying,", "start": 86.6, "duration": 2.9}, {"text": "\"All right, do we collect more data for our class project now or not? \"", "start": 89.5, "duration": 3.67}, {"text": "To make the right judgment call for that.", "start": 93.17, "duration": 2.04}, {"text": "To map the concepts you learned today.", "start": 95.21, "duration": 1.77}, {"text": "To when you're actually in the hot seat,", "start": 96.98, "duration": 1.65}, {"text": "you know making a decision to be going,", "start": 98.63, "duration": 1.845}, {"text": "spending another two days scraping data off the Internet,", "start": 100.475, "duration": 2.715}, {"text": "or are you gonna tune this algorithm,", "start": 103.19, "duration": 1.53}, {"text": "tune these parameters to the algorithm and actually make those decisions is actually, um,", "start": 104.72, "duration": 3.995}, {"text": "uh, it, it, it often takes a lot of,", "start": 108.715, "duration": 2.42}, {"text": "um, careful thinking to make the mapping.", "start": 111.135, "duration": 2.565}, {"text": "From the principles we're talking about today,", "start": 113.7, "duration": 1.49}, {"text": "and then probably all of you go,", "start": 115.19, "duration": 1.08}, {"text": "\"Yep, that makes sense.\"", "start": 116.27, "duration": 1.32}, {"text": "But to actually do that when you're in the hot seat making the decisions.", "start": 117.59, "duration": 3.15}, {"text": "That, that, that's something that, um,", "start": 120.74, "duration": 2.195}, {"text": "will often take, take some careful thought, I guess.", "start": 122.935, "duration": 2.84}, {"text": "Um, and I think, uh,", "start": 125.775, "duration": 1.38}, {"text": "uh, you know, for a long time, um,", "start": 127.155, "duration": 3.255}, {"text": "the concepts of machine learning have been an art, right, where,", "start": 130.41, "duration": 3.315}, {"text": "you know, we'll, we'll go to these people that have been doing it for 30 years.", "start": 133.725, "duration": 3.365}, {"text": "And you say, \"Hey, my learning algorithm doesn't work,\" you know,", "start": 137.09, "duration": 3.21}, {"text": "uh, uh, uh, what do we do now?", "start": 140.3, "duration": 1.77}, {"text": "And then they will have some judgment or you go.", "start": 142.07, "duration": 2.22}, {"text": "And people asked me and for some reason because we've", "start": 144.29, "duration": 2.01}, {"text": "done it for a long time, we will say, \"Oh yeah,", "start": 146.3, "duration": 2.13}, {"text": "I get more data, or I'll tune that parameter, or try a neural network with big hidden units, and for some reason that'll work.", "start": 148.43, "duration": 5.685}, {"text": "And what I hope to do today is,", "start": 154.115, "duration": 2.285}, {"text": "uh, turn that black magic, that, that,", "start": 156.4, "duration": 2.45}, {"text": "that art into much more refined,", "start": 158.85, "duration": 1.549}, {"text": "so that you can much more systematically make these decisions yourself, rather than,", "start": 160.399, "duration": 3.811}, {"text": "uh, talk to someone, um,", "start": 164.21, "duration": 2.025}, {"text": "who's done this for 30 years, then for,", "start": 166.235, "duration": 2.1}, {"text": "for some reason is able to give you the good recommendations even if,", "start": 168.335, "duration": 3.81}, {"text": "you know, that to turn from, um,", "start": 172.145, "duration": 2.775}, {"text": "more of a black art into more of a systematic engineering discipline.", "start": 174.92, "duration": 3.825}, {"text": "Um, and, and just, uh, uh, one note.", "start": 178.745, "duration": 2.955}, {"text": "Uh, some of the work we are gonna do today is not the best approach for,", "start": 181.7, "duration": 3.155}, {"text": "uh, developing novel machine learning research,", "start": 184.855, "duration": 2.575}, {"text": "or if you're- if your main goal is to write research papers, uh,", "start": 187.43, "duration": 3.36}, {"text": "some of what I'll say will apply,", "start": 190.79, "duration": 1.53}, {"text": "some of what I'll say will not apply,", "start": 192.32, "duration": 1.38}, {"text": "but I'll come back to that later.", "start": 193.7, "duration": 1.35}, {"text": "So most of today's focused on how to help you build stuff that works,", "start": 195.05, "duration": 3.515}, {"text": "right, to build, build applications that work.", "start": 198.565, "duration": 2.555}, {"text": "Um, so the three key ideas, um,", "start": 201.12, "duration": 3.45}, {"text": "you see today are first is, uh,", "start": 204.57, "duration": 2.625}, {"text": "diagnostics for debugging learning algorithms.", "start": 207.195, "duration": 3.315}, {"text": "Um, one thing you might not know,", "start": 210.51, "duration": 2.83}, {"text": "or actually if you're working on the class project maybe you know this already is that,", "start": 213.34, "duration": 3.805}, {"text": "uh, when you implement a learning algorithm for the first time,", "start": 217.145, "duration": 2.645}, {"text": "it almost never works, right?", "start": 219.79, "duration": 1.7}, {"text": "At least not the first time.", "start": 221.49, "duration": 1.545}, {"text": "Uh, uh, uh, and so,", "start": 223.035, "duration": 2.415}, {"text": "um, what is it- I still remember was- there was a weekend,", "start": 225.45, "duration": 3.885}, {"text": "um, uh, about a year ago where I implemented Softmax regression on my laptop,", "start": 229.335, "duration": 5.1}, {"text": "and it worked the first time.", "start": 234.435, "duration": 1.65}, {"text": "And even to this day, I, I still remember that feeling of surprise,", "start": 236.085, "duration": 3.485}, {"text": "like, no, there's got to be a bug and I", "start": 239.57, "duration": 1.41}, {"text": "went in to try to find the bug, and there wasn't a bug.", "start": 240.98, "duration": 1.875}, {"text": "But, but it's so rare.", "start": 242.855, "duration": 1.305}, {"text": "[LAUGHTER] So the learning algorithm worked the first time.", "start": 244.16, "duration": 3.12}, {"text": "I still remember it over a year later.", "start": 247.28, "duration": 1.895}, {"text": "Uh, and so a lot of the workflow of developing learning algorithms,", "start": 249.175, "duration": 3.94}, {"text": "it, it actually feels like a debugging workflow, right?", "start": 253.115, "duration": 3.675}, {"text": "Um, and so I want to help you become systematic at that.", "start": 256.79, "duration": 4.095}, {"text": "Um, and, uh, uh,", "start": 260.885, "duration": 1.94}, {"text": "two key ideas here are about error analysis, and integrative analysis.", "start": 262.825, "duration": 3.235}, {"text": "[NOISE] So how to analyze the errors in your learning algorithm.", "start": 266.06, "duration": 2.7}, {"text": "And also how to, how to understand what's not working,", "start": 268.76, "duration": 2.31}, {"text": "what's error analysis, and how to understand what's working,", "start": 271.07, "duration": 2.205}, {"text": "which is ablative analysis.", "start": 273.275, "duration": 1.575}, {"text": "And then, and then finding with some philosophies and how to", "start": 274.85, "duration": 2.37}, {"text": "get started on a machine learning project,", "start": 277.22, "duration": 2.4}, {"text": "su- such as your class project, okay?", "start": 279.62, "duration": 2.405}, {"text": "So let's start with, uh,", "start": 282.025, "duration": 2.01}, {"text": "discussing debugging learning algorithms.", "start": 284.035, "duration": 4.01}, {"text": "Um, so what happens all the time is you have an idea for a machine learning application.", "start": 288.045, "duration": 6.17}, {"text": "You implement something, uh,", "start": 294.215, "duration": 2.095}, {"text": "and then it won't work as well as you hoped.", "start": 296.31, "duration": 1.7}, {"text": "And the key question is,", "start": 298.01, "duration": 1.485}, {"text": "what do you do next, right?", "start": 299.495, "duration": 1.315}, {"text": "When I want to work on machine learning algorithm, that's actually most of my workflow.", "start": 300.81, "duration": 3.515}, {"text": "We usually have something implemented.", "start": 304.325, "duration": 1.89}, {"text": "It's just not working that well.", "start": 306.215, "duration": 1.635}, {"text": "And your ability to decide what to do next has a huge impact on,", "start": 307.85, "duration": 3.825}, {"text": "on, on your efficiency.", "start": 311.675, "duration": 1.98}, {"text": "Um, uh, I, I think, uh, when, when,", "start": 313.655, "duration": 2.59}, {"text": "um, when I was, uh,", "start": 316.245, "duration": 1.275}, {"text": "when I was an undergrad, uh,", "start": 317.52, "duration": 1.41}, {"text": "at Carnegie Mellon University,", "start": 318.93, "duration": 1.365}, {"text": "I had a friend, um, that would, uh,", "start": 320.295, "duration": 2.31}, {"text": "debug their code by,", "start": 322.605, "duration": 1.77}, {"text": "um, you know, they write a piece of code.", "start": 324.375, "duration": 2.25}, {"text": "And then as always, when you write a piece of code,", "start": 326.625, "duration": 2.07}, {"text": "initially there's always a bunch of syntax errors, right?", "start": 328.695, "duration": 2.025}, {"text": "And so their debugging strategy was to delete", "start": 330.72, "duration": 2.51}, {"text": "every single line of code that generated", "start": 333.23, "duration": 1.49}, {"text": "a syntax error because this is a good way to get rid of errors.", "start": 334.72, "duration": 2.35}, {"text": "So that wasn't a good strategy.", "start": 337.07, "duration": 1.32}, {"text": "So in, in, in machine learning as well,", "start": 338.39, "duration": 2.49}, {"text": "there are good and less good debugging strategies, right?", "start": 340.88, "duration": 3.235}, {"text": "Um, so let's start with a motivating example.", "start": 344.115, "duration": 2.595}, {"text": "Uh, let's say we're building an anti-spam classifier.", "start": 346.71, "duration": 3.84}, {"text": "And, um, let's say you've carefully", "start": 350.55, "duration": 2.99}, {"text": "chosen a small set of a hundred words to use as features", "start": 353.54, "duration": 2.85}, {"text": "So instead of using, you know,", "start": 356.39, "duration": 1.14}, {"text": "10,000 or 50,000 words.", "start": 357.53, "duration": 1.59}, {"text": "You've chosen a hundred words that you think could be most relevant to, um, anti-spam.", "start": 359.12, "duration": 6.62}, {"text": "And let's say you start off implementing logistic regularization.", "start": 365.74, "duration": 5.12}, {"text": "Uh, I think when we talk about this,", "start": 370.86, "duration": 1.83}, {"text": "this is also, you know,", "start": 372.69, "duration": 1.02}, {"text": "there's a frequentist and Bayesian school,", "start": 373.71, "duration": 1.56}, {"text": "but you can think of this as Bayesian which is a progression where, uh,", "start": 375.27, "duration": 3.485}, {"text": "you have the maximum likelihood term on the left,", "start": 378.755, "duration": 3.045}, {"text": "and then that second term is the regularization term, right?", "start": 381.8, "duration": 4.02}, {"text": "Um, so that's, so that's Bayesian logistic regression.", "start": 385.82, "duration": 3.075}, {"text": "If you're Bayesian or, uh,", "start": 388.895, "duration": 1.615}, {"text": "which is regression with regularization if you are,", "start": 390.51, "duration": 3.0}, {"text": "uh, you know, using frequency statistics.", "start": 393.51, "duration": 2.34}, {"text": "[NOISE] And let say that, um,", "start": 395.85, "duration": 2.745}, {"text": "logistic regression with regularization or Bayesian logistic regression,", "start": 398.595, "duration": 3.53}, {"text": "it gets 20% test error which is unacceptably high, right?", "start": 402.125, "duration": 3.195}, {"text": "Making one in five mistakes on, on your spam filter.", "start": 405.32, "duration": 2.58}, {"text": "Um, and so what do you do next?", "start": 407.9, "duration": 3.02}, {"text": "Um, now, for this scenario, I, I wanna,", "start": 410.92, "duration": 2.48}, {"text": "uh, and, and so, um, for, uh,", "start": 413.4, "duration": 3.49}, {"text": "when you implement an algorithm like this, uh,", "start": 416.89, "duration": 2.56}, {"text": "what many teams will do is,", "start": 419.45, "duration": 2.28}, {"text": "um, try improving the algorithm in different ways.", "start": 421.73, "duration": 2.76}, {"text": "So what many teams would do is say, \"Oh yeah,", "start": 424.49, "duration": 2.82}, {"text": "I remember, you know, well,", "start": 427.31, "duration": 1.63}, {"text": "we like big data, more data always helps.\"", "start": 428.94, "duration": 2.42}, {"text": "So let's get some more data and hope that solves the problem.", "start": 431.36, "duration": 2.67}, {"text": "So one or some teams would say,", "start": 434.03, "duration": 1.62}, {"text": "\"Let's get more training examples.\"", "start": 435.65, "duration": 2.4}, {"text": "And, and, and it's actually true, you know,", "start": 438.05, "duration": 1.185}, {"text": "more data pretty much never hurts.", "start": 439.235, "duration": 1.785}, {"text": "It almost always helps,", "start": 441.02, "duration": 1.34}, {"text": "but the key question is how much.", "start": 442.36, "duration": 1.94}, {"text": "Um, or you could try using a smaller set of features.", "start": 444.3, "duration": 4.19}, {"text": "With a hundred features probably some weren't that relevant.", "start": 448.49, "duration": 2.555}, {"text": "So let's get rid of some features.", "start": 451.045, "duration": 1.75}, {"text": "Um, or if you try having a larger set of features,", "start": 452.795, "duration": 2.145}, {"text": "hundred features is too small, right?", "start": 454.94, "duration": 1.32}, {"text": "So let's add more features.", "start": 456.26, "duration": 1.855}, {"text": "Um, uh, or you might want other designs of the features, you know,", "start": 458.115, "duration": 5.55}, {"text": "instead of, uh, uh, just using features in an e-mail body,", "start": 463.665, "duration": 3.66}, {"text": "uh, you can use features from the e-mail header.", "start": 467.325, "duration": 2.385}, {"text": "Uh, the e-mail header has,", "start": 469.71, "duration": 1.53}, {"text": "um, uh, not just a From To subject,", "start": 471.24, "duration": 2.33}, {"text": "but also routing information about what's the set of", "start": 473.57, "duration": 2.64}, {"text": "servers of the Internet that the e-mail took to get to you.", "start": 476.21, "duration": 3.41}, {"text": "Um, uh, or you could try running gradient descent for more iterations.", "start": 479.62, "duration": 5.11}, {"text": "That, that, you know, that never hurts, right, for usually.", "start": 484.73, "duration": 3.82}, {"text": "Uh, uh, from gradient descent, let's switch to Newton's methods.", "start": 488.83, "duration": 3.57}, {"text": "Uh, or let's try a different value for Lambda.", "start": 492.4, "duration": 3.28}, {"text": "Um, or, or we say, you know,", "start": 495.68, "duration": 2.19}, {"text": "forget about Bayesian logistic regression or,", "start": 497.87, "duration": 2.04}, {"text": "or run regression regularization.", "start": 499.91, "duration": 1.605}, {"text": "Let's, let's use a totally different algorithm,", "start": 501.515, "duration": 1.575}, {"text": "like an SVM or neural networks or something, right?", "start": 503.09, "duration": 2.79}, {"text": "So what happens in a lot of teams is, um,", "start": 505.88, "duration": 4.42}, {"text": "uh, someone will pick one of these ideas, kind of at random.", "start": 510.3, "duration": 5.03}, {"text": "Um, it depends on, you know,", "start": 515.33, "duration": 2.25}, {"text": "what they happen to read the night before, right, about something.", "start": 517.58, "duration": 3.49}, {"text": "Uh, or, or their experience on the last project.", "start": 521.07, "duration": 2.22}, {"text": "And sometimes a project,", "start": 523.29, "duration": 1.785}, {"text": "and sometimes you or the project leader will say,", "start": 525.075, "duration": 2.805}, {"text": "uh, you know, we'll pick one of these and just say, \"Let's try that.\"", "start": 527.88, "duration": 3.03}, {"text": "And then spend, spend a few days or few weeks trying that,", "start": 530.91, "duration": 2.985}, {"text": "and it may or may not be the best thing to do.", "start": 533.895, "duration": 2.59}, {"text": "So, um, uh, I think that in, in,", "start": 536.485, "duration": 3.11}, {"text": "in my team's machine learning workflow,", "start": 539.595, "duration": 1.605}, {"text": "so first, if you actually, you and a few others,", "start": 541.2, "duration": 2.79}, {"text": "sit down and brainstorm a list of the things you could try, you actually are,", "start": 543.99, "duration": 3.27}, {"text": "are already ahead of a lot of teams because all teams", "start": 547.26, "duration": 2.6}, {"text": "will come just by gut feeling, right?", "start": 549.86, "duration": 2.62}, {"text": "Um, uh, or the most opinionated person will pick one of these things at random and do that,", "start": 552.48, "duration": 5.56}, {"text": "but you brainstorm a list of things and then,", "start": 558.04, "duration": 2.22}, {"text": "and then try to evaluate the different options.", "start": 560.26, "duration": 2.085}, {"text": "You're already ahead of many teams.", "start": 562.345, "duration": 1.845}, {"text": "Um, oh, sorry, and I think,", "start": 564.19, "duration": 2.55}, {"text": "uh, uh, yeah and I think, right, you know,", "start": 566.74, "duration": 3.435}, {"text": "unless you analyze these different options, um, uh,", "start": 570.175, "duration": 3.225}, {"text": "uh, it's hard to know which of these is actually the best option.", "start": 573.4, "duration": 5.49}, {"text": "So, um, the most common diagnostic I end up using in developing learning algorithms,", "start": 578.89, "duration": 8.07}, {"text": "is a, um, bias versus variance diagnostic, right?", "start": 586.96, "duration": 3.885}, {"text": "And I think I, um,", "start": 590.845, "duration": 1.67}, {"text": "talked about bias and variance already with a classifier is", "start": 592.515, "duration": 3.63}, {"text": "highly biased, then it tends to under fit the data.", "start": 596.145, "duration": 4.635}, {"text": "So high bias is, well, actually.", "start": 600.78, "duration": 2.4}, {"text": "You guys remember this, right?", "start": 603.18, "duration": 3.355}, {"text": "If, um, If you have a dataset just like this,", "start": 606.535, "duration": 3.585}, {"text": "a highly biased classifier may be much too simple,", "start": 610.12, "duration": 3.045}, {"text": "and high variance classifiers may be much too complex,", "start": 613.165, "duration": 3.315}, {"text": "and some- something in-between,", "start": 616.48, "duration": 1.995}, {"text": "you know, with, with trade off bias and variance in an appropriate way, right?", "start": 618.475, "duration": 3.615}, {"text": "So that's bias and variance.", "start": 622.09, "duration": 1.38}, {"text": "Um, and so, uh,", "start": 623.47, "duration": 2.495}, {"text": "it turns out that one of the most common diagnostics I end up using in", "start": 625.965, "duration": 4.365}, {"text": "pretty much every single machine learning project is a bias versus variance diagnostic.", "start": 630.33, "duration": 4.94}, {"text": "So understand how much of", "start": 635.27, "duration": 1.73}, {"text": "your learning algorithm's problem comes from bias and how much of it comes from variance.", "start": 637.0, "duration": 4.05}, {"text": "Um, and, uh, uh, and,", "start": 641.05, "duration": 3.045}, {"text": "you know, I- I've had,", "start": 644.095, "duration": 1.2}, {"text": "I don't know, like former PhD students, right,", "start": 645.295, "duration": 2.145}, {"text": "that- that learned about bias and variance when they're doing their PhD and", "start": 647.44, "duration": 4.29}, {"text": "then sometimes even a couple of years after they've graduated from Stanford and worked,", "start": 651.73, "duration": 4.47}, {"text": "you know, on more practical problems.", "start": 656.2, "duration": 1.71}, {"text": "They actually tell me that, that,", "start": 657.91, "duration": 1.62}, {"text": "that their understanding of bias and variances continue to deepen,", "start": 659.53, "duration": 3.885}, {"text": "right, for, for, for many years.", "start": 663.415, "duration": 2.265}, {"text": "So this is one of those concepts is, is, um,", "start": 665.68, "duration": 2.745}, {"text": "if you can systematically apply it, you'll be much more efficient and this is really the,", "start": 668.425, "duration": 4.5}, {"text": "maybe the single most useful tool I've found,", "start": 672.925, "duration": 2.295}, {"text": "understanding bias and variance at debugging learning algorithms.", "start": 675.22, "duration": 3.36}, {"text": "Um, and so what I'm gonna describe,", "start": 678.58, "duration": 2.25}, {"text": "is a workflow where you would run some diagnostics to figure out what is the problem,", "start": 680.83, "duration": 4.965}, {"text": "uh, and then try to fix what the problem is.", "start": 685.795, "duration": 1.74}, {"text": "And so, um, just to summarize this no- this example.", "start": 687.535, "duration": 4.155}, {"text": "Um, uh, this logistic regression error is unacceptably", "start": 691.69, "duration": 3.78}, {"text": "high and you want to- and you suspect problems due to high variance or high bias.", "start": 695.47, "duration": 4.395}, {"text": "And so, um, it turns out that there's a diagnostic that lets", "start": 699.865, "duration": 3.735}, {"text": "you look at your algorithm's performance and try to figure out if,", "start": 703.6, "duration": 4.935}, {"text": "um, how much of the problem is variance and how much of the problem is bias.", "start": 708.535, "duration": 4.485}, {"text": "Oh, and I'm going to say test error,", "start": 713.02, "duration": 1.74}, {"text": "but if you are developing,", "start": 714.76, "duration": 1.47}, {"text": "should I really be doing this with a dev set or development set rather than a test set, right?", "start": 716.23, "duration": 4.275}, {"text": "But so let me, let me explain this, um,", "start": 720.505, "duration": 3.075}, {"text": "uh, diagnostic in greater detail.", "start": 723.58, "duration": 4.53}, {"text": "Uh, so it turns out that, um,", "start": 728.11, "duration": 2.1}, {"text": "if you have a classifier with very high variance,", "start": 730.21, "duration": 3.675}, {"text": "then the performance on the test set,", "start": 733.885, "duration": 3.075}, {"text": "or actually would be better,", "start": 736.96, "duration": 1.545}, {"text": "better practice to use the hold-out cross validation so the, the development set.", "start": 738.505, "duration": 3.795}, {"text": "You see that the error that you classify has, um, much, uh,", "start": 742.3, "duration": 4.095}, {"text": "uh, much lower error on the training set than on the development set.", "start": 746.395, "duration": 5.565}, {"text": "But in contrast, if you have high bias,", "start": 751.96, "duration": 2.79}, {"text": "then the training error and the test set error and the dev set error will go behind.", "start": 754.75, "duration": 4.125}, {"text": "So let me sh- let me illustrate this with a picture.", "start": 758.875, "duration": 3.735}, {"text": "Um, so this is a learning curve and what that means is, um,", "start": 762.61, "duration": 5.22}, {"text": "on the horizontal axis,", "start": 767.83, "duration": 1.725}, {"text": "you are going to vary the number of training examples, right?", "start": 769.555, "duration": 3.495}, {"text": "Uh, and when I talk about bias and variance,", "start": 773.05, "duration": 2.535}, {"text": "I had a plot where the horizontal axis was the degree of polynomial, right?", "start": 775.585, "duration": 4.215}, {"text": "You fit a first order, second order,", "start": 779.8, "duration": 1.44}, {"text": "third order, fourth order polynomial.", "start": 781.24, "duration": 1.455}, {"text": "In this plot, the horizontal axis is different, it's the number of training examples.", "start": 782.695, "duration": 4.32}, {"text": "And so it turns out that,", "start": 787.015, "duration": 1.86}, {"text": "um, whenever you train a learning algorithm, you know,", "start": 788.875, "duration": 3.45}, {"text": "the more data you have usually,", "start": 792.325, "duration": 2.25}, {"text": "the better your development set error,", "start": 794.575, "duration": 2.085}, {"text": "the better your your test set error, right?", "start": 796.66, "duration": 1.83}, {"text": "This error usually goes down,", "start": 798.49, "duration": 1.86}, {"text": "when you increase the number of training examples.", "start": 800.35, "duration": 2.25}, {"text": "The other thing, the other- and,", "start": 802.6, "duration": 2.385}, {"text": "and let's say that you're hoping to achieve a certain level of desired performance,", "start": 804.985, "duration": 4.875}, {"text": "you know, for business reasons,", "start": 809.86, "duration": 1.2}, {"text": "you'd like your spam classifier to achieve", "start": 811.06, "duration": 1.71}, {"text": "a certain level of design performance and often- sometimes,", "start": 812.77, "duration": 3.48}, {"text": "desired level of performance is, um,", "start": 816.25, "duration": 1.875}, {"text": "to do about as well as a human can.", "start": 818.125, "duration": 2.115}, {"text": "That's a common business objective depending on your application,", "start": 820.24, "duration": 3.315}, {"text": "uh, but sometimes it can be different, right.", "start": 823.555, "duration": 2.295}, {"text": "So you have some- your product manager, you know,", "start": 825.85, "duration": 2.49}, {"text": "tells you that well you,", "start": 828.34, "duration": 1.29}, {"text": "if you're leading the project,", "start": 829.63, "duration": 1.23}, {"text": "you think that you need to hit a certain level of", "start": 830.86, "duration": 2.04}, {"text": "target performance in order for it to be a very useful spam filter.", "start": 832.9, "duration": 3.88}, {"text": "So the other plot, uh, uh,", "start": 836.78, "duration": 5.27}, {"text": "to add to this which will help you analyze bias", "start": 842.05, "duration": 3.12}, {"text": "versus variance is to plot the training error.", "start": 845.17, "duration": 3.525}, {"text": "Um, now one thing to help you with training error is that it increases, um, uh,", "start": 848.695, "duration": 6.24}, {"text": "as the training set size increases because,", "start": 854.935, "duration": 4.455}, {"text": "if you have only one example, right?", "start": 859.39, "duration": 2.625}, {"text": "Let's say you're building a spam classifier and you have only one training example,", "start": 862.015, "duration": 4.019}, {"text": "then any algorithm, you know,", "start": 866.034, "duration": 1.741}, {"text": "can fit one training example perfectly.", "start": 867.775, "duration": 2.145}, {"text": "And so if your training set size is very small.", "start": 869.92, "duration": 2.145}, {"text": "The training set error is usually 0, right?", "start": 872.065, "duration": 2.235}, {"text": "If you have like 5, 10 examples,", "start": 874.3, "duration": 2.4}, {"text": "you probably can fit all 5 examples perfectly. And it's only if you have a bigger training set", "start": 876.7, "duration": 5.145}, {"text": "that it becomes harder for the learning algorithm to", "start": 881.845, "duration": 2.775}, {"text": "fit your training data that well, right?", "start": 884.62, "duration": 3.045}, {"text": "Or in the the linear regression case,", "start": 887.665, "duration": 1.785}, {"text": "here you have you have one example,", "start": 889.45, "duration": 1.365}, {"text": "yeah you can fit a straight line to data,", "start": 890.815, "duration": 1.665}, {"text": "if you have two examples, you can fit any model,", "start": 892.48, "duration": 2.085}, {"text": "pretty much to the data,", "start": 894.565, "duration": 1.47}, {"text": "and have zero training error.", "start": 896.035, "duration": 1.77}, {"text": "There's only a very, very large training set that a classifier like", "start": 897.805, "duration": 3.99}, {"text": "logistic regression or linear regression may have", "start": 901.795, "duration": 1.875}, {"text": "a harder time fitting all of your training examples.", "start": 903.67, "duration": 2.7}, {"text": "So that's why training error or average training error,", "start": 906.37, "duration": 2.445}, {"text": "average over your training set, uh,", "start": 908.815, "duration": 1.86}, {"text": "generally increases, um, as you increase the training set size.", "start": 910.675, "duration": 4.455}, {"text": "So, um, now there are two characteristics of this plot,", "start": 915.13, "duration": 6.75}, {"text": "that suggest that, um,", "start": 921.88, "duration": 1.74}, {"text": "if you plot the learning curves if you see the- this, this pattern,", "start": 923.62, "duration": 4.29}, {"text": "this suggests that, um,", "start": 927.91, "duration": 2.01}, {"text": "the algorithm has a large bias problem, right?", "start": 929.92, "duration": 2.76}, {"text": "And the two properties written at the bottom,", "start": 932.68, "duration": 1.8}, {"text": "one, the weaker signal,", "start": 934.48, "duration": 1.71}, {"text": "the one that's harder to rely on,", "start": 936.19, "duration": 1.755}, {"text": "is that, um, the development set error,", "start": 937.945, "duration": 2.505}, {"text": "or the test set error is still decreasing,", "start": 940.45, "duration": 1.98}, {"text": "as you increase the training set size.", "start": 942.43, "duration": 1.605}, {"text": "So the green curve is still,", "start": 944.035, "duration": 1.545}, {"text": "you know, still looks like it's going down,", "start": 945.58, "duration": 1.8}, {"text": "and so this suggests that if you increase", "start": 947.38, "duration": 2.4}, {"text": "the training set size and extrapolate further to the right,", "start": 949.78, "duration": 2.775}, {"text": "that the curve would keep on going down.", "start": 952.555, "duration": 2.235}, {"text": "Um, this turns out to be a weaker signal because sometimes we look at a curve like that,", "start": 954.79, "duration": 5.235}, {"text": "it's actually quite hard to tell,", "start": 960.025, "duration": 1.95}, {"text": "you know, to extrapolate to the right.", "start": 961.975, "duration": 2.175}, {"text": "Uh, uh, if you double the training set size,", "start": 964.15, "duration": 2.625}, {"text": "how much further would the green curve go down?", "start": 966.775, "duration": 2.025}, {"text": "It's actually kind of hard to tell.", "start": 968.8, "duration": 1.08}, {"text": "So I find this a useful signal,", "start": 969.88, "duration": 2.13}, {"text": "but sometimes it's a bit hard to judge, you know,", "start": 972.01, "duration": 2.34}, {"text": "exactly where the curve will go if you extrapolate to the right.", "start": 974.35, "duration": 2.88}, {"text": "Um, the stronger signal is actually the second one,", "start": 977.23, "duration": 3.78}, {"text": "the fact that there's a huge gap between your training error and your test set error,", "start": 981.01, "duration": 4.125}, {"text": "or your training or your dev set error would be the better thing to look at.", "start": 985.135, "duration": 2.955}, {"text": "It's actually a stronger signal that,", "start": 988.09, "duration": 2.625}, {"text": "um, this particular learning algorithm has,", "start": 990.715, "duration": 2.055}, {"text": "um, has high variance right,", "start": 992.77, "duration": 2.55}, {"text": "um, uh, because, uh,", "start": 995.32, "duration": 2.235}, {"text": "as you increase the training set size,", "start": 997.555, "duration": 2.535}, {"text": "you find that the gap between, um,", "start": 1000.09, "duration": 3.075}, {"text": "training and test error usually closes, usually reduces.", "start": 1003.165, "duration": 4.065}, {"text": "And so there's still a lot of room, for, um, uh,", "start": 1007.23, "duration": 3.69}, {"text": "making your test set error become closer to your training error.", "start": 1010.92, "duration": 4.44}, {"text": "And so if you see a learning curve like this, this is a strong sign that,", "start": 1015.36, "duration": 4.26}, {"text": "um, you have a variance problem, okay?", "start": 1019.62, "duration": 2.88}, {"text": "Now let's look at what the curve- what the learning curve will look like,", "start": 1022.5, "duration": 3.345}, {"text": "um, if you have a bias problem.", "start": 1025.845, "duration": 2.76}, {"text": "Um, so this is a typical learning curve for high bias which is, uh,", "start": 1028.605, "duration": 4.56}, {"text": "that's your dev set error or your development set cross-validation error, uh, test error,", "start": 1033.165, "duration": 5.805}, {"text": "and you're hoping to hit a level of performance like that,", "start": 1038.97, "duration": 2.61}, {"text": "and your training error looks like that.", "start": 1041.58, "duration": 4.23}, {"text": "And, um, so one sign that you have", "start": 1045.81, "duration": 5.82}, {"text": "a high bias problem is that", "start": 1051.63, "duration": 2.88}, {"text": "this algorithm is not even doing that well on the training set, right?", "start": 1054.51, "duration": 4.92}, {"text": "Even on the training set, you know,", "start": 1059.43, "duration": 2.37}, {"text": "you're not achieving your desired level of performance,", "start": 1061.8, "duration": 3.36}, {"text": "and it's like, look learn, i- i- imagine you know,", "start": 1065.16, "duration": 2.91}, {"text": "you're, you're looking at learning algorithms and say,", "start": 1068.07, "duration": 1.845}, {"text": "it's like this algorithm has seen these examples and", "start": 1069.915, "duration": 2.67}, {"text": "even for examples it's seen, it's not doing as well as you were hoping.", "start": 1072.585, "duration": 2.925}, {"text": "So clearly the algorithm's not fitting the data well enough.", "start": 1075.51, "duration": 3.3}, {"text": "So this is a sign that you have a high bias problem,", "start": 1078.81, "duration": 3.51}, {"text": "not enough features, your learning algorithm is too simple.", "start": 1082.32, "duration": 2.715}, {"text": "And the other signal is that, um,", "start": 1085.035, "duration": 3.795}, {"text": "uh, this is very a small gap between the training and, uh, the test error, right?", "start": 1088.83, "duration": 3.87}, {"text": "And you can imagine when you see a plot like this,", "start": 1092.7, "duration": 3.375}, {"text": "no matter how much more data you get, right,", "start": 1096.075, "duration": 2.565}, {"text": "go ahead and extrapolate to the right,", "start": 1098.64, "duration": 1.725}, {"text": "as far as you want, you know.", "start": 1100.365, "duration": 1.995}, {"text": "No matter how much more data you get,", "start": 1102.36, "duration": 2.16}, {"text": "um, no matter how far you extrapolate to the right of this plot,", "start": 1104.52, "duration": 3.555}, {"text": "the gree- the blue curve, the training error,", "start": 1108.075, "duration": 2.505}, {"text": "is never going to come back down,", "start": 1110.58, "duration": 1.65}, {"text": "to hit the desired level of performance.", "start": 1112.23, "duration": 2.385}, {"text": "Uh, and because the test set error is you", "start": 1114.615, "duration": 2.485}, {"text": "know generally higher than your training set error,", "start": 1117.1, "duration": 2.33}, {"text": "no matter how much more data you have,", "start": 1119.43, "duration": 1.87}, {"text": "no matter how far you extrapolate to the right,", "start": 1121.3, "duration": 2.025}, {"text": "the error is never going to come down to,", "start": 1123.325, "duration": 2.325}, {"text": "to your desired level of performance.", "start": 1125.65, "duration": 1.815}, {"text": "So if you get a, um,", "start": 1127.465, "duration": 2.3}, {"text": "training error and test error curve that looks like this,", "start": 1129.765, "duration": 3.315}, {"text": "you kind of know that, you know,", "start": 1133.08, "duration": 1.895}, {"text": "while getting more training data may help, right?", "start": 1134.975, "duration": 3.655}, {"text": "The green curve could come down, like a little bit.", "start": 1138.63, "duration": 1.98}, {"text": "If you get more training data, uh,", "start": 1140.61, "duration": 2.385}, {"text": "the act of getting more training data by", "start": 1142.995, "duration": 2.785}, {"text": "itself will never get you to where you want to go.", "start": 1145.78, "duration": 2.79}, {"text": "Okay? Um, so let's work through this example.", "start": 1148.57, "duration": 7.005}, {"text": "So for each of the four bullets here, um,", "start": 1155.575, "duration": 5.01}, {"text": "each of the four- first four ideas fixes", "start": 1160.585, "duration": 2.625}, {"text": "either a high variance or a high bias problem, right?", "start": 1163.21, "duration": 3.59}, {"text": "So let's, let's go through them and, and ask, uh,", "start": 1166.8, "duration": 3.63}, {"text": "for the first one,", "start": 1170.43, "duration": 1.845}, {"text": "do you think it, do you think it helps you fix high bias or high variance?", "start": 1172.275, "duration": 4.765}, {"text": "[BACKGROUND]", "start": 1177.04, "duration": 8.699}, {"text": "High variance, right?", "start": 1185.739, "duration": 1.066}, {"text": "Okay. Right. Cool. All right, high variance, right?", "start": 1186.805, "duration": 2.885}, {"text": "A- anyone want to say, say- well, great.", "start": 1189.69, "duration": 3.015}, {"text": "Anyone want to say why? Yeah, okay.", "start": 1192.705, "duration": 10.035}, {"text": "[inaudible]", "start": 1202.74, "duration": 7.5}, {"text": "All right, cool, yes, uh, right. Yeah, right.", "start": 1210.24, "duration": 2.745}, {"text": "I guess if you're fitting a very high order polynomial that wiggles like this,", "start": 1212.985, "duration": 3.3}, {"text": "if you have more data,", "start": 1216.285, "duration": 1.185}, {"text": "it will make it- then you won't have these oscillates,", "start": 1217.47, "duration": 3.18}, {"text": "so crazy even if you have a higher order polynomial.", "start": 1220.65, "duration": 3.195}, {"text": "Right. And, um, if you look at a", "start": 1223.845, "duration": 2.31}, {"text": "high variance curve, um,", "start": 1226.155, "duration": 5.575}, {"text": "this was- wow, there's a lot of latency, you know.", "start": 1232.27, "duration": 3.94}, {"text": "That's all for some reason.", "start": 1236.21, "duration": 2.94}, {"text": "Huh. Right, sSo this is a high variance plot.", "start": 1239.15, "duration": 9.555}, {"text": "Um, and, uh, uh,", "start": 1248.705, "duration": 3.015}, {"text": "and if you have a learning algorithm of high variance, you can,", "start": 1251.72, "duration": 3.465}, {"text": "hopefully, you know, if you extrapolate to the right,", "start": 1255.185, "duration": 3.135}, {"text": "there is some hope that the green curve will keep on coming down.", "start": 1258.32, "duration": 3.84}, {"text": "So, so getting more training data if you have high variance,", "start": 1262.16, "duration": 3.69}, {"text": "which is if you're in this situation,", "start": 1265.85, "duration": 1.365}, {"text": "looks like it could help you- help- it's,", "start": 1267.215, "duration": 1.845}, {"text": "it's worth trying, right?", "start": 1269.06, "duration": 1.2}, {"text": "I can't guarantee it work, but it's worth trying.", "start": 1270.26, "duration": 2.31}, {"text": "[inaudible] when you think about these functions,", "start": 1272.57, "duration": 3.299}, {"text": "like for certain algorithms [inaudible] uniformly distributed.", "start": 1275.869, "duration": 5.566}, {"text": "Oh, I see. Yes. Sorry. That's a good one. So let's see.", "start": 1281.435, "duration": 2.865}, {"text": "Um, the curves will look like this assuming that your training data is IID, right?", "start": 1284.3, "duration": 5.67}, {"text": "Um, the training and dev and test sets are all drawn from the same distribution.", "start": 1289.97, "duration": 4.32}, {"text": "Uh, uh, uh, there is learning theory that suggests that in most cases,", "start": 1294.29, "duration": 5.025}, {"text": "the green curve should decay as 1 over", "start": 1299.315, "duration": 2.385}, {"text": "square roots of m. That's the rate that which it should decay,", "start": 1301.7, "duration": 2.64}, {"text": "uh, until, until it reaches some Bayes error.", "start": 1304.34, "duration": 3.285}, {"text": "That's what the learning theory says.", "start": 1307.625, "duration": 2.055}, {"text": "Does that make sense? Um, and sometime- and,", "start": 1309.68, "duration": 4.425}, {"text": "and learning algorithms errors don't always go to 0, right?", "start": 1314.105, "duration": 2.475}, {"text": "Because sometimes, uh, uh,", "start": 1316.58, "duration": 1.305}, {"text": "there- sometimes, um, the data is just ambiguous.", "start": 1317.885, "duration": 3.15}, {"text": "I don't know, like, uh, I guess, you know,", "start": 1321.035, "duration": 2.01}, {"text": "my PhD students, including Annan,", "start": 1323.045, "duration": 1.68}, {"text": "we do a lot of work in healthcare.", "start": 1324.725, "duration": 1.455}, {"text": "And sometimes when you look at an x-ray,", "start": 1326.18, "duration": 2.085}, {"text": "it's just blurry, and you could try to make a diagnosis, right?", "start": 1328.265, "duration": 3.315}, {"text": "Is there, is there, uh- or I actually,", "start": 1331.58, "duration": 2.655}, {"text": "Annan is working on predicting patient's mortality.", "start": 1334.235, "duration": 2.265}, {"text": "What's the chance that someone dying in the next year or so?", "start": 1336.5, "duration": 2.52}, {"text": "And sometimes you look at a patient's medical record,", "start": 1339.02, "duration": 2.91}, {"text": "and you just can't tell when- what's,", "start": 1341.93, "duration": 1.905}, {"text": "you know, will, will they pass away in the next year or so.", "start": 1343.835, "duration": 2.235}, {"text": "Or you're looking at an x-ray,", "start": 1346.07, "duration": 1.38}, {"text": "you just can't tell is there,", "start": 1347.45, "duration": 1.68}, {"text": "is there a tumor or not?", "start": 1349.13, "duration": 1.11}, {"text": "Because it's just blurry, and so learning algorithm's error don't always decay to zero,", "start": 1350.24, "duration": 4.365}, {"text": "but the theory says that as,", "start": 1354.605, "duration": 1.89}, {"text": "as M increases, it will decay at roughly a rate of 1 over square root of M,", "start": 1356.495, "duration": 3.495}, {"text": "um, toward that baseline error,", "start": 1359.99, "duration": 2.235}, {"text": "which is, which is called Bayes error,", "start": 1362.225, "duration": 1.665}, {"text": "which is the best that you could possibly hope", "start": 1363.89, "duration": 1.5}, {"text": "anything could do given how blurry the images are,", "start": 1365.39, "duration": 2.87}, {"text": "given how noisy the vector is, right?", "start": 1368.26, "duration": 3.13}, {"text": "All right. Um, sorry,", "start": 1372.66, "duration": 2.8}, {"text": "I gave the answer away. [LAUGHTER] Okay.", "start": 1375.46, "duration": 1.545}, {"text": "So uh, try a smaller set of features, uh,", "start": 1377.005, "duration": 2.55}, {"text": "that fixes a high variance problem.", "start": 1379.555, "duration": 3.18}, {"text": "Right? Uh, and one concrete example would be, um,", "start": 1382.735, "duration": 3.9}, {"text": "if you have this dataset and you're fitting a, you know,", "start": 1386.635, "duration": 2.265}, {"text": "10th order polynomial and the curve oscillates all over the place, that's high variance.", "start": 1388.9, "duration": 4.41}, {"text": "You can say, well,", "start": 1393.31, "duration": 1.57}, {"text": "maybe I don't need a 10th order polynomial,", "start": 1394.88, "duration": 2.069}, {"text": "maybe I should use, you know,", "start": 1396.949, "duration": 1.471}, {"text": "only- Wow, I don't know where my- I'm sorry. I don't know what's going on?", "start": 1398.42, "duration": 3.9}, {"text": "[NOISE] Okay. All right.", "start": 1402.32, "duration": 4.62}, {"text": "So maybe you say maybe I don't need my features to be", "start": 1406.94, "duration": 2.94}, {"text": "all of these things, 10th order polynomial,", "start": 1409.88, "duration": 3.225}, {"text": "maybe if this is too high variance,", "start": 1413.105, "duration": 1.515}, {"text": "I'm going to get rid of a lot of features and just use,", "start": 1414.62, "duration": 2.37}, {"text": "you know, a much smaller number of features.", "start": 1416.99, "duration": 2.535}, {"text": "Right? So that fixes,", "start": 1419.525, "duration": 1.185}, {"text": "um, uh, high variance.", "start": 1420.71, "duration": 3.585}, {"text": "Um, and then if you use a larger set of features [NOISE] [inaudible] , right?", "start": 1424.295, "duration": 8.775}, {"text": "Cool. So that's if you're fitting", "start": 1433.07, "duration": 2.28}, {"text": "a straight line to the data and it's not doing that well,", "start": 1435.35, "duration": 2.535}, {"text": "you can go, \"Gee, maybe I should add a quadratic term,\" just add more features, right?", "start": 1437.885, "duration": 4.335}, {"text": "So that fixes variance.", "start": 1442.22, "duration": 1.305}, {"text": "And adding e-mail header features.", "start": 1443.525, "duration": 2.325}, {"text": "[BACKGROUND] Cool.", "start": 1445.85, "duration": 4.395}, {"text": "Yeah. Generally, I would try this if- um,", "start": 1450.245, "duration": 2.965}, {"text": "ah, to try to reduce bias.", "start": 1453.21, "duration": 2.84}, {"text": "And so in the workflow of, um,", "start": 1456.05, "duration": 3.84}, {"text": "how you develop a learning algorithm, ah,", "start": 1459.89, "duration": 2.19}, {"text": "I would recommend that, um, you,", "start": 1462.08, "duration": 3.66}, {"text": "ah- so, so one of the things about,", "start": 1465.74, "duration": 2.85}, {"text": "um, building learning algorithms, is that,", "start": 1468.59, "duration": 3.075}, {"text": "for a new application problem, uh,", "start": 1471.665, "duration": 4.17}, {"text": "it's difficult to know in advance, uh,", "start": 1475.835, "duration": 2.745}, {"text": "if you're gonna run into a high bias or high variance problem, right?", "start": 1478.58, "duration": 4.23}, {"text": "It, it is actually very difficult to know in", "start": 1482.81, "duration": 2.31}, {"text": "advance what's gonna go wrong with your learning algorithm.", "start": 1485.12, "duration": 2.925}, {"text": "And so the advice I tend to give is, uh,", "start": 1488.045, "duration": 3.525}, {"text": "if you're working on a new application,", "start": 1491.57, "duration": 2.055}, {"text": "uh, implement a quick and dirty learning algorithm.", "start": 1493.625, "duration": 2.145}, {"text": "It, it will have like a quick and dirty implementation of something.", "start": 1495.77, "duration": 3.39}, {"text": "So you can run your learning algorithm,", "start": 1499.16, "duration": 2.414}, {"text": "uh, just say- start with logistic regression, right?", "start": 1501.574, "duration": 2.506}, {"text": "Let's start with something simple.", "start": 1504.08, "duration": 1.59}, {"text": "Um, and then run this bias-variance type of analysis, uh,", "start": 1505.67, "duration": 4.455}, {"text": "to see, sort of,", "start": 1510.125, "duration": 1.53}, {"text": "what went wrong and then use that to decide what to do next.", "start": 1511.655, "duration": 4.305}, {"text": "You go to a more complex algorithm,", "start": 1515.96, "duration": 1.71}, {"text": "do you try adding more data?", "start": 1517.67, "duration": 2.22}, {"text": "Um, the, the one exception to this is if you're", "start": 1519.89, "duration": 3.36}, {"text": "working on a domain in which you have a lot of experience, right?", "start": 1523.25, "duration": 3.12}, {"text": "Uh, and, and so for example,", "start": 1526.37, "duration": 2.145}, {"text": "you know, I've done a lot of work on speech recognition.", "start": 1528.515, "duration": 2.535}, {"text": "So because I've done that work,", "start": 1531.05, "duration": 1.725}, {"text": "I kinda have a sense of how much data is needed for the application,", "start": 1532.775, "duration": 3.45}, {"text": "then, then I might just build something more complicated from the get go.", "start": 1536.225, "duration": 3.795}, {"text": "Or, or if you're doing- or if you're working on, say,", "start": 1540.02, "duration": 2.52}, {"text": "face recognition and because you've read a lot of research papers,", "start": 1542.54, "duration": 2.76}, {"text": "you have a sense of how much data is needed.", "start": 1545.3, "duration": 2.01}, {"text": "Then maybe it's worth trying something because you're building on a body of knowledge.", "start": 1547.31, "duration": 3.84}, {"text": "Uh, but, but if you're working on something,", "start": 1551.15, "duration": 2.22}, {"text": "on a brand new application that you and maybe,", "start": 1553.37, "duration": 2.895}, {"text": "you know, no one in the published academic literature has worked on or,", "start": 1556.265, "duration": 3.255}, {"text": "or you don't totally", "start": 1559.52, "duration": 1.2}, {"text": "trust the published results to be representative of your problem,", "start": 1560.72, "duration": 3.405}, {"text": "then I will usually recommend that, um,", "start": 1564.125, "duration": 2.865}, {"text": "you implement a- build a quick and dirty implementation,", "start": 1566.99, "duration": 2.67}, {"text": "look at the bias and variance of the algorithm, uh,", "start": 1569.66, "duration": 2.55}, {"text": "and then use that to better decide what to try next.", "start": 1572.21, "duration": 3.915}, {"text": "Right? Um, so I think,", "start": 1576.125, "duration": 3.18}, {"text": "uh, bias and variance is, uh,", "start": 1579.305, "duration": 2.49}, {"text": "I think, is actua- is really like the single most powerful tool I know,", "start": 1581.795, "duration": 3.21}, {"text": "you know, for analyzing the performance of learning algorithms.", "start": 1585.005, "duration": 2.715}, {"text": "And I do this pretty much in every single machine learning application.", "start": 1587.72, "duration": 3.135}, {"text": "Um, there's one other pattern that I see quite often,", "start": 1590.855, "duration": 4.395}, {"text": "which is, um, uh- which,", "start": 1595.25, "duration": 2.1}, {"text": "which addresses the second set, which is, um,", "start": 1597.35, "duration": 2.79}, {"text": "uh, which is a- which is the optimization algorithm, ah, working.", "start": 1600.14, "duration": 6.33}, {"text": "So, so let me, let me explain this with,", "start": 1606.47, "duration": 1.8}, {"text": "um, a motivating example, right?", "start": 1608.27, "duration": 2.115}, {"text": "So, um, it turns out that when you implement a learning algorithm,", "start": 1610.385, "duration": 4.334}, {"text": "uh, you often have a few guesses for what's wrong.", "start": 1614.719, "duration": 3.721}, {"text": "And if you can systematically test if", "start": 1618.44, "duration": 3.45}, {"text": "that hypothesis is right before you spend a lot of work to try to fix it,", "start": 1621.89, "duration": 3.51}, {"text": "then you could be much more efficient.", "start": 1625.4, "duration": 1.425}, {"text": "So, uh, let's explain that with a concrete example.", "start": 1626.825, "duration": 2.865}, {"text": "So, so you understand those words I just said,", "start": 1629.69, "duration": 1.83}, {"text": "maybe they're a little bit abstract, which is,", "start": 1631.52, "duration": 1.785}, {"text": "um, let's say that, you know,", "start": 1633.305, "duration": 2.145}, {"text": "you tuned your logistic regression algorithm for a while.", "start": 1635.45, "duration": 3.12}, {"text": "And lets say logistic regression gets 2%t error on", "start": 1638.57, "duration": 2.76}, {"text": "spam e-mail and a 2% error on non-spam, right?", "start": 1641.33, "duration": 3.915}, {"text": "And it's okay to have 2% error on spam e-mail, maybe, right?", "start": 1645.245, "duration": 4.065}, {"text": "You know, so you, you have to read a little bit of spam e-mail.", "start": 1649.31, "duration": 2.835}, {"text": "It's like, that's okay.", "start": 1652.145, "duration": 1.845}, {"text": "Uh, but 2% error on non-spam is just not really", "start": 1653.99, "duration": 3.24}, {"text": "acceptable because you're losing 1 in 50 important e-mails.", "start": 1657.23, "duration": 3.795}, {"text": "Um, and let's say that,", "start": 1661.025, "duration": 3.33}, {"text": "uh, you know, your teammate, right,", "start": 1664.355, "duration": 2.13}, {"text": "also try- trains an SVM and they find", "start": 1666.485, "duration": 3.585}, {"text": "in SVM using a linear kernel gets 10% error on spam,", "start": 1670.07, "duration": 3.66}, {"text": "uh, but 0.01% error on non-spam.", "start": 1673.73, "duration": 3.945}, {"text": "All right. And maybe not great,", "start": 1677.675, "duration": 1.605}, {"text": "but for this- for purposes of illustration,", "start": 1679.28, "duration": 1.89}, {"text": "let's say this is acceptable.", "start": 1681.17, "duration": 1.89}, {"text": "Um, but because it turns out logistic regression is more computationally efficient and,", "start": 1683.06, "duration": 6.885}, {"text": "and it may be easier to update, right?", "start": 1689.945, "duration": 2.505}, {"text": "And you get more examples,", "start": 1692.45, "duration": 1.2}, {"text": "run a few more iterations of gradient descent.", "start": 1693.65, "duration": 1.56}, {"text": "Uh, and let's say you want to ship", "start": 1695.21, "duration": 2.01}, {"text": "a logistic regression implementation rather than SVM implementation.", "start": 1697.22, "duration": 3.72}, {"text": "Um, so what do you do next?", "start": 1700.94, "duration": 2.31}, {"text": "It turns out that, um,", "start": 1703.25, "duration": 2.79}, {"text": "one common question you have when training your learning algorithm is,", "start": 1706.04, "duration": 5.025}, {"text": "you often wonder, uh,", "start": 1711.065, "duration": 1.86}, {"text": "is your, um, optimization algorithm converging?", "start": 1712.925, "duration": 4.005}, {"text": "Right? So you know, it's,", "start": 1716.93, "duration": 1.515}, {"text": "it's gradient ascent, is it converging?", "start": 1718.445, "duration": 2.655}, {"text": "And so one thing you might do is, uh,", "start": 1721.1, "duration": 2.745}, {"text": "draw a plot of the training optimization objective,", "start": 1723.845, "duration": 3.96}, {"text": "of J of Theta,", "start": 1727.805, "duration": 1.08}, {"text": "whatever you are maximizing or log likelihood of J of Theta or whatever,", "start": 1728.885, "duration": 3.375}, {"text": "versus the number of iterations.", "start": 1732.26, "duration": 1.875}, {"text": "And, um, often the plot will look like that, right?", "start": 1734.135, "duration": 3.975}, {"text": "And, you know, the curve is,", "start": 1738.11, "duration": 1.98}, {"text": "kind of, going up,", "start": 1740.09, "duration": 1.26}, {"text": "but not that fast.", "start": 1741.35, "duration": 1.62}, {"text": "And if you train it twice as long or even 10 times as long, will that help?", "start": 1742.97, "duration": 4.83}, {"text": "Right? And again, training,", "start": 1747.8, "duration": 1.26}, {"text": "training the algorithm for more iterations,", "start": 1749.06, "duration": 1.845}, {"text": "it, you know, pretty much never hurts.", "start": 1750.905, "duration": 2.355}, {"text": "If, if you regularize the algorithm properly,", "start": 1753.26, "duration": 1.98}, {"text": "training the algorithm longer, you know,", "start": 1755.24, "duration": 1.995}, {"text": "almo- almost always helps, right?", "start": 1757.235, "duration": 2.145}, {"text": "Pretty much never hurts, uh,", "start": 1759.38, "duration": 1.785}, {"text": "but it's the right thing to do to go and burn another 48 hours of,", "start": 1761.165, "duration": 5.085}, {"text": "you know, CPU or GPU cycles to just train this thing longer and hoping it works better.", "start": 1766.25, "duration": 4.65}, {"text": "Right? Maybe. Maybe not.", "start": 1770.9, "duration": 1.62}, {"text": "Um, so is there a,", "start": 1772.52, "duration": 1.77}, {"text": "is there a systematic way to tell- is there a better way, uh,", "start": 1774.29, "duration": 4.71}, {"text": "to tell if you should invest a lot more time,", "start": 1779.0, "duration": 3.015}, {"text": "um, in running the optimization algorithm?", "start": 1782.015, "duration": 2.205}, {"text": "Sometimes it's just hard to tell, right?", "start": 1784.22, "duration": 2.095}, {"text": "So, um, now, the other question that you sometimes wonder- so,", "start": 1786.315, "duration": 6.785}, {"text": "so a lot of- um,", "start": 1793.1, "duration": 1.68}, {"text": "where a lot of this iteration of", "start": 1794.78, "duration": 1.8}, {"text": "debugging learning algorithms is looking at what your learning algorithm is", "start": 1796.58, "duration": 2.19}, {"text": "doing and just asking yourself what are my guesses for what could be wrong.", "start": 1798.77, "duration": 4.315}, {"text": "Uh, and maybe one of your guesses is, well,", "start": 1803.085, "duration": 2.245}, {"text": "maybe optimizing the wrong cost function.", "start": 1805.33, "duration": 2.46}, {"text": "Right? So, so here is what I mean.", "start": 1807.79, "duration": 1.71}, {"text": "Um, what you care about is this, um,", "start": 1809.5, "duration": 2.655}, {"text": "weighted accuracy criteria, uh,", "start": 1812.155, "duration": 3.55}, {"text": "you know, where, uh,", "start": 1815.705, "duration": 2.905}, {"text": "sum over your dev set or test set of, you know,", "start": 1818.61, "duration": 3.575}, {"text": "weights on different examples of whether it gets it right,", "start": 1822.185, "duration": 3.285}, {"text": "uh, where the weights are higher for non-spammed and spam.", "start": 1825.47, "duration": 3.84}, {"text": "Because you really make sure you label non-spam e-mail correctly, right?", "start": 1829.31, "duration": 3.87}, {"text": "So, so maybe that's the weighted accuracy criteria you care about.", "start": 1833.18, "duration": 3.75}, {"text": "Uh, but for logistic regression,", "start": 1836.93, "duration": 4.335}, {"text": "uh, you are maximizing this cost function, right?", "start": 1841.265, "duration": 3.3}, {"text": "Law of likelihood minus this regularization term.", "start": 1844.565, "duration": 2.655}, {"text": "So you're optimizing J of Theta,", "start": 1847.22, "duration": 2.85}, {"text": "when what you actually care about is A of Theta.", "start": 1850.07, "duration": 3.57}, {"text": "So maybe you're optimizing the wrong cost function.", "start": 1853.64, "duration": 3.495}, {"text": "And then one way to change the cost function", "start": 1857.135, "duration": 2.145}, {"text": "would be to fiddle with the parameter Lambda, right?", "start": 1859.28, "duration": 2.43}, {"text": "That's one way to change the definition of J of Theta.", "start": 1861.71, "duration": 2.73}, {"text": "Um, another way to change J of Theta is to", "start": 1864.44, "duration": 3.15}, {"text": "just totally change the cost function you are maximizing,", "start": 1867.59, "duration": 3.015}, {"text": "like change it to the SVM objective, right?", "start": 1870.605, "duration": 2.43}, {"text": "Or, or- and then part of that also means choosing the appropriate value for C. Okay?", "start": 1873.035, "duration": 6.595}, {"text": "And so, um, there is a second diagnostic which, um,", "start": 1879.74, "duration": 6.37}, {"text": "I end up using i- th- th- which is - which I hope you can tell,", "start": 1886.11, "duration": 4.2}, {"text": "is the problem your optimization algorithm?", "start": 1890.31, "duration": 3.27}, {"text": "Uh, in other words is gradient ascent not converging?", "start": 1893.58, "duration": 3.69}, {"text": "Or is the problem that you're just optimizing the wrong function?", "start": 1897.27, "duration": 3.915}, {"text": "Right? And, and we'll see two examples of this thing.", "start": 1901.185, "duration": 2.415}, {"text": "So this is the first example.", "start": 1903.6, "duration": 1.38}, {"text": "Okay? Um, and so here's the diagnostic that can help you figure that out.", "start": 1904.98, "duration": 5.025}, {"text": "So just to summarize this scenario- this, um, this, uh,", "start": 1910.005, "duration": 3.57}, {"text": "example - this running example we're using,", "start": 1913.575, "duration": 2.19}, {"text": "um, the SVM outperforms logistic regression.", "start": 1915.765, "duration": 2.835}, {"text": "If you want to deploy logistic regression.", "start": 1918.6, "duration": 1.89}, {"text": "Uh, let's say that theta SVM for the parameters learned by SVM.", "start": 1920.49, "duration": 3.255}, {"text": "And, and instead of writing the SVM parameters as w and b,", "start": 1923.745, "duration": 3.51}, {"text": "I'm just gonna write the linear SVM.", "start": 1927.255, "duration": 2.1}, {"text": "SVM linear kernel.", "start": 1929.355, "duration": 1.215}, {"text": "You know, using the logistic regression parameterization.", "start": 1930.57, "duration": 3.09}, {"text": "Right? So if you have a linear set of parameters.", "start": 1933.66, "duration": 2.67}, {"text": "Um, and let's say that theta BLR will be the parameters learned by logistic regression.", "start": 1936.33, "duration": 3.915}, {"text": "Right? So I'll, I'll just- yeah,", "start": 1940.245, "duration": 2.04}, {"text": "regularized logistic regression or Bayesian logistic regression.", "start": 1942.285, "duration": 3.3}, {"text": "So you care about weighted accuracy and, uh, uh, um,", "start": 1945.585, "duration": 3.795}, {"text": "uh, and the, the SVM outperforms Bayesian logistic regression.", "start": 1949.38, "duration": 6.195}, {"text": "Okay? So this is one- a one-slide summary of where we are in this example.", "start": 1955.575, "duration": 5.73}, {"text": "So how can you tell if the problem is your optimization algorithm,", "start": 1961.305, "duration": 5.504}, {"text": "uh, meaning that you need to run gradient ascent longer to actually maximize J of Theta.", "start": 1966.809, "duration": 5.686}, {"text": "Um, or this- oh, sorry. And then- right.", "start": 1972.495, "duration": 2.565}, {"text": "And this is the- what BLR tries to maximize.", "start": 1975.06, "duration": 2.955}, {"text": "Right? So, so how do you tell, we have,", "start": 1978.015, "duration": 2.31}, {"text": "we've two possible hypotheses you wanna distinguish between.", "start": 1980.325, "duration": 3.285}, {"text": "One is that, um,", "start": 1983.61, "duration": 2.01}, {"text": "the learning algorithm is not actually finding", "start": 1985.62, "duration": 2.73}, {"text": "the value of Theta that maximizes J of Theta. All right?", "start": 1988.35, "duration": 3.42}, {"text": "For some reason gradient ascent is not converging.", "start": 1991.77, "duration": 2.805}, {"text": "So that would be a problem with the optimization algorithm.", "start": 1994.575, "duration": 2.835}, {"text": "That j of Theta that, that,", "start": 1997.41, "duration": 1.71}, {"text": "that, you know, uh, for,", "start": 1999.12, "duration": 1.515}, {"text": "for the property of the- for", "start": 2000.635, "duration": 1.485}, {"text": "the problem to be with the optimization algorithm it means that,", "start": 2002.12, "duration": 2.715}, {"text": "if only we could have an algorithm that maximizes j of Theta we would do great.", "start": 2004.835, "duration": 4.605}, {"text": "But for some reason gradient ascent isn't doing well.", "start": 2009.44, "duration": 2.97}, {"text": "That's one hypothesis.", "start": 2012.41, "duration": 1.515}, {"text": "The second hypothesis is that J of Theta is just the wrong function to be optimizing.", "start": 2013.925, "duration": 3.9}, {"text": "It is just a bad choice of cost function,", "start": 2017.825, "duration": 1.965}, {"text": "that j of Theta is too different from A of Theta,", "start": 2019.79, "duration": 3.405}, {"text": "that maximizing J of theta doesn't give you,", "start": 2023.195, "duration": 2.895}, {"text": "you know a classifier that does well on A of theta which is what you actually care about.", "start": 2026.09, "duration": 5.595}, {"text": "Okay? Any que- so this is a problem setup.", "start": 2031.685, "duration": 3.225}, {"text": "Is there any, any que- I wanna make sure people understand this.", "start": 2034.91, "duration": 2.115}, {"text": "This is- raise, raise your hand if this makes sense.", "start": 2037.025, "duration": 2.94}, {"text": "Most people? Okay. Cool. Almost everyone, okay.", "start": 2039.965, "duration": 3.39}, {"text": "Good. Any questions about this problem setup?", "start": 2043.355, "duration": 3.42}, {"text": "Why don't you, why don't you [inaudible].", "start": 2046.775, "duration": 2.955}, {"text": "Oh. Uh, thank you. Why not maximize A of Theta directly?", "start": 2049.73, "duration": 2.805}, {"text": "Because A of Theta is non-differentiable.", "start": 2052.535, "duration": 1.845}, {"text": "So we don't actually have,", "start": 2054.38, "duration": 1.29}, {"text": "um, you know there's this indicator function.", "start": 2055.67, "duration": 2.07}, {"text": "So it's- we actually don't- we, uh,", "start": 2057.74, "duration": 2.11}, {"text": "- it turns out maximizing A of Theta explicitly is NP-hard.", "start": 2059.85, "duration": 3.2}, {"text": "Uh, uh, but just- we just don't have great algorithms to try and do, do that.", "start": 2063.05, "duration": 5.11}, {"text": "Okay. So it turns out there's a diagnostic you could", "start": 2068.53, "duration": 4.81}, {"text": "use to distinguish between these of two- these two different problems.", "start": 2073.34, "duration": 4.92}, {"text": "Um, and here's the diagnostic.", "start": 2078.26, "duration": 1.95}, {"text": "Which is, check the cost function that logistic regression is trying to maximize.", "start": 2080.21, "duration": 7.95}, {"text": "So J. And compute that cost function on the parameters found by", "start": 2088.16, "duration": 5.85}, {"text": "the SVM and compute that cost function", "start": 2094.01, "duration": 3.135}, {"text": "on the parameters found by Bayesian logistic regression.", "start": 2097.145, "duration": 3.525}, {"text": "And just see which, which value is higher.", "start": 2100.67, "duration": 2.73}, {"text": "Okay? Um, so there are two cases.", "start": 2103.4, "duration": 4.74}, {"text": "Either, this is greater,", "start": 2108.14, "duration": 2.414}, {"text": "or this is less than or equal to.", "start": 2110.554, "duration": 2.386}, {"text": "Right? They're just two possible cases.", "start": 2112.94, "duration": 1.86}, {"text": "So what I'm gonna do is go over case one and case two", "start": 2114.8, "duration": 3.705}, {"text": "corresponding to this greater than or is less than equal than.", "start": 2118.505, "duration": 3.645}, {"text": "Uh, and let's, let's see what that implies.", "start": 2122.15, "duration": 2.22}, {"text": "So on the next slide, I'm gonna copy over this equation.", "start": 2124.37, "duration": 3.54}, {"text": "Right? That's, that's just a fact that the SVM does", "start": 2127.91, "duration": 2.55}, {"text": "better than Bayesian logistic regression on a problem.", "start": 2130.46, "duration": 3.045}, {"text": "So on the next I'm gonna copy over this first equation.", "start": 2133.505, "duration": 3.0}, {"text": "Um, and then we're gonna consider,", "start": 2136.505, "duration": 1.755}, {"text": "you know, these two cases separately.", "start": 2138.26, "duration": 1.98}, {"text": "So greater than will be case one and less than or equal to will be case two.", "start": 2140.24, "duration": 3.3}, {"text": "Okay? So let me copy over these two equations in the next slide.", "start": 2143.54, "duration": 3.72}, {"text": "Right? So that's the first equation that I just copied over here.", "start": 2147.26, "duration": 3.81}, {"text": "And that's- this is the greater than, this is case one.", "start": 2151.07, "duration": 3.075}, {"text": "Okay? So let's see how to interpret this.", "start": 2154.145, "duration": 4.11}, {"text": "Um, in case one,", "start": 2158.255, "duration": 3.52}, {"text": "J of theta SVM is greater than J of Theta BLR.", "start": 2161.775, "duration": 5.2}, {"text": "Right? Meaning that whatever the SVM was doing, um,", "start": 2166.975, "duration": 5.275}, {"text": "it found a value for Theta which we have written as, Theta SVM.", "start": 2172.25, "duration": 8.65}, {"text": "And theta SVM has a higher value on the cost function J than theta BLR.", "start": 2180.9, "duration": 8.81}, {"text": "But Bayesian logistic regression was trying to maximize J of theta.", "start": 2189.71, "duration": 6.0}, {"text": "Right? I mean Bayesian logistic regression is just using", "start": 2195.71, "duration": 2.22}, {"text": "gradient ascent to try to maximize J of theta.", "start": 2197.93, "duration": 4.07}, {"text": "And so under case one,", "start": 2202.0, "duration": 2.625}, {"text": "this shows that whatever the SVM was doing,", "start": 2204.625, "duration": 3.825}, {"text": "whatever your buddy implementing SVM did.", "start": 2208.45, "duration": 2.91}, {"text": "They managed to find a value for Theta", "start": 2211.36, "duration": 2.96}, {"text": "that actually achieves a higher value of J of Theta,", "start": 2214.32, "duration": 3.695}, {"text": "than your implementation of Bayesian logistic regression.", "start": 2218.015, "duration": 3.705}, {"text": "So this means that Theta BLR fails to maximize the cost function J.", "start": 2221.72, "duration": 5.82}, {"text": "And, uh, and the problem is with the optimization algorithm.", "start": 2227.54, "duration": 5.115}, {"text": "Okay? So this is case one.", "start": 2232.655, "duration": 2.19}, {"text": "Case two, um- again I'm just copying over the first equation.", "start": 2234.845, "duration": 5.58}, {"text": "Right? Because this is just part of our analysis.", "start": 2240.425, "duration": 2.115}, {"text": "This is part of the problem set up.", "start": 2242.54, "duration": 1.515}, {"text": "Uh, then case two is now the second line.", "start": 2244.055, "duration": 2.265}, {"text": "It's now a less than or equal sign.", "start": 2246.32, "duration": 1.845}, {"text": "Okay? So let's see how to interpret this.", "start": 2248.165, "duration": 5.07}, {"text": "Um, so under- if you look at the second equation right?", "start": 2253.235, "duration": 3.825}, {"text": "The less than equal to sign.", "start": 2257.06, "duration": 1.59}, {"text": "It looks like J did a better job than the SVM maximizing J- excuse me.", "start": 2258.65, "duration": 7.38}, {"text": "It looks like Bayesian logistic regression did a better job than the SVM,", "start": 2266.03, "duration": 4.184}, {"text": "um, maximizing J of Theta.", "start": 2270.214, "duration": 2.626}, {"text": "Right? So, you know,", "start": 2272.84, "duration": 1.38}, {"text": "you tell Bayesian logistic regression to maximize J of Theta.", "start": 2274.22, "duration": 3.495}, {"text": "And by golly, it found the- it found the value of Theta.", "start": 2277.715, "duration": 3.345}, {"text": "That's that- it found a value that achieves a higher value of J of Theta than,", "start": 2281.06, "duration": 4.365}, {"text": "than whatever your buddy did using an SVM implementation.", "start": 2285.425, "duration": 2.805}, {"text": "So it actually did a good job", "start": 2288.23, "duration": 1.41}, {"text": "trying to find a value of Theta that drives up J of Theta as much as possible.", "start": 2289.64, "duration": 6.105}, {"text": "But if you look at these two equations in combination what we have is that,", "start": 2295.745, "duration": 5.145}, {"text": "um, the SVM does worse on the cost function J.", "start": 2300.89, "duration": 6.75}, {"text": "But it does better on the thing you actually care about.", "start": 2307.64, "duration": 3.915}, {"text": "A of Theta.", "start": 2311.555, "duration": 1.665}, {"text": "So what these two equations in combination tell you is that having the best value-", "start": 2313.22, "duration": 6.855}, {"text": "the highest value for J of Theta does not", "start": 2320.075, "duration": 3.405}, {"text": "correspond to having the best possible value for A of Theta.", "start": 2323.48, "duration": 4.995}, {"text": "So it tells you that maximizing J of", "start": 2328.475, "duration": 3.105}, {"text": "Theta doesn't mean you're doing a good job on A of Theta.", "start": 2331.58, "duration": 3.78}, {"text": "And therefore, maybe J of Theta is not such a good thing to be maximizing.", "start": 2335.36, "duration": 4.23}, {"text": "Because maximizing it, doesn't actually give you the result you ultimately care about.", "start": 2339.59, "duration": 4.84}, {"text": "So under case two, um,", "start": 2344.5, "duration": 3.055}, {"text": "you can be convinced that j of Theta is", "start": 2347.555, "duration": 2.925}, {"text": "just a- i- i- is not the best function to be maximizing.", "start": 2350.48, "duration": 2.985}, {"text": "Because getting a high value of J of", "start": 2353.465, "duration": 2.145}, {"text": "theta doesn't get you a high value for what you actually care about.", "start": 2355.61, "duration": 3.015}, {"text": "And so the problem is with the objective function of the maximization problem.", "start": 2358.625, "duration": 5.145}, {"text": "And maybe we should just find a different function to maximize.", "start": 2363.77, "duration": 3.975}, {"text": "Okay? So, um,", "start": 2367.745, "duration": 5.755}, {"text": "any questions about this? Right, go ahead.", "start": 2373.9, "duration": 7.0}, {"text": "If you want to change the cost function in case two,", "start": 2380.9, "duration": 4.425}, {"text": "you saw it was the right one. [inaudible]", "start": 2385.325, "duration": 9.705}, {"text": "Yeah. Uh, let me come back to that.", "start": 2395.03, "duration": 1.62}, {"text": "Yeah. It's a g- a complicated answer.", "start": 2396.65, "duration": 1.905}, {"text": "Yeah. All right. Actually, let,", "start": 2398.555, "duration": 1.665}, {"text": "let- let's do this first.", "start": 2400.22, "duration": 1.26}, {"text": "Um, so, uh, all right.", "start": 2401.48, "duration": 7.575}, {"text": "For these four bullets,", "start": 2409.055, "duration": 1.84}, {"text": "does it fix the optimization algorithm or does it fix the optimization objective?", "start": 2410.895, "duration": 4.18}, {"text": "First one. Does it fix", "start": 2415.075, "duration": 1.395}, {"text": "the optimization algorithm or does it fix the optimization objective?", "start": 2416.47, "duration": 3.4}, {"text": "Cool. Second one.", "start": 2421.29, "duration": 2.35}, {"text": "Ah, I don't know what's wrong with this thing.", "start": 2423.64, "duration": 2.92}, {"text": "This is so strange. Okay. All right.", "start": 2426.56, "duration": 3.16}, {"text": "Does it fix the optimization algorithm or fix", "start": 2430.12, "duration": 2.74}, {"text": "the optimization objective? Optimization algorithm, right?", "start": 2432.86, "duration": 3.345}, {"text": "So Newton's method still looks at the same cost function J", "start": 2436.205, "duration": 3.225}, {"text": "of Theta but in some cases it just optimizes it much more efficiently.", "start": 2439.43, "duration": 3.63}, {"text": "Um, this is a funny one.", "start": 2443.06, "duration": 2.235}, {"text": "Usually, you fiddle with lambda, um, to,", "start": 2445.295, "duration": 2.78}, {"text": "uh, uh, trade off bias and variance things.", "start": 2448.075, "duration": 2.92}, {"text": "Right. That, that this is one way to change the optimization objective.", "start": 2450.995, "duration": 3.06}, {"text": "Although uh, uh, uh, usually you change", "start": 2454.055, "duration": 1.965}, {"text": "lambda to just bias and variance rather than this.", "start": 2456.02, "duration": 2.7}, {"text": "Right? Uh, and then trying to use an SVM, right?", "start": 2458.72, "duration": 3.84}, {"text": "Would be one way to totally change the optimization objective.", "start": 2462.56, "duration": 2.79}, {"text": "Okay? So, uh, to,", "start": 2465.35, "duration": 2.64}, {"text": "to address the question just now.", "start": 2467.99, "duration": 1.215}, {"text": "Sometimes we find you have the wrong optimization objective,", "start": 2469.205, "duration": 3.03}, {"text": "is that there, there isn't always an obvious thing to do.", "start": 2472.235, "duration": 3.435}, {"text": "Right? Sometimes you have to,", "start": 2475.67, "duration": 1.59}, {"text": "uh, brainstorm a few ideas.", "start": 2477.26, "duration": 1.53}, {"text": "Is that there, there isn't,", "start": 2478.79, "duration": 1.2}, {"text": "uh, um, always one obvious thing to try.", "start": 2479.99, "duration": 2.97}, {"text": "But at least it tells you that,", "start": 2482.96, "duration": 1.38}, {"text": "that category of things of trying out different optimization objectives is what you want.", "start": 2484.34, "duration": 4.365}, {"text": "Right? Um, all right.", "start": 2488.705, "duration": 4.085}, {"text": "So, um, let's go through a more complex example.", "start": 2492.79, "duration": 5.35}, {"text": "They're, they're, you know,", "start": 2498.14, "duration": 1.095}, {"text": "incorporate some of these- wow, I don't know what's wrong.", "start": 2499.235, "duration": 2.445}, {"text": "I sprayed my laptop.", "start": 2501.68, "duration": 1.44}, {"text": "I wonder if my- this is so strange.", "start": 2503.12, "duration": 3.55}, {"text": "Let me see what I can do. Yeah. All right.", "start": 2507.7, "duration": 8.89}, {"text": "Well. Okay. Let's go for a more complex example, uh, that, that,", "start": 2516.59, "duration": 4.29}, {"text": "that will illustrate some of these concepts, uh, that,", "start": 2520.88, "duration": 2.6}, {"text": "that we've been going through and,", "start": 2523.48, "duration": 1.21}, {"text": "and just let you see another example of these things. Um, uh, oh,", "start": 2524.69, "duration": 5.03}, {"text": "and- and I find that,", "start": 2529.72, "duration": 1.565}, {"text": "um, one- one thing I've learned as a teacher,", "start": 2531.285, "duration": 1.875}, {"text": "you know, one of the ways for you to become good at this, right?", "start": 2533.16, "duration": 3.6}, {"text": "Is to go, you know,", "start": 2536.76, "duration": 1.53}, {"text": "work in a good AI group for five years, right?", "start": 2538.29, "duration": 3.0}, {"text": "Because when you work in a good AI group for some several years,", "start": 2541.29, "duration": 3.0}, {"text": "then you have seen, you know, 10 projects,", "start": 2544.29, "duration": 2.37}, {"text": "and that lets you gain that experience.", "start": 2546.66, "duration": 2.55}, {"text": "But it turns out that it takes,", "start": 2549.21, "duration": 1.905}, {"text": "I don't know, depending on what AI group you work on,", "start": 2551.115, "duration": 2.235}, {"text": "it- it takes- if you work on a different project every year,", "start": 2553.35, "duration": 3.195}, {"text": "then in five years that I guess you work on five projects or something.", "start": 2556.545, "duration": 2.61}, {"text": "I- I actually don't know. Or maybe 10 projects or something.", "start": 2559.155, "duration": 2.505}, {"text": "But, er, one of the reasons that,", "start": 2561.66, "duration": 2.16}, {"text": "um, in, uh, the way I try to explain this,", "start": 2563.82, "duration": 2.535}, {"text": "I'm try to go- give specific scenarios with you so that, um, you know,", "start": 2566.355, "duration": 4.83}, {"text": "my Ph.D students and I, we spent- actually,", "start": 2571.185, "duration": 2.145}, {"text": "we spent like many years working with Stanford Autonomous Helicopter,", "start": 2573.33, "duration": 3.525}, {"text": "but I'm trying to distill the key lessons down for", "start": 2576.855, "duration": 2.325}, {"text": "you so that you don't need to work on a project for, you know,", "start": 2579.18, "duration": 2.67}, {"text": "few years to gain this experience but to give you", "start": 2581.85, "duration": 2.625}, {"text": "some approximation to this knowledge in maybe 20 minutes, right?", "start": 2584.475, "duration": 3.795}, {"text": "The 20 minutes won't give you the depth of", "start": 2588.27, "duration": 1.77}, {"text": "three years of experience but we try to summarize", "start": 2590.04, "duration": 2.46}, {"text": "the key lessons so that we can learn", "start": 2592.5, "duration": 2.1}, {"text": "from experience that others took years to develop.", "start": 2594.6, "duration": 3.39}, {"text": "Um, all right. So, uh,", "start": 2597.99, "duration": 3.255}, {"text": "this helicopter actually sits in my office.", "start": 2601.245, "duration": 2.7}, {"text": "Uh, uh, uh but if you go to my office,", "start": 2603.945, "duration": 3.54}, {"text": "uh, uh, and, you know, grab this helicopter,", "start": 2607.485, "duration": 2.415}, {"text": "uh, uh, and- and- and we ask you to write a piece of code to make this fly by itself,", "start": 2609.9, "duration": 4.95}, {"text": "use the learning algorithm to make this fly by itself.", "start": 2614.85, "duration": 2.355}, {"text": "How do you go about doing so?", "start": 2617.205, "duration": 1.86}, {"text": "So it turns out a good way to, um,", "start": 2619.065, "duration": 2.895}, {"text": "make a helicopter fly by itself is to use,", "start": 2621.96, "duration": 2.325}, {"text": "uh, is to do the following.", "start": 2624.285, "duration": 2.13}, {"text": "Uh, step one is build a,", "start": 2626.415, "duration": 2.475}, {"text": "uh, computer simulator for a helicopter.", "start": 2628.89, "duration": 2.595}, {"text": "So, you know, that's actually a simulator, right?", "start": 2631.485, "duration": 2.385}, {"text": "Like a video game simulator of a helicopter.", "start": 2633.87, "duration": 2.76}, {"text": "Um, the advantage of using, you know,", "start": 2636.63, "duration": 2.31}, {"text": "say a video game simulator of a helicopter,", "start": 2638.94, "duration": 1.8}, {"text": "is you could try a lot of things,", "start": 2640.74, "duration": 1.275}, {"text": "crash a lot in simulation,", "start": 2642.015, "duration": 1.845}, {"text": "you know, which is cheap, whereas crashing a helicopter in real life is- is- is-", "start": 2643.86, "duration": 3.81}, {"text": "is slightly dangerous and- and- and also, uh, more expensive.", "start": 2647.67, "duration": 4.035}, {"text": "Um, uh, but so step one build a simulator of a helicopter.", "start": 2651.705, "duration": 4.29}, {"text": "Step two, uh, choose a cost function.", "start": 2655.995, "duration": 2.595}, {"text": "And for today, I'm just using a relatively simple cost function which is squared error.", "start": 2658.59, "duration": 4.38}, {"text": "So you want the helicopter to fly the position x desired,", "start": 2662.97, "duration": 3.824}, {"text": "and your helicopter is there,", "start": 2666.794, "duration": 1.711}, {"text": "you know, wandered off to some other place x.", "start": 2668.505, "duration": 2.115}, {"text": "So let's use a squared error to penalize it, right?", "start": 2670.62, "duration": 3.51}, {"text": "Um, when we talk about reinforcement learning towards the end of this quarter,", "start": 2674.13, "duration": 3.885}, {"text": "we'll- we'll actually go through the same example again by using, uh,", "start": 2678.015, "duration": 3.735}, {"text": "the reinforcement learning terminology,", "start": 2681.75, "duration": 1.725}, {"text": "understand this slightly- this at a slightly deeper level.", "start": 2683.475, "duration": 2.475}, {"text": "And we'll go over this exact same example,", "start": 2685.95, "duration": 1.92}, {"text": "after you learn about reinforcement learning.", "start": 2687.87, "duration": 1.56}, {"text": "But we'll just go over a slightly simplified- very slightly simplified version today.", "start": 2689.43, "duration": 4.065}, {"text": "Um, and so, uh,", "start": 2693.495, "duration": 3.315}, {"text": "run a reinforcement learning algorithm and what the reinforcement learning algorithm does,", "start": 2696.81, "duration": 3.885}, {"text": "is it tries to minimize that cost function J of Theta.", "start": 2700.695, "duration": 4.2}, {"text": "Um, and so, uh, you know,", "start": 2704.895, "duration": 3.015}, {"text": "and so you learn some set of parameters Theta sub through", "start": 2707.91, "duration": 2.565}, {"text": "RL for controlling the helicopter, right?", "start": 2710.475, "duration": 3.885}, {"text": "And we'll talk about reinforcement learning, you know,", "start": 2714.36, "duration": 1.83}, {"text": "the- the- we'll- you- you'll see all this redone with", "start": 2716.19, "duration": 3.06}, {"text": "proper reinforcement learning notation where J is a reward function,", "start": 2719.25, "duration": 3.27}, {"text": "Theta Rs is the control policy and so on.", "start": 2722.52, "duration": 2.04}, {"text": "But don't worry about that for now.", "start": 2724.56, "duration": 1.41}, {"text": "Um, so let's say you do this,", "start": 2725.97, "duration": 3.195}, {"text": "and the resulting controller, right?", "start": 2729.165, "duration": 3.42}, {"text": "The way you fly the helicopter,", "start": 2732.585, "duration": 1.695}, {"text": "it gets much worse performance than a human pilot, you know,", "start": 2734.28, "duration": 3.18}, {"text": "so the helicopter wobbles all over the place", "start": 2737.46, "duration": 2.625}, {"text": "and doesn't quite stay where you are hoping it will.", "start": 2740.085, "duration": 3.345}, {"text": "So what do you do next, right?", "start": 2743.43, "duration": 3.225}, {"text": "Well, here are some options, uh,", "start": 2746.655, "duration": 1.755}, {"text": "corresponding to the three steps above.", "start": 2748.41, "duration": 2.475}, {"text": "You could work on improving your simulator.", "start": 2750.885, "duration": 3.39}, {"text": "Um, it turns out even today,", "start": 2754.275, "duration": 2.13}, {"text": "you know, we- we- we've had helicopters for what?", "start": 2756.405, "duration": 2.865}, {"text": "I don't know- like, uh, uh, I think, uh,", "start": 2759.27, "duration": 2.52}, {"text": "we started having a lot of commercial helicopters around the 1950s.", "start": 2761.79, "duration": 2.31}, {"text": "You see we have been co- conc- helicopter for many decades now.", "start": 2764.1, "duration": 3.63}, {"text": "But airflow around the helicopter is very complicated.", "start": 2767.73, "duration": 3.06}, {"text": "And even today, there are actually some, uh, uh,", "start": 2770.79, "duration": 2.64}, {"text": "details of how air flows around the helicopter.", "start": 2773.43, "duration": 2.745}, {"text": "The- the aerodynamics textbook, you know,", "start": 2776.175, "duration": 2.445}, {"text": "that- that even, um, AeroAstro people, right?", "start": 2778.62, "duration": 2.475}, {"text": "The experts in AeroAstro cannot fully explain.", "start": 2781.095, "duration": 2.295}, {"text": "So helicopters are incredibly complicated.", "start": 2783.39, "duration": 2.475}, {"text": "And there's almost unlimited headroom,", "start": 2785.865, "duration": 2.88}, {"text": "uh, for building better and more accurate simulations of helicopters.", "start": 2788.745, "duration": 3.15}, {"text": "So maybe you wanna do that or maybe you think that cost function is messed up,", "start": 2791.895, "duration": 4.485}, {"text": "you know, maybe a squared error isn't the best metric, right?", "start": 2796.38, "duration": 4.215}, {"text": "Uh, and- and it turns out, um,", "start": 2800.595, "duration": 2.115}, {"text": "the way helicopter- a helicopter has a tail rotor that blows wind to one side, right?", "start": 2802.71, "duration": 4.65}, {"text": "So I guess, uh,", "start": 2807.36, "duration": 1.23}, {"text": "because the- the- the main rotor spins in one direction,", "start": 2808.59, "duration": 2.85}, {"text": "if it only had a main rotor,", "start": 2811.44, "duration": 1.44}, {"text": "then the body will spin in the opposite direction.", "start": 2812.88, "duration": 2.37}, {"text": "Er, an equal and opposite reaction within torque, right?", "start": 2815.25, "duration": 2.49}, {"text": "So the main rotor spins in one direction.", "start": 2817.74, "duration": 2.505}, {"text": "If it only had a main rotor,", "start": 2820.245, "duration": 1.485}, {"text": "the rotor on top,", "start": 2821.73, "duration": 1.195}, {"text": "and it just spun that, then the body of the helicopter would spin the opposite direction.", "start": 2822.925, "duration": 3.265}, {"text": "So that's why you need a tail rotor to blow air down off to one side,", "start": 2826.19, "duration": 4.28}, {"text": "to not make it, um, uh,", "start": 2830.47, "duration": 2.08}, {"text": "uh, spin in the opposite direction.", "start": 2832.55, "duration": 1.5}, {"text": "Uh, but because of that, it turns out", "start": 2834.05, "duration": 1.605}, {"text": "the helicopter's staying in place, it's actually tilted slightly to a side.", "start": 2835.655, "duration": 3.09}, {"text": "Because a tail rotor blows air in one direction.", "start": 2838.745, "duration": 2.7}, {"text": "So it's pushing you off to one side,", "start": 2841.445, "duration": 1.845}, {"text": "so you have to tilt your helicopter in the opposite direction.", "start": 2843.29, "duration": 2.63}, {"text": "So- so the main rotor blows air to one side,", "start": 2845.92, "duration": 2.36}, {"text": "the tail rotor blows air to the other side.", "start": 2848.28, "duration": 1.785}, {"text": "So you actually stay in place, right?", "start": 2850.065, "duration": 1.605}, {"text": "So a helicopter is actually asymmetric.", "start": 2851.67, "duration": 1.62}, {"text": "Lift in birds is not the same.", "start": 2853.29, "duration": 1.455}, {"text": "So- so- so because of this comp- complication,", "start": 2854.745, "duration": 3.645}, {"text": "maybe squared error isn't the best, um, uh,", "start": 2858.39, "duration": 2.49}, {"text": "uh, error because, you know,", "start": 2860.88, "duration": 1.98}, {"text": "your- your orientation- your optimal orientation is actually not zero, right?", "start": 2862.86, "duration": 4.65}, {"text": "Um, so- so- so maybe you should modify the cost function.", "start": 2867.51, "duration": 4.725}, {"text": "Um, or maybe you wanna modify the, um,", "start": 2872.235, "duration": 3.795}, {"text": "reinforcement learning algorithm because you secretly", "start": 2876.03, "duration": 2.31}, {"text": "suspect that your algorithm is not doing", "start": 2878.34, "duration": 2.49}, {"text": "a great job of minimizing that cost function, right?", "start": 2880.83, "duration": 4.785}, {"text": "That it's not actually finding the value of Theta that absolutely minimizes J of Theta.", "start": 2885.615, "duration": 5.01}, {"text": "So it turns out that, um, uh,", "start": 2890.625, "duration": 3.765}, {"text": "each one of these topics can easily be a PhD thesis, right?", "start": 2894.39, "duration": 5.01}, {"text": "You can definitely work for six years on any one of these topics.", "start": 2899.4, "duration": 2.925}, {"text": "Um, and the problem is, uh, uh,", "start": 2902.325, "duration": 3.705}, {"text": "you know, so I- I actually- I actually know someone that wrote their PhD thesis is on, right?", "start": 2906.03, "duration": 5.655}, {"text": "Uh, improving helicopter simulator, right?", "start": 2911.685, "duration": 2.385}, {"text": "Um, uh, but the problem is maybe a helicopter simulator is good enough.", "start": 2914.07, "duration": 4.89}, {"text": "You can spend six years improving", "start": 2918.96, "duration": 2.13}, {"text": "your helicopter simulator but will that actually get you the result?", "start": 2921.09, "duration": 3.72}, {"text": "And you can write- and you can write a PhD thesis,", "start": 2924.81, "duration": 1.62}, {"text": "and you get a PhD doing that maybe.", "start": 2926.43, "duration": 1.62}, {"text": "But if your goal is not", "start": 2928.05, "duration": 1.5}, {"text": "just to write a PhD thesis, it's actually to make a helicopter fly better.", "start": 2929.55, "duration": 3.135}, {"text": "It's actually not- not totally clear, right?", "start": 2932.685, "duration": 2.805}, {"text": "If- if that's the key thing for you to spend time on.", "start": 2935.49, "duration": 3.375}, {"text": "Um, so what I'd like to do is, uh,", "start": 2938.865, "duration": 4.125}, {"text": "describe to you a set of diagnostics that allows you to use this sort of", "start": 2942.99, "duration": 4.71}, {"text": "logical step-by-step reasoning to debug", "start": 2947.7, "duration": 3.78}, {"text": "which of these three things is what you should actually be spending time on, right?", "start": 2951.48, "duration": 4.515}, {"text": "Um, so is it possible for us to come up with a debugging process to logically reason, uh,", "start": 2955.995, "duration": 7.47}, {"text": "so as to select one of these things to work on and- and have conviction,", "start": 2963.465, "duration": 3.6}, {"text": "and then be relatively confident that this is a useful thing to work on, right?", "start": 2967.065, "duration": 4.845}, {"text": "Um, so here's how we're gonna do it.", "start": 2971.91, "duration": 4.59}, {"text": "Um, so just to summarize a scenario, right?", "start": 2976.5, "duration": 4.23}, {"text": "Um, the controller given by Theta RL performs poorly, right?", "start": 2980.73, "duration": 5.205}, {"text": "So, uh, this is how I would reason through a learning algorithm, right?", "start": 2985.935, "duration": 4.83}, {"text": "So suppose, uh, suppose all of these things were true,", "start": 2990.765, "duration": 4.725}, {"text": "um, suppose that- okay,", "start": 2995.49, "duration": 2.49}, {"text": "corresponding to the three steps in the previous slide,", "start": 2997.98, "duration": 2.175}, {"text": "suppose the helicopter simulator was accurate and suppose,", "start": 3000.155, "duration": 4.065}, {"text": "um, uh, you know, the learning algorithm,", "start": 3004.22, "duration": 2.94}, {"text": "uh, correctly, you know,", "start": 3007.16, "duration": 2.58}, {"text": "minimizes the cost function and suppose J of Theta is a good cost function, right?", "start": 3009.74, "duration": 5.67}, {"text": "If- if all of these things were true,", "start": 3015.41, "duration": 2.01}, {"text": "then the learned parameters should fly well on the actual helicopter, right?", "start": 3017.42, "duration": 5.52}, {"text": "Um, but it doesn't fly well on a helicopter,", "start": 3022.94, "duration": 3.165}, {"text": "so one of these three things is false.", "start": 3026.105, "duration": 3.645}, {"text": "And our job is to figure out,", "start": 3029.75, "duration": 2.19}, {"text": "is- is to identify at least one of these three statements: one,", "start": 3031.94, "duration": 4.02}, {"text": "two or three that's false because that- that- that lets you", "start": 3035.96, "duration": 3.15}, {"text": "sink your teeth into something that to- to- to work on, right?", "start": 3039.11, "duration": 3.685}, {"text": "Um, and I think, uh, uh, um,", "start": 3042.795, "duration": 2.35}, {"text": "to make an analogy to more conventional software debugging,", "start": 3045.145, "duration": 3.825}, {"text": "if a big complicated program,", "start": 3048.97, "duration": 2.145}, {"text": "and for some reason,", "start": 3051.115, "duration": 1.155}, {"text": "your program crashes, you're like the core down to whatever, um,", "start": 3052.27, "duration": 3.645}, {"text": "if you can isolate this big complicated program into one component that crashes,", "start": 3055.915, "duration": 6.285}, {"text": "then you can focus your attention on that component that you", "start": 3062.2, "duration": 3.39}, {"text": "know crashes for some reason and try to find the bug there, right?", "start": 3065.59, "duration": 3.735}, {"text": "And so instead of trying to look over a huge code base,", "start": 3069.325, "duration": 2.805}, {"text": "if you could do binary search or try to isolate", "start": 3072.13, "duration": 2.31}, {"text": "the problem in a smaller part of your code base,", "start": 3074.44, "duration": 2.865}, {"text": "then you can focus your debugging efforts on that part of your code base,", "start": 3077.305, "duration": 3.855}, {"text": "try to figure why it crashes,", "start": 3081.16, "duration": 1.41}, {"text": "and then fix that first.", "start": 3082.57, "duration": 1.245}, {"text": "And after you fix that, it might still crash,", "start": 3083.815, "duration": 2.145}, {"text": "then there may be a second problem to work on but at least you know that, um,", "start": 3085.96, "duration": 4.095}, {"text": "trying to fix the first bug seems like, uh,", "start": 3090.055, "duration": 1.86}, {"text": "seems with a worthwhile thing to do, okay?", "start": 3091.915, "duration": 3.665}, {"text": "So what we're gonna do is, um, uh,", "start": 3095.58, "duration": 3.89}, {"text": "come up with a oh, sorry, that's gradient descent, come up with a set of diagnostics", "start": 3099.47, "duration": 3.81}, {"text": "to isolate the problem to one of these three components, okay?", "start": 3103.28, "duration": 4.87}, {"text": "So the first step is,", "start": 3108.15, "duration": 2.245}, {"text": "uh, let's look at,", "start": 3110.395, "duration": 1.98}, {"text": "um, how well the algorithm flies in simulation, right?", "start": 3112.375, "duration": 4.725}, {"text": "So what I said just now was, uh,", "start": 3117.1, "duration": 1.53}, {"text": "you ran the algorithm and it resulted in", "start": 3118.63, "duration": 3.175}, {"text": "a set of parameters that doesn't do well on your actual helicopter.", "start": 3121.805, "duration": 3.63}, {"text": "So the first thing I will do is just check how well", "start": 3125.435, "duration": 2.595}, {"text": "does this thing even do in simulation, right?", "start": 3128.03, "duration": 2.865}, {"text": "And, uh, uh, there are two possible cases.", "start": 3130.895, "duration": 3.78}, {"text": "Um, if it flies well in simulation but doesn't do well in real life,", "start": 3134.675, "duration": 4.845}, {"text": "then it means something's wrong with the simulator, right?", "start": 3139.52, "duration": 3.72}, {"text": "It- it means it's actually work- working on the simulator because, you know,", "start": 3143.24, "duration": 3.795}, {"text": "if it's already working well in the simulator,", "start": 3147.035, "duration": 2.29}, {"text": "I mean what else could you expect to", "start": 3149.325, "duration": 2.345}, {"text": "learn the reinforcement learning algorithms to do, right?", "start": 3151.67, "duration": 2.31}, {"text": "You know, you told the reinforcement learning algorithm to go and fly", "start": 3153.98, "duration": 2.67}, {"text": "well in the simulator because this is just training simulation.", "start": 3156.65, "duration": 2.91}, {"text": "It's already doing well in the simulator,", "start": 3159.56, "duration": 2.175}, {"text": "so there's not much to improve on there, right?", "start": 3161.735, "duration": 2.16}, {"text": "At least, it's hard to improve on that.", "start": 3163.895, "duration": 1.92}, {"text": "Uh, but- but- but if- if- if you found a learning", "start": 3165.815, "duration": 3.045}, {"text": "algori- if your learning algorithm does well in the simulator but not in real life,", "start": 3168.86, "duration": 3.255}, {"text": "then this means that the simulator,", "start": 3172.115, "duration": 2.355}, {"text": "um, isn't matching real life well.", "start": 3174.47, "duration": 2.91}, {"text": "And so dish- that- that's strong evidence.", "start": 3177.38, "duration": 2.64}, {"text": "That's strong grounds for you to spend some time to improve your simulator. Yeah?", "start": 3180.02, "duration": 4.62}, {"text": "[inaudible].", "start": 3184.64, "duration": 6.21}, {"text": "Oh, yeah. Uh, right.", "start": 3190.85, "duration": 1.74}, {"text": "So to just repeat for", "start": 3192.59, "duration": 1.41}, {"text": "the camera, is it ever the case that it flies bad in the simulator but well in real life?", "start": 3194.0, "duration": 4.679}, {"text": "I wish that happened.", "start": 3198.679, "duration": 1.591}, {"text": "[LAUGHTER] You know, I actually, um, very rarely,", "start": 3200.27, "duration": 4.365}, {"text": "I- I think, uh,", "start": 3204.635, "duration": 1.215}, {"text": "if that happens I will,", "start": 3205.85, "duration": 1.59}, {"text": "I will still work on improving the simulator.", "start": 3207.44, "duration": 2.07}, {"text": "Um, uh, so there,", "start": 3209.51, "duration": 1.845}, {"text": "there is one scenario where that happens,", "start": 3211.355, "duration": 1.815}, {"text": "it turns out that, uh, uh,", "start": 3213.17, "duration": 2.08}, {"text": "when we train this helicopter in the simulator or really, any robot in the simulator,", "start": 3215.47, "duration": 5.755}, {"text": "we often add a lot of noise to he simulator because one lesson we've learned is", "start": 3221.225, "duration": 3.555}, {"text": "that if your simulators is noisy, because simulators are always wrong, right?", "start": 3224.78, "duration": 3.54}, {"text": "Any- any digital simulation is only an approximation in the real world.", "start": 3228.32, "duration": 2.985}, {"text": "So it turns out we have a lot of noise in all of our simulators,", "start": 3231.305, "duration": 2.865}, {"text": "because we think if that the learning algorithm is", "start": 3234.17, "duration": 2.55}, {"text": "robust to all this noise you've thrown at it in simulation.", "start": 3236.72, "duration": 3.15}, {"text": "Then, whatever the noise the real world throws at it,", "start": 3239.87, "duration": 2.595}, {"text": "it has a bigger chance of being robust too, as well.", "start": 3242.465, "duration": 2.775}, {"text": "Um, uh, and so we tend to throw a lot of noise into, into simulators.", "start": 3245.24, "duration": 4.68}, {"text": "And so one case where that does happen is when we find we threw too much noise", "start": 3249.92, "duration": 3.87}, {"text": "added in simulation and tha- that might be a sign we should dial back the noise a bit.", "start": 3253.79, "duration": 4.08}, {"text": "Um, right, cool.", "start": 3257.87, "duration": 2.625}, {"text": "Uh, so, um, yeah, right.", "start": 3260.495, "duration": 5.205}, {"text": "So this first diagnostic tells you should work on improving the simulation.", "start": 3265.7, "duration": 3.84}, {"text": "But just, I think there's a big mismatch between", "start": 3269.54, "duration": 3.075}, {"text": "simulation performance and real world performance.", "start": 3272.615, "duration": 2.745}, {"text": "That's a good sign that,", "start": 3275.36, "duration": 1.965}, {"text": "you know, that you should improve the simulation.", "start": 3277.325, "duration": 2.865}, {"text": "Second, um, this is actually very similar to the diagnostic we use on", "start": 3280.19, "duration": 5.34}, {"text": "the Spam, you know, Bayesian logistic regression and SVM example.", "start": 3285.53, "duration": 6.72}, {"text": "So what we're gonna do is, um,", "start": 3292.25, "duration": 3.135}, {"text": "we're going to measure this equation.", "start": 3295.385, "duration": 3.81}, {"text": "And this is, this again, this is", "start": 3299.195, "duration": 1.725}, {"text": "very similar to our previous equation which is,", "start": 3300.92, "duration": 4.065}, {"text": "take the cost function, similar as the previous example.", "start": 3304.985, "duration": 3.525}, {"text": "Take the cost function J that reinforcement learning is,", "start": 3308.51, "duration": 4.515}, {"text": "uh, totally minimized, right?", "start": 3313.025, "duration": 1.77}, {"text": "That's J and J of theta was a squared error, right?", "start": 3314.795, "duration": 2.325}, {"text": "So take the cost function that, uh, uh,", "start": 3317.12, "duration": 2.685}, {"text": "reinforcement learning was told to minimize and see if", "start": 3319.805, "duration": 4.155}, {"text": "the human achieves better squared error than the reinforcement learning algorithm.", "start": 3323.96, "duration": 6.24}, {"text": "We just see, you know supervise better.", "start": 3330.2, "duration": 2.925}, {"text": "So let's measure the human performance on this squared error cost function um,", "start": 3333.125, "duration": 5.67}, {"text": "and see which one does better.", "start": 3338.795, "duration": 1.89}, {"text": "So there are two cases that equation will be either less than", "start": 3340.685, "duration": 4.29}, {"text": "or it will be greater than or equal to, right, so less, or greater or equal to.", "start": 3344.975, "duration": 4.305}, {"text": "So case one, is um,", "start": 3349.28, "duration": 1.98}, {"text": "say to human is less than", "start": 3351.26, "duration": 3.9}, {"text": "excuse me, J of theta human is less than J of theta RL. That would be this case.", "start": 3355.16, "duration": 4.17}, {"text": "Then, that tells you that the problem", "start": 3359.33, "duration": 2.7}, {"text": "is with the reinforcement learning algorithm, right?", "start": 3362.03, "duration": 2.505}, {"text": "That somehow the human achieves a lower squared error uh, and so, uh,", "start": 3364.535, "duration": 6.03}, {"text": "the learning algorithm is not finding the best possible squared error, that is", "start": 3370.565, "duration": 4.5}, {"text": "some other controller as evidenced by whatever the human is", "start": 3375.065, "duration": 3.255}, {"text": "doing that actually achieves a lower cost function, right?", "start": 3378.32, "duration": 4.215}, {"text": "So in this case,", "start": 3382.535, "duration": 1.89}, {"text": "um, we think the learning algorithm or,", "start": 3384.425, "duration": 3.48}, {"text": "or reinforcement learning algorithm is not doing a good job", "start": 3387.905, "duration": 2.895}, {"text": "minimizing that and we'll work on the reinforcement learning algorithm.", "start": 3390.8, "duration": 3.85}, {"text": "The other case would be if the sign of the inequality is the other way around.", "start": 3394.75, "duration": 4.975}, {"text": "Right? Now in this case,", "start": 3399.725, "duration": 2.835}, {"text": "um, you can infer that the problem is in the cost function.", "start": 3402.56, "duration": 3.84}, {"text": "Because what happens here is,", "start": 3406.4, "duration": 3.105}, {"text": "um, the human is flying better than the reinforcement learning algorithm.", "start": 3409.505, "duration": 5.295}, {"text": "But the human is achieving what looks like a worse cost than", "start": 3414.8, "duration": 4.02}, {"text": "the reinforcement learning algorithm.", "start": 3418.82, "duration": 2.73}, {"text": "So what this tells you is that minimizing J of theta does not correspond to flying well.", "start": 3421.55, "duration": 6.93}, {"text": "Right? Your learning algorithm achieves a better value for J of theta,", "start": 3428.48, "duration": 3.93}, {"text": "you know, J of theta RL is actually smaller than what the human is doing.", "start": 3432.41, "duration": 4.125}, {"text": "So the reinforcement learning algorithm as far as it knows is doing", "start": 3436.535, "duration": 3.525}, {"text": "a great job cause it's finding a value of theta where J of theta is really really small.", "start": 3440.06, "duration": 4.8}, {"text": "But in this last case, um,", "start": 3444.86, "duration": 2.655}, {"text": "you know that finding such a small value of J of theta doesn't correspond to flying", "start": 3447.515, "duration": 7.245}, {"text": "well because a human doesn't achieve such a good value in the cost function but", "start": 3454.76, "duration": 3.33}, {"text": "the helicopter actually just looks better, was flying in a more satisfactory way.", "start": 3458.09, "duration": 4.515}, {"text": "And that tells you that this squared error cost function", "start": 3462.605, "duration": 2.91}, {"text": "is not the right cost function for,", "start": 3465.515, "duration": 2.97}, {"text": "for, for what flying accurately remains, right?", "start": 3468.485, "duration": 3.135}, {"text": "And so um, through this set of diagnostics,", "start": 3471.62, "duration": 4.17}, {"text": "um, uh, you could decide which one of these three things.", "start": 3475.79, "duration": 4.94}, {"text": "Uh, improving the simulator,", "start": 3480.73, "duration": 2.46}, {"text": "improving the RL algorithm,", "start": 3483.19, "duration": 1.5}, {"text": "reinforcement learning algorithm or improving", "start": 3484.69, "duration": 2.325}, {"text": "the cost function is the thing you should work on.", "start": 3487.015, "duration": 3.725}, {"text": "And what happens in- in", "start": 3490.74, "duration": 3.2}, {"text": "this particular project and what often happens in machine learning applications is,", "start": 3493.94, "duration": 3.99}, {"text": "you run this set of diagnostics and this", "start": 3497.93, "duration": 2.01}, {"text": "actually happened when we were working on this helicopter.", "start": 3499.94, "duration": 2.175}, {"text": "We ran this set of diagnostics and then one week we were saying,", "start": 3502.115, "duration": 3.51}, {"text": "\"Yep simulator's got a problem, let's work on that.\"", "start": 3505.625, "duration": 2.55}, {"text": "And then we'd improve the simulator,", "start": 3508.175, "duration": 1.455}, {"text": "improve the simulator and after", "start": 3509.63, "duration": 1.74}, {"text": "a couple of weeks of work we will run these diagnostics and say,", "start": 3511.37, "duration": 2.265}, {"text": "\"Oh, looks like the simulator is not good enough.\"", "start": 3513.635, "duration": 1.83}, {"text": "And maybe there's a problem with the RL algorithm,", "start": 3515.465, "duration": 2.25}, {"text": "then we'll work on that, work on that and improve that.", "start": 3517.715, "duration": 2.055}, {"text": "And after that, after awhile we'll say, \"Oh, they'll say that's", "start": 3519.77, "duration": 2.34}, {"text": "also good enough and the problem is in the cost function.\"", "start": 3522.11, "duration": 2.67}, {"text": "And sometimes the, the location of", "start": 3524.78, "duration": 2.67}, {"text": "the most acute problems shifts right after you've cleared out one set of problems.", "start": 3527.45, "duration": 4.215}, {"text": "It might be the case that now the bottleneck is the simulator, right?", "start": 3531.665, "duration": 5.1}, {"text": "And so, um, I often use this, uh,", "start": 3536.765, "duration": 3.36}, {"text": "workflow to constantly drive prioritization for what to work on next, right?", "start": 3540.125, "duration": 6.345}, {"text": "And, and to answer your question just now about how do you find the new cost function?", "start": 3546.47, "duration": 4.125}, {"text": "It turns out finding a new cost function is actually not that easy.", "start": 3550.595, "duration": 3.345}, {"text": "Uh, so actually one, one of my former PhD students Adam Coates um,", "start": 3553.94, "duration": 4.38}, {"text": "through this type of process realized that", "start": 3558.32, "duration": 2.625}, {"text": "finding a good cost function is actually really difficult.", "start": 3560.945, "duration": 2.865}, {"text": "Uh, because if you want a helicopter to fly and maneuver,", "start": 3563.81, "duration": 2.76}, {"text": "you know, like fly at speed and then make a bank turn, right?", "start": 3566.57, "duration": 3.27}, {"text": "Like how do you mathematically define what is an accurate bank turn?", "start": 3569.84, "duration": 3.12}, {"text": "It's actually really difficult to write down an equation to", "start": 3572.96, "duration": 2.91}, {"text": "specify what is a good way of, I will fly in that and do a turn.", "start": 3575.87, "duration": 3.105}, {"text": "Or is this, how do you specify what is a good turn?", "start": 3578.975, "duration": 2.865}, {"text": "So um, he wound up writing a research paper,", "start": 3581.84, "duration": 3.66}, {"text": "uh, one of the best application paper, it won at ICML.", "start": 3585.5, "duration": 3.3}, {"text": "Uh-uh on, on how to define a good cost function,", "start": 3588.8, "duration": 2.715}, {"text": "it's actually pretty complicated,", "start": 3591.515, "duration": 1.605}, {"text": "but the reason he did it and it was a good use of his time was running", "start": 3593.12, "duration": 4.41}, {"text": "diagnostics like these which gave us", "start": 3597.53, "duration": 1.86}, {"text": "confidence that this was actually a worthwhile problem uh,", "start": 3599.39, "duration": 3.09}, {"text": "and the, that resulted in,", "start": 3602.48, "duration": 1.635}, {"text": "you know making real progress in optimization, right.", "start": 3604.115, "duration": 4.095}, {"text": "Um, any questions about this? All right, cool.", "start": 3608.21, "duration": 9.645}, {"text": "Actually, I think I- all right, anyway,", "start": 3617.855, "duration": 2.535}, {"text": "all right, fun helicopter videos, I always want to show this, but it's fine.", "start": 3620.39, "duration": 2.46}, {"text": "And you guys saw this earlier. All right, so,", "start": 3622.85, "duration": 5.34}, {"text": "um, only one time,", "start": 3628.19, "duration": 6.7}, {"text": "all right, let's go through this.", "start": 3637.21, "duration": 2.65}, {"text": "So, um, uh, in addition to,", "start": 3639.86, "duration": 6.18}, {"text": "um, these specific diagnoses of bias", "start": 3646.04, "duration": 3.57}, {"text": "versus variance and optimization algorithms versus optimization objective.", "start": 3649.61, "duration": 4.11}, {"text": "Um, oh sorry- and when we do RL,", "start": 3653.72, "duration": 2.685}, {"text": "I wanted to just go through that example one more time,", "start": 3656.405, "duration": 2.205}, {"text": "so you see everything you just saw again,", "start": 3658.61, "duration": 1.98}, {"text": "after you learned about reinforcement learning, they tend to squeeze up.", "start": 3660.59, "duration": 3.465}, {"text": "Okay. Now, in addition to these type of diagnostics,", "start": 3664.055, "duration": 5.265}, {"text": "um, uh, how to debug learning algorithms, um,", "start": 3669.32, "duration": 3.48}, {"text": "there's one other set of tools you'll find very useful,", "start": 3672.8, "duration": 2.79}, {"text": "which is, uh, error analysis tools, uh,", "start": 3675.59, "duration": 2.52}, {"text": "which lets you figure out,", "start": 3678.11, "duration": 1.2}, {"text": "which is another way for you to figure out what's working,", "start": 3679.31, "duration": 2.61}, {"text": "what's not working, or really what's not working in the learning algorithm.", "start": 3681.92, "duration": 2.97}, {"text": "[NOISE] So let's let's go through a motivating example.", "start": 3684.89, "duration": 2.745}, {"text": "Um, so let's say you're building a,", "start": 3687.635, "duration": 3.945}, {"text": "um, uh, you know, uh, like a security system,", "start": 3691.58, "duration": 3.27}, {"text": "so when someone walks in front of a door,", "start": 3694.85, "duration": 1.92}, {"text": "you unlock the door knob based on whether or not, you know,", "start": 3696.77, "duration": 2.4}, {"text": "that person is authorized to enter right that, that place.", "start": 3699.17, "duration": 3.36}, {"text": "Um, and so let's say that, uh, uh,", "start": 3702.53, "duration": 5.22}, {"text": "so there are a lot of machine learning applications where", "start": 3707.75, "duration": 2.355}, {"text": "it's not just one learning algorithm, right?", "start": 3710.105, "duration": 2.865}, {"text": "But instead you have a pipeline,", "start": 3712.97, "duration": 1.32}, {"text": "you string together many different steps.", "start": 3714.29, "duration": 1.89}, {"text": "So how do you actually build a face recognition algorithm?", "start": 3716.18, "duration": 3.435}, {"text": "To decide if someone approaching your front door", "start": 3719.615, "duration": 2.115}, {"text": "is authorized to unlock the door, all right.", "start": 3721.73, "duration": 2.22}, {"text": "Well, here's something you could do which is, uh,", "start": 3723.95, "duration": 2.085}, {"text": "you start with a camera image like this, and then,", "start": 3726.035, "duration": 2.955}, {"text": "um, you could do preprocessing to remove the background.", "start": 3728.99, "duration": 3.435}, {"text": "So all that co- co- complicated color in the background, let's get rid of that.", "start": 3732.425, "duration": 3.45}, {"text": "And it turns out that, um,", "start": 3735.875, "duration": 1.35}, {"text": "when you have a camera against a static background, right?", "start": 3737.225, "duration": 3.78}, {"text": "You could actually do this, you know,", "start": 3741.005, "duration": 2.04}, {"text": "with a little bit of noise relatively easily", "start": 3743.045, "duration": 1.935}, {"text": "because if you have a fixed camera that's just like mounted,", "start": 3744.98, "duration": 2.655}, {"text": "you know, on your door frame,", "start": 3747.635, "duration": 1.62}, {"text": "it always sees the same background,", "start": 3749.255, "duration": 2.505}, {"text": "and so you can just look at what pixels have changed and- and just", "start": 3751.76, "duration": 3.45}, {"text": "keep the pixels that have changed compared to- I mean re- because,", "start": 3755.21, "duration": 3.45}, {"text": "you know, this camera always sees that gray background and that, um,", "start": 3758.66, "duration": 4.38}, {"text": "brown bench in the back,", "start": 3763.04, "duration": 1.17}, {"text": "and so you just look at what pixels have changed a lot and,", "start": 3764.21, "duration": 2.175}, {"text": "and this background doesn't really move, right.", "start": 3766.385, "duration": 1.695}, {"text": "So this is- this- this is- this is actually feasible by", "start": 3768.08, "duration": 3.21}, {"text": "just looking at what pixels have changed and", "start": 3771.29, "duration": 1.47}, {"text": "keeping pixels that have changed relative to that.", "start": 3772.76, "duration": 2.175}, {"text": "Um, and so, after getting to the background,", "start": 3774.935, "duration": 3.98}, {"text": "you could run the face detection algorithm, uh,", "start": 3778.915, "duration": 2.505}, {"text": "and then, uh, after detecting the face, it turns out that,", "start": 3781.42, "duration": 3.72}, {"text": "uh, actually, you know,", "start": 3785.14, "duration": 1.795}, {"text": "I've actually worked with a bunch of face detection,", "start": 3786.935, "duration": 1.605}, {"text": "worked with a bunch of face- face recognition systems.", "start": 3788.54, "duration": 1.89}, {"text": "It turns out that, um,", "start": 3790.43, "duration": 1.485}, {"text": "for some of the leading face recognition systems,", "start": 3791.915, "duration": 2.895}, {"text": "so- depends on details, but some of them.", "start": 3794.81, "duration": 1.86}, {"text": "Uh, it turns out that, um,", "start": 3796.67, "duration": 1.725}, {"text": "the appearance of the eyes is a very important cue for recognizing people,", "start": 3798.395, "duration": 4.38}, {"text": "that's why, if you cover your eyes you actually have a much harder time recognizing people,", "start": 3802.775, "duration": 2.955}, {"text": "as eyes are very distinct through people.", "start": 3805.73, "duration": 1.755}, {"text": "Just segment out the eyes,", "start": 3807.485, "duration": 1.755}, {"text": "um, segment out the nose,", "start": 3809.24, "duration": 2.76}, {"text": "and the other thing you- segment out the mouth.", "start": 3812.0, "duration": 2.88}, {"text": "[LAUGHTER] It's Halloween.", "start": 3814.88, "duration": 2.79}, {"text": "[LAUGHTER] All right.", "start": 3817.67, "duration": 3.48}, {"text": "And then- and then feed these features into some other algorithms,", "start": 3821.15, "duration": 3.03}, {"text": "say logistic regression, that then, you know,", "start": 3824.18, "duration": 2.295}, {"text": "finally outputs a label that says,", "start": 3826.475, "duration": 2.4}, {"text": "is this the person, right?", "start": 3828.875, "duration": 1.86}, {"text": "That- that- that, you know- you know,", "start": 3830.735, "duration": 1.395}, {"text": "you're authorized to open the door for.", "start": 3832.13, "duration": 2.37}, {"text": "Um, so it- so in many learning algorithms,", "start": 3834.5, "duration": 5.1}, {"text": "you have a complicated pipeline like this of different components that,", "start": 3839.6, "duration": 3.765}, {"text": "that have to be strung together,", "start": 3843.365, "duration": 1.89}, {"text": "and, uh, you know,", "start": 3845.255, "duration": 1.755}, {"text": "if you read the newspaper articles about-", "start": 3847.01, "duration": 2.835}, {"text": "or if you read research papers in machine learning, often,", "start": 3849.845, "duration": 3.66}, {"text": "uh, uh, the, the research papers will say, oh,", "start": 3853.505, "duration": 3.465}, {"text": "we built a machine translation system,", "start": 3856.97, "duration": 1.68}, {"text": "we've trained a gazillion, you know,", "start": 3858.65, "duration": 2.13}, {"text": "of sentences found on the Internet and that's great and a pure end-to-end system,", "start": 3860.78, "duration": 3.87}, {"text": "so that's like one learning algorithm that sucks in an input,", "start": 3864.65, "duration": 3.03}, {"text": "by sucking an English sentence and spit out the French sentence or something, right?", "start": 3867.68, "duration": 3.59}, {"text": "So that's, that's like one learning algorithm.", "start": 3871.27, "duration": 2.665}, {"text": "It turns out that for a lot of practical applications,", "start": 3873.935, "duration": 2.76}, {"text": "if you don't have a gazillion examples, uh,", "start": 3876.695, "duration": 2.37}, {"text": "you end up designing much more complex machine learning pipelines like this,", "start": 3879.065, "duration": 4.665}, {"text": "where it's not just one monolithic learning algorithm,", "start": 3883.73, "duration": 3.44}, {"text": "but instead there are many different smaller components.", "start": 3887.17, "duration": 2.52}, {"text": "Um, and I think in,", "start": 3889.69, "duration": 2.415}, {"text": "in- uh, uh, I think that, you know,", "start": 3892.105, "duration": 2.085}, {"text": "the, the, the, the, um,", "start": 3894.19, "duration": 2.31}, {"text": "I think that, uh,", "start": 3896.5, "duration": 1.52}, {"text": "having a lot of data's great, all right?", "start": 3898.02, "duration": 2.09}, {"text": "I love having more data,", "start": 3900.11, "duration": 1.2}, {"text": "but big data has also been a little bit over-hyped,", "start": 3901.31, "duration": 2.325}, {"text": "uh, and to model things you could do with small data sets as well.", "start": 3903.635, "duration": 3.51}, {"text": "And in the teams [NOISE] I've worked with,", "start": 3907.145, "duration": 2.85}, {"text": "we find that if, if,", "start": 3909.995, "duration": 1.65}, {"text": "if you have a relatively small dataset,", "start": 3911.645, "duration": 1.995}, {"text": "often you can still get great results.", "start": 3913.64, "duration": 1.71}, {"text": "You know, my teams often get great results at 100 images,", "start": 3915.35, "duration": 3.645}, {"text": "100 training examples or something.", "start": 3918.995, "duration": 1.515}, {"text": "But when you have small data,", "start": 3920.51, "duration": 1.83}, {"text": "it often takes more, uh,", "start": 3922.34, "duration": 1.665}, {"text": "insightful design of machine learning pipelines like this, right?", "start": 3924.005, "duration": 3.99}, {"text": "Um, now, [NOISE] when you have a machine learning pipeline like this, uh,", "start": 3927.995, "duration": 5.31}, {"text": "the things you want to do- what you want to do is,", "start": 3933.305, "duration": 3.285}, {"text": "uh, so, so you build a pipeline like this and it doesn't work, right?", "start": 3936.59, "duration": 3.99}, {"text": "And there's this common workflow.", "start": 3940.58, "duration": 1.155}, {"text": "You build a pipe, you build something,", "start": 3941.735, "duration": 1.375}, {"text": "it doesn't work, so you want to debug it.", "start": 3943.11, "duration": 2.545}, {"text": "So in order to decide which part of the pipeline to work on, um,", "start": 3945.655, "duration": 5.58}, {"text": "it's very useful if you can look at your- the error of your system and try to attribute", "start": 3951.235, "duration": 5.655}, {"text": "the error to the different components so that you", "start": 3956.89, "duration": 3.46}, {"text": "can decide which component to work on next, right?", "start": 3960.35, "duration": 3.72}, {"text": "And, and, there's actually a- I'll tell you a true story, you know,", "start": 3964.07, "duration": 2.91}, {"text": "remember preprocess background removal step, right?", "start": 3966.98, "duration": 2.91}, {"text": "Since you're getting rid of the background,", "start": 3969.89, "duration": 1.875}, {"text": "um, it turns out that, uh,", "start": 3971.765, "duration": 2.58}, {"text": "there are a lot of details of how to do background removal,", "start": 3974.345, "duration": 3.164}, {"text": "uh, for example, um,", "start": 3977.509, "duration": 1.771}, {"text": "the simple way to do it is to look at every pixel and", "start": 3979.28, "duration": 2.82}, {"text": "just see which pixels have changed, uh,", "start": 3982.1, "duration": 3.225}, {"text": "but it turns out that if there's a tree in the background that, you know,", "start": 3985.325, "duration": 3.375}, {"text": "waves a little bit because the wind moves", "start": 3988.7, "duration": 2.28}, {"text": "the tree and blows the leaves and branches around a little bit,", "start": 3990.98, "duration": 2.835}, {"text": "then sometimes the background pixels do change a little bit.", "start": 3993.815, "duration": 3.315}, {"text": "And so they're actually really complicated background removal algorithms,", "start": 3997.13, "duration": 3.27}, {"text": "they try to model basically", "start": 4000.4, "duration": 1.89}, {"text": "the trees and the bushes moving around a little bit in the background,", "start": 4002.29, "duration": 2.73}, {"text": "so you know, that even though the pixels of the tree", "start": 4005.02, "duration": 2.55}, {"text": "moves around is part of the background,  you just get rid of it.", "start": 4007.57, "duration": 2.64}, {"text": "So background removal, there's simple versions where you just look", "start": 4010.21, "duration": 3.3}, {"text": "at each pixel and see how much it's changed and there's incredibly complicated versions.", "start": 4013.51, "duration": 3.675}, {"text": "Um, so I actually know someone, uh, that, uh,", "start": 4017.185, "duration": 5.655}, {"text": "uh, was trying to work on a problem like this and", "start": 4022.84, "duration": 2.97}, {"text": "they decided to improve their background removal algorithm.", "start": 4025.81, "duration": 3.255}, {"text": "Uh, and they actually, er,", "start": 4029.065, "duration": 1.47}, {"text": "this real person actually literally wrote a PhD thesis on background removal.", "start": 4030.535, "duration": 3.675}, {"text": "Uh, and so I'm glad he got a PhD,", "start": 4034.21, "duration": 2.67}, {"text": "but it turn- but,", "start": 4036.88, "duration": 1.905}, {"text": "you know, when I look at the problem he was actually trying to solve,", "start": 4038.785, "duration": 2.82}, {"text": "I don't think it actually moved the needle, right?", "start": 4041.605, "duration": 2.37}, {"text": "So- so, um.", "start": 4043.975, "duration": 2.055}, {"text": "Uh, this is one of the nice things about academia,", "start": 4046.03, "duration": 2.61}, {"text": "right, guys, so long as, you know,", "start": 4048.64, "duration": 1.425}, {"text": "you can- you can still publish a paper.", "start": 4050.065, "duration": 1.605}, {"text": "[LAUGHTER]", "start": 4051.67, "duration": 2.34}, {"text": "And- and- and that was technically innovative.", "start": 4054.01, "duration": 2.64}, {"text": "It was actually a very good technical work.", "start": 4056.65, "duration": 1.47}, {"text": "But- but- but- but if- so if your goal is to publish a paper, great, do that, uh,", "start": 4058.12, "duration": 4.63}, {"text": "but then if your goal is to build a better face recognition system,", "start": 4062.75, "duration": 2.735}, {"text": "then I would carefully ask which components should", "start": 4065.485, "duration": 2.355}, {"text": "you actually spend your time to work on, all right?", "start": 4067.84, "duration": 2.58}, {"text": "Um, so here's what you can do with error analysis,", "start": 4070.42, "duration": 5.28}, {"text": "which is, say your overall system has 85% accuracy.", "start": 4075.7, "duration": 5.385}, {"text": "Here's what I would do. I would go in and in your,", "start": 4081.085, "duration": 4.995}, {"text": "uh, dev set, in your development set,", "start": 4086.08, "duration": 1.83}, {"text": "the whole of the cross validation set, right,", "start": 4087.91, "duration": 1.8}, {"text": "uh, go in and for every one of your examples in the dev set,", "start": 4089.71, "duration": 5.4}, {"text": "I would plug into the ground truth for the background.", "start": 4095.11, "duration": 3.495}, {"text": "Meaning that, uh, rather than using a-some, you know,", "start": 4098.605, "duration": 4.245}, {"text": "approximate heuristic algorithm for", "start": 4102.85, "duration": 2.16}, {"text": "roughly cleaning out the background which may or may not work out well,", "start": 4105.01, "duration": 3.12}, {"text": "I would just use Photoshop.", "start": 4108.13, "duration": 1.47}, {"text": "And for every example in the dev set,", "start": 4109.6, "duration": 1.815}, {"text": "I would give it the perfect background removal, right?", "start": 4111.415, "duration": 3.165}, {"text": "So imagine if instead of some noisy algorithm trying to remove the background,", "start": 4114.58, "duration": 4.44}, {"text": "this step of the algorithm was- just had perfect performance, right?", "start": 4119.02, "duration": 4.26}, {"text": "And then you can give it perfect performance on your dev set, on your test set,", "start": 4123.28, "duration": 3.12}, {"text": "just by using Photoshop to just tell it this is a background,", "start": 4126.4, "duration": 2.79}, {"text": "this is a foreground, right?", "start": 4129.19, "duration": 1.875}, {"text": "And let's say that when you plug in this perfect background removal,", "start": 4131.065, "duration": 4.44}, {"text": "the accuracy improves to 85.1%.", "start": 4135.505, "duration": 3.615}, {"text": "And then you can keep on going from left to right in this pi- pipeline which is, um, now,", "start": 4139.12, "duration": 6.15}, {"text": "instead of using some learning algorithm to do face detection,", "start": 4145.27, "duration": 3.15}, {"text": "let's just go in and for the test set, you know,", "start": 4148.42, "duration": 2.625}, {"text": "modify, kind of have the face detection algorithm cheat, right?", "start": 4151.045, "duration": 3.12}, {"text": "Have it just memorize the right location for", "start": 4154.165, "duration": 2.955}, {"text": "the face in the test set and just give it a perfect result in the test set.", "start": 4157.12, "duration": 3.675}, {"text": "So when- when I shaded these things, um,", "start": 4160.795, "duration": 2.505}, {"text": "that means I'm giving it the perfect result, right?", "start": 4163.3, "duration": 3.63}, {"text": "Uh, so let's just go in and on the test set", "start": 4166.93, "duration": 2.52}, {"text": "give it the perfect face detection for every single example,", "start": 4169.45, "duration": 2.88}, {"text": "an- and then look at the final output and see", "start": 4172.33, "duration": 2.79}, {"text": "how that changes the accuracy of the final output, right?", "start": 4175.12, "duration": 3.12}, {"text": "And then, same for these components, um,", "start": 4178.24, "duration": 2.94}, {"text": "eyes segmentation, nose segmentation, mouth segmentation.", "start": 4181.18, "duration": 3.78}, {"text": "Uh, and then- and you do these one at a time.", "start": 4184.96, "duration": 3.165}, {"text": "And then finally for logistic regression,", "start": 4188.125, "duration": 2.535}, {"text": "if you give it the perfect output,", "start": 4190.66, "duration": 1.635}, {"text": "your- your- your- your accuracy should be 100%, right?", "start": 4192.295, "duration": 3.975}, {"text": "Uh, so now, what you can do is look at the sequence of,", "start": 4196.27, "duration": 4.65}, {"text": "um, uh, of steps and see which one gave you the biggest gain.", "start": 4200.92, "duration": 5.265}, {"text": "And it looks like, um,", "start": 4206.185, "duration": 1.56}, {"text": "in this example, it looks like, um,", "start": 4207.745, "duration": 3.275}, {"text": "when you gave it perfect face detection,", "start": 4211.02, "duration": 3.575}, {"text": "the accuracy improved from 85.1 to 91%.", "start": 4214.595, "duration": 3.395}, {"text": "So, you know, roughly a 6% improvement.", "start": 4217.99, "duration": 2.445}, {"text": "And that tells you that,", "start": 4220.435, "duration": 1.5}, {"text": "if only you can improve your face detection algorithm maybe", "start": 4221.935, "duration": 3.195}, {"text": "your overall system could get better by as much as 6%.", "start": 4225.13, "duration": 3.48}, {"text": "So this gives you faith that, you know,", "start": 4228.61, "duration": 2.1}, {"text": "maybe it's worth improving on your face detection component.", "start": 4230.71, "duration": 3.135}, {"text": "And in contrast, this tells you that even if you had perfect background removal,", "start": 4233.845, "duration": 5.999}, {"text": "it's only 0.1% better so maybe don't- don't- don't spend too much time on that.", "start": 4239.844, "duration": 4.981}, {"text": "Um, and it looks like that, uh,", "start": 4244.825, "duration": 2.775}, {"text": "when you gave it perfect eye segmentation,", "start": 4247.6, "duration": 2.34}, {"text": "it went up another 4%.", "start": 4249.94, "duration": 1.32}, {"text": "So maybe that's another good project to prioritize, right?", "start": 4251.26, "duration": 4.11}, {"text": "Um, and if you're in a team,", "start": 4255.37, "duration": 1.62}, {"text": "one common structure would be to do the separate analysis,", "start": 4256.99, "duration": 3.36}, {"text": "and then we have some people work on face detection,", "start": 4260.35, "duration": 2.46}, {"text": "some people work on eyes segmentation.", "start": 4262.81, "duration": 1.725}, {"text": "You could usually do a few things in parallel if you have a large engineering team.", "start": 4264.535, "duration": 3.39}, {"text": "But at least this should give you a sense of", "start": 4267.925, "duration": 2.385}, {"text": "the relative privatization of the different things. Question?", "start": 4270.31, "duration": 3.54}, {"text": "[inaudible]", "start": 4273.85, "duration": 16.05}, {"text": "Yeah, right. So if you just cumulatively,", "start": 4289.9, "duration": 1.935}, {"text": "uh, such as give it perfect eye segmentation,", "start": 4291.835, "duration": 1.844}, {"text": "then add on top of it nose segmentation,", "start": 4293.679, "duration": 2.056}, {"text": "or do you give it perfect eye segmentation and then take that away,", "start": 4295.735, "duration": 3.075}, {"text": "and then give it perfect nose segmentation.", "start": 4298.81, "duration": 1.65}, {"text": "Um, the way I presented it here is done cumulatively.", "start": 4300.46, "duration": 3.27}, {"text": "Uh, um, and- and it turns out that, uh, let's see.", "start": 4303.73, "duration": 3.705}, {"text": "If you give it- once you give it a perfect face,", "start": 4307.435, "duration": 2.52}, {"text": "uh, uh, uh, once you give it, you know,", "start": 4309.955, "duration": 1.635}, {"text": "perfect things in the later stages,", "start": 4311.59, "duration": 2.82}, {"text": "maybe the- the earlier stages doesn't matter that much anymore.", "start": 4314.41, "duration": 2.94}, {"text": "So that's one pattern. It turns out that,", "start": 4317.35, "duration": 2.175}, {"text": "uh, uh, you could do it either way, right?", "start": 4319.525, "duration": 2.4}, {"text": "For the uh, eyes-nose-mouth,", "start": 4321.925, "duration": 1.935}, {"text": "you can do it cumulatively or one at a time and", "start": 4323.86, "duration": 2.82}, {"text": "you'll probably get relatively similar results.", "start": 4326.68, "duration": 2.865}, {"text": "Um, uh, no guarantee,", "start": 4329.545, "duration": 1.365}, {"text": "you might get different results in terms of conclusions.", "start": 4330.91, "duration": 2.01}, {"text": "But, uh, but I think,", "start": 4332.92, "duration": 1.95}, {"text": "to the extent that you are wondering if doing it", "start": 4334.87, "duration": 2.76}, {"text": "cumulatively versus non-cumulatively might give you different results,", "start": 4337.63, "duration": 2.865}, {"text": "I will just do it both ways.", "start": 4340.495, "duration": 1.155}, {"text": "And then- an- and then- and- and I think this, um,", "start": 4341.65, "duration": 3.39}, {"text": "error analysis is not a", "start": 4345.04, "duration": 2.61}, {"text": "hard mathematical rule, if- if that makes sense.", "start": 4347.65, "duration": 2.52}, {"text": "It is not that you do this and then there's a formula that tells you,", "start": 4350.17, "duration": 3.63}, {"text": "okay, work on, uh,", "start": 4353.8, "duration": 1.98}, {"text": "uh, face detection, right?", "start": 4355.78, "duration": 1.185}, {"text": "I think that this should be,", "start": 4356.965, "duration": 1.545}, {"text": "um, married with judgments on,", "start": 4358.51, "duration": 2.805}, {"text": "you know, how- how hard do you think it is to", "start": 4361.315, "duration": 2.655}, {"text": "improve face detection versus eye segmentation, right?", "start": 4363.97, "duration": 3.18}, {"text": "But this at least gives you a sense of- of- of- it gives you a sense of prioritization.", "start": 4367.15, "duration": 3.81}, {"text": "Um, and it's worth doing this in- in- in", "start": 4370.96, "duration": 2.22}, {"text": "multiple ways if- if you think of- if- if- if you're", "start": 4373.18, "duration": 2.445}, {"text": "concerned in the discrepancy in the cumulative and non-cumulative versions, all right?", "start": 4375.625, "duration": 5.295}, {"text": "Um, so when we have a complex machine learning pipeline,", "start": 4380.92, "duration": 3.195}, {"text": "this type of error analysis helps you break down the error,", "start": 4384.115, "duration": 4.35}, {"text": "so attribute the error to different components,", "start": 4388.465, "duration": 2.52}, {"text": "which lets you focus your attention on what to work on.", "start": 4390.985, "duration": 3.685}, {"text": "So if you [inaudible]?", "start": 4396.09, "duration": 5.14}, {"text": "Oh, right. Yeah. If you do face detection", "start": 4401.23, "duration": 1.65}, {"text": "accurately and then your error drops, what does that entail?", "start": 4402.88, "duration": 2.58}, {"text": "Uh, it's not impossible for that to happen,", "start": 4405.46, "duration": 2.67}, {"text": "uh, it would be quite rare.", "start": 4408.13, "duration": 2.025}, {"text": "Uh, I would, uh, uh,", "start": 4410.155, "duration": 3.15}, {"text": "uh- so at a high-level,", "start": 4413.305, "duration": 1.365}, {"text": "what I would do is go in and try to figure out what's going on actually.", "start": 4414.67, "duration": 2.565}, {"text": "I- I wouldn't ignore that.", "start": 4417.235, "duration": 1.56}, {"text": "Uh, uh, so this is something I see.", "start": 4418.795, "duration": 2.55}, {"text": "Sometimes a team gets a- discovers", "start": 4421.345, "duration": 1.845}, {"text": "a weird phenomenon like that and usually ignore it and move on.", "start": 4423.19, "duration": 2.415}, {"text": "I wouldn't do that, I would- it's actually go.", "start": 4425.605, "duration": 2.76}, {"text": "Whenever you find one of these weird things, uh,", "start": 4428.365, "duration": 2.895}, {"text": "I wouldn't gloss over and ignore it,", "start": 4431.26, "duration": 2.565}, {"text": "I would go in and figure what's going on.", "start": 4433.825, "duration": 1.905}, {"text": "Does it make sense? It's- it is like debugging a software [NOISE].", "start": 4435.73, "duration": 2.55}, {"text": "You know, if- if you're- if you're trying to debug a piece of software,", "start": 4438.28, "duration": 3.134}, {"text": "and if- whenever you move your mouse over, you know,", "start": 4441.414, "duration": 4.066}, {"text": "some button, some random pixel color changes,", "start": 4445.48, "duration": 3.06}, {"text": "you go, huh, that's weird.", "start": 4448.54, "duration": 1.305}, {"text": "And then some people just ignore it and say,", "start": 4449.845, "duration": 2.115}, {"text": "\"Oh well, the user won't see this.\"", "start": 4451.96, "duration": 1.44}, {"text": "[LAUGHTER] But I'll say no, let's go figure it out.", "start": 4453.4, "duration": 1.29}, {"text": "[LAUGHTER]", "start": 4454.69, "duration": 4.44}, {"text": "So what you're saying is quite rare but not impossible.", "start": 4459.13, "duration": 2.73}, {"text": "But I would- I would, uh,", "start": 4461.86, "duration": 1.8}, {"text": "I don't have an easy solution for how to figure out what's", "start": 4463.66, "duration": 2.49}, {"text": "going on but I would- I would- wanna figure out what's going on.", "start": 4466.15, "duration": 3.25}, {"text": "Um, all right.", "start": 4469.86, "duration": 2.35}, {"text": "So one last thing before we break.", "start": 4472.21, "duration": 3.0}, {"text": "So error analysis, um,", "start": 4475.21, "duration": 1.8}, {"text": "helps figure out the difference between where you are now,", "start": 4477.01, "duration": 3.99}, {"text": "85% overall system accuracy and 100%, right?", "start": 4481.0, "duration": 4.17}, {"text": "So it tries to explain difference between where you are and,", "start": 4485.17, "duration": 2.835}, {"text": "you know, perfect performance.", "start": 4488.005, "duration": 1.515}, {"text": "There's a different type of analysis called ablative analysis", "start": 4489.52, "duration": 3.569}, {"text": "which figures out the difference between where you", "start": 4493.089, "duration": 2.011}, {"text": "are and something much worse. So- so here's what I mean.", "start": 4495.1, "duration": 2.775}, {"text": "Um, er, so let's say that you built,", "start": 4497.875, "duration": 4.695}, {"text": "um, let's say you built", "start": 4502.57, "duration": 4.02}, {"text": "a good anti-spam classifier by adding", "start": 4506.59, "duration": 2.07}, {"text": "lots of clever features in logistic regression, right?", "start": 4508.66, "duration": 2.49}, {"text": "So a spelling correction because spam is trying", "start": 4511.15, "duration": 2.25}, {"text": "to misspell words to mess up the tokenizer,", "start": 4513.4, "duration": 3.3}, {"text": "uh, uh, to make word look, you know,", "start": 4516.7, "duration": 1.875}, {"text": "spammy words not look like spammy words.", "start": 4518.575, "duration": 2.745}, {"text": "Uh, sender host features.", "start": 4521.32, "duration": 1.5}, {"text": "So, what machine did the e-mail come from?", "start": 4522.82, "duration": 2.07}, {"text": "You know, header features uh,", "start": 4524.89, "duration": 1.875}, {"text": "could have a parser from NLP,", "start": 4526.765, "duration": 2.355}, {"text": "parse a text, uh,", "start": 4529.12, "duration": 1.485}, {"text": "use a JavaScript parser to understand, right?", "start": 4530.605, "duration": 2.79}, {"text": "Or even you can, uh, uh, uh,", "start": 4533.395, "duration": 2.325}, {"text": "fetch the web pages that a- that the e-mail refers to and parse that.", "start": 4535.72, "duration": 4.095}, {"text": "Um, and the question is um,", "start": 4539.815, "duration": 2.31}, {"text": "how much would these- these components really help?", "start": 4542.125, "duration": 2.4}, {"text": "And it turns out, if you're writing a research paper,", "start": 4544.525, "duration": 2.625}, {"text": "you know, sometimes you're writing a research paper and you can say, \"Hey.", "start": 4547.15, "duration": 2.13}, {"text": "Look, I built a great spam classifier,\" and that's okay.", "start": 4549.28, "duration": 2.58}, {"text": "That's, like, a nice result to have.", "start": 4551.86, "duration": 2.01}, {"text": "But if you can explain to your reader,", "start": 4553.87, "duration": 2.1}, {"text": "either in a research paper or in a class project report like a term project,", "start": 4555.97, "duration": 3.645}, {"text": "what ac- what actually made the difference,", "start": 4559.615, "duration": 1.86}, {"text": "that conveys a lot of insights as well.", "start": 4561.475, "duration": 3.345}, {"text": "So, um, so simple logistic regression", "start": 4564.82, "duration": 3.87}, {"text": "without all these clever features got 94% performance,", "start": 4568.69, "duration": 3.21}, {"text": "uh, and with all of your- addition of all these clever features,", "start": 4571.9, "duration": 4.02}, {"text": "you got 99%, uh, uh, accuracy.", "start": 4575.92, "duration": 4.19}, {"text": "So an ablative analysis which we'll do, is, um,", "start": 4580.11, "duration": 3.975}, {"text": "we move the components one at a time to see how it breaks, right?", "start": 4584.085, "duration": 4.375}, {"text": "So just- so just now,", "start": 4588.46, "duration": 1.23}, {"text": "we were adding to the system by making", "start": 4589.69, "duration": 2.01}, {"text": "components perfect with error analysis, this is how it improves.", "start": 4591.7, "duration": 3.24}, {"text": "Here, we're gonna remove things one at a time.", "start": 4594.94, "duration": 2.13}, {"text": "I did not mean to remove that [LAUGHTER].", "start": 4597.07, "duration": 6.56}, {"text": "So let me figure out what's going to pop on. All right.", "start": 4603.63, "duration": 2.23}, {"text": "We move things one at a time to see how it breaks.", "start": 4605.86, "duration": 3.0}, {"text": "So let's see, we remove spelling correction.", "start": 4608.86, "duration": 2.19}, {"text": "And, uh, as the set of features,", "start": 4611.05, "duration": 1.68}, {"text": "the error goes away that.", "start": 4612.73, "duration": 1.245}, {"text": "Then let's remove the sender host features,", "start": 4613.975, "duration": 1.905}, {"text": "we remove email header features and so on until,", "start": 4615.88, "duration": 4.935}, {"text": "uh, when you remove all of these features you end up there.", "start": 4620.815, "duration": 2.895}, {"text": "And again, you could do this cumulatively or", "start": 4623.71, "duration": 1.8}, {"text": "remove one and put it back, remove one and put back.", "start": 4625.51, "duration": 1.92}, {"text": "Uh, uh, you know, or- or you could do it both", "start": 4627.43, "duration": 1.89}, {"text": "ways and see if they give you slightly different insights.", "start": 4629.32, "duration": 2.04}, {"text": "Uh, and so the conclusion from", "start": 4631.36, "duration": 4.41}, {"text": "this particular analysis is that the biggest gap is from the,", "start": 4635.77, "duration": 4.5}, {"text": "uh, text parser features,", "start": 4640.27, "duration": 1.86}, {"text": "because when you remove that the error or the accuracy went down by 4%.", "start": 4642.13, "duration": 5.13}, {"text": "And so, you know,", "start": 4647.26, "duration": 1.11}, {"text": "there is a strong evidence.", "start": 4648.37, "duration": 1.08}, {"text": "If you wanna publish a paper,", "start": 4649.45, "duration": 1.245}, {"text": "you can say like text parser features significantly", "start": 4650.695, "duration": 2.895}, {"text": "improves spam filter accuracy in that level of insight.", "start": 4653.59, "duration": 3.84}, {"text": "An- and then if you're working with spam filter for many years, right, you know,", "start": 4657.43, "duration": 3.585}, {"text": "there- there are- there are really important applications", "start": 4661.015, "duration": 2.385}, {"text": "where sometimes the same team will work on for many years.", "start": 4663.4, "duration": 2.325}, {"text": "So this type of error analysis gives you", "start": 4665.725, "duration": 2.22}, {"text": "intuition about what's important and what's not, uh,", "start": 4667.945, "duration": 3.045}, {"text": "and helps you decide to maybe even double down", "start": 4670.99, "duration": 3.12}, {"text": "on text parser features or maybe if, uh, um, uh,", "start": 4674.11, "duration": 3.63}, {"text": "or maybe if, uh, the sender host features is too computationally expensive to compute,", "start": 4677.74, "duration": 4.08}, {"text": "tells you maybe you can just get rid of that and without too much harm.", "start": 4681.82, "duration": 3.015}, {"text": "And also if you're a publishing paper or sending a report,", "start": 4684.835, "duration": 2.985}, {"text": "this gives much more insight to your report.", "start": 4687.82, "duration": 2.78}, {"text": "Okay? All right.", "start": 4690.6, "duration": 2.32}, {"text": "Um, so that's it for error analysis and ablative analysis.", "start": 4692.92, "duration": 4.62}, {"text": "I hope this was useful for your class projects as well.", "start": 4697.54, "duration": 2.73}, {"text": "I'll take one last question over there.", "start": 4700.27, "duration": 1.48}, {"text": "Uh, how did you chose the order of to remove the features?", "start": 4701.75, "duration": 3.89}, {"text": "Oh. Yeah. Uh, uh, how would you choose the order in which you- no systematic way.", "start": 4705.64, "duration": 4.545}, {"text": "If you didn't have a systematic way you do that, the other way,", "start": 4710.185, "duration": 2.325}, {"text": "the non-cumulative, where you remove one [NOISE] put it back, remove one put it back.", "start": 4712.51, "duration": 3.36}, {"text": "So either way it works. All right, let's break.", "start": 4715.87, "duration": 2.94}, {"text": "Um, uh, and, uh,", "start": 4718.81, "duration": 1.44}, {"text": "problem set two is- is due tonight.", "start": 4720.25, "duration": 2.67}, {"text": "A friendly reminder, and problem set three will be posted, uh,", "start": 4722.92, "duration": 3.18}, {"text": "in the next, like, several tens of minutes.", "start": 4726.1, "duration": 2.385}, {"text": "Okay. Thanks everyone.", "start": 4728.485, "duration": 2.215}]