[{"vid": "QuZL5IKpO_U", "cid": "UgzljrYkicUj5MGqPPF4AaABAg", "comment": "Audio channels fixed!", "votes": "38", "replies": "2", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "Ugwn4uXJmODrzQH_n6N4AaABAg", "comment": "Can anyone explain how projection matrices and fitting the lines automatically minimizes the least square error?", "votes": "2", "replies": "1", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgyA_VyAL79I_9fTiO54AaABAg", "comment": "30:55 Since the cofactor here is 0 coincidentally, it would be better to use a general tridiagonal matrix(n by n or at least 5 by 5) to show that the cofactor is Dn-2", "votes": "1", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgycYDA-kjSuPUD4UMR4AaABAg", "comment": "DR. Strang, from looking at your pass quizzes at MIT  they seem very challenging to me. There are many twist and turns in your quizzes. I hope that the MIT students are learning linear algebra that stays with them forever. These students are supposed to be the world's brightest.", "votes": "2", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgydVm8GGllcimWQMKd4AaABAg", "comment": "I'd like have a Grammpa iquals him", "votes": "2", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "Ugwv2fsMj7LkNHl-6_d4AaABAg", "comment": "42:48 matix A^TA is not invertible, then what about the projection matrix P", "votes": "1", "replies": "3", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgyagdGvPEWm5D6zw-V4AaABAg", "comment": "15:02 i couldn't find c for the projection matrix", "votes": "0", "replies": "1", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgwZQdbdI-T0zanKHFV4AaABAg", "comment": "Something like (-1)^(n/2) * ((n-1)!!)^2 for the determinant of the even ones?", "votes": "0", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "Ugz33bUMLBYjtRl1yHt4AaABAg", "comment": "Thank you so much Professor Strang and MITTTTT, my best summer friendddd! yahoo! Linear Algebra!", "votes": "12", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgwrZ-LzQYjW4Pr_5el4AaABAg", "comment": "Find Uk... Easy, it's in Europe!", "votes": "14", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "Ugz5j2zFV6iqMTrfAZh4AaABAg", "comment": "31:54 Could someone please explain why both of them aren't minus? (which makes outcome plus not minus)", "votes": "2", "replies": "2", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgxS8MDnJlh5eVxpOs54AaABAg", "comment": "Thank you for sharing us human these invaluable contents.", "votes": "3", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "Ugxo7cuSGMSVe37e_NN4AaABAg", "comment": "i think the explanation of the first queston was a little bit wrong it seems. because he wrote the equation  to diagonalize the matxix P even though it does not have 3 independent eigen vectors.", "votes": "0", "replies": "2", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgwAf-Na5jFhYqW9uDd4AaABAg", "comment": "At 42:15, how would I find the projection matrix, if the inverse of Atranspose*A doesn't exist, such as in this example?", "votes": "8", "replies": "3", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "Ugzdd-ibDDLRR5PhCtN4AaABAg", "comment": "42:19 P = {{1/5, 0, 2/5}, {0, 1, 0}, {2/5, 0, 2/5}}", "votes": "0", "replies": "", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg", "comment": "It's Christmas and I'm reviewing Linear Algebra.", "votes": "38", "replies": "7", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgwuklH_nUvV1Zpdu_d4AaABAg", "comment": "from 44:51 LOL", "votes": "2", "replies": "2", "reply": false}, {"vid": "QuZL5IKpO_U", "cid": "UgzljrYkicUj5MGqPPF4AaABAg.9-H9PpIICa697-dkYYPS2a", "comment": "Thanks, my left ear is finally able to learn.", "votes": "6", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgzljrYkicUj5MGqPPF4AaABAg.9-H9PpIICa69BXuSQY-OtR", "comment": "thank you!", "votes": "1", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugwn4uXJmODrzQH_n6N4AaABAg.9aAnGz23jnP9acdZIpdhlN", "comment": "Sure. First note that the least squares solution is the vector x which minimizes the distance between Ax and b. We know that the closest vector to b in the column space of A is exactly the projection of b onto the column space of A. This projection is given by A(A^TA)^-1A^Tb so Ax = A(A^TA)^-1A^Tb. Multiplying both sides by A^T on the left yields A^TAx = A^TA(A^TA)^-1A^Tb = A^Tb which is the equation you see him write. This will always yield a least squares solution even if the matrix A^TA is not itself invertible.", "votes": "5", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugwv2fsMj7LkNHl-6_d4AaABAg.9NxPOQ_zZdh9ORG9MXpTv5", "comment": "\u00a0@weilinfu5736\u00a0 tq\ud83d\ude0a", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugwv2fsMj7LkNHl-6_d4AaABAg.9NxPOQ_zZdh9ORGss4xFbV", "comment": "\u00a0@weilinfu5736\u00a0 is your argument according to the fact that linear combinations of the matrix row vectors are same as the linear combinations of the rows of the compressed matrix,  i mean they both span same space hence there would be no loss of properties", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugwv2fsMj7LkNHl-6_d4AaABAg.9NxPOQ_zZdh9ORMI8sTIZs", "comment": "\u00a0@weilinfu5736\u00a0 hey there, thanks from india I was actually studying the topics for ml to have a deep grasp of ml algorithms", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgyagdGvPEWm5D6zw-V4AaABAg.9NF7hs_thdZ9NzkDuM17UD", "comment": "I think it's done as C^k = S[LAMBDA]^kS^-1", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugz5j2zFV6iqMTrfAZh4AaABAg.9Afu5B0DMn89BVM1cKtV7A", "comment": "I have the same doubt", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugz5j2zFV6iqMTrfAZh4AaABAg.9Afu5B0DMn89Bgjjgxvm0R", "comment": "It's both negative when seeing the position in the big matrix. However when calculating the cofactor the second one is in position a11 of the 3x3 matrix whose determinant we are calculating.", "votes": "7", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugxo7cuSGMSVe37e_NN4AaABAg.98CaR8-APrV9DyTuWXUoio", "comment": "It has.  For lambda = 0, 0 we have x1 = <1,-2,0> , x2 = <1,0,-1> and for lambda = 1 we have x3 = <2, 1, 2>", "votes": "1", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "Ugxo7cuSGMSVe37e_NN4AaABAg.98CaR8-APrV9Fto8bg9vQ3", "comment": "The three columns of P, of course, are not independent since rank is 1. But the three eigenvectors of P are independent here.", "votes": "1", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwAf-Na5jFhYqW9uDd4AaABAg.9876y5NEiEC99Gr7Gjip1w", "comment": "In this question Mr.Strang wrote the general formula for column space of matrices (in this case rectangular matrix, otherwise this formula would always give Identity). Question asks to project onto column space, in that case you just take A as [(0,1,0) (1,0,2)]. Using A(T)A would give you a 2x2 matrix with rank 2, now being invertible.", "votes": "18", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwAf-Na5jFhYqW9uDd4AaABAg.9876y5NEiEC9FtoIsgsdEW", "comment": "Your claim is wrong. Atranspose*A does exist.", "votes": "2", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwAf-Na5jFhYqW9uDd4AaABAg.9876y5NEiEC9RxZe9fzQ9D", "comment": "\u00a0@chiaochao9550\u00a0 The confusing part is the inverse\u2026", "votes": "2", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg.92yui9Zj7I792z9ZlaYqH5", "comment": "\u00a0@wilhellmllw3608\u00a0 Haha. Team over achievers!", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg.92yui9Zj7I796rq_4JPzv3", "comment": "It's the middle of the Corona Crisis and I'm reviewing Linear Algebra. Nothing is more important than making progress!", "votes": "8", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg.92yui9Zj7I798O7T6ntvFj", "comment": "The biggest of sacrifices require the strongest of wills - Thanos", "votes": "9", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg.92yui9Zj7I798QYiRrnXAK", "comment": "Labroidas \ud83d\ude02 ty 4 that", "votes": "1", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg.92yui9Zj7I79BXuXCipxPO", "comment": "its summer vacation, im learning linear algebra while others are smoking weed", "votes": "5", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg.92yui9Zj7I79Cze4H0PrC5", "comment": "\u00a0@quirkyquester\u00a0 you can do both what's the harm", "votes": "4", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwDRS-Lx3t6Vb2O3SJ4AaABAg.92yui9Zj7I79NvWdzazRSN", "comment": "self teaching feels best in winter", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwuklH_nUvV1Zpdu_d4AaABAg.90ZCkHckBBq96hPHyqt1yA", "comment": "never fails to crack me up randomly while I'm studying haha", "votes": "0", "replies": "", "reply": true}, {"vid": "QuZL5IKpO_U", "cid": "UgwuklH_nUvV1Zpdu_d4AaABAg.90ZCkHckBBq96t0cZ5HrRr", "comment": "\u00a0@berrycoolcat\u00a0 Yeah", "votes": "0", "replies": "", "reply": true}]