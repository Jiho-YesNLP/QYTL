[{"vid": "iZTeva0WSTQ", "cid": "Ugy1iIqkAnVPa3LtLEt4AaABAg", "comment": "Can someone help me with the Problem sets and how should I get my hands on them?", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzcxZrOgT-MNMVD9254AaABAg", "comment": "better than Andrew", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgznoAxiF91bXxpysUR4AaABAg", "comment": "lecture be so good that optimus prime gets curious and asks questions", "votes": "21", "replies": "3", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzS3EIxyoYNwdVoVxR4AaABAg", "comment": "where do i learn this level of statistics", "votes": "0", "replies": "1", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwWKiBOpCDdggktGFV4AaABAg", "comment": "can anyone please send the problem sheets as  i am unable to login through piazza. Thanks for your help.", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzK4iu13DblVq-PvyF4AaABAg", "comment": "Softmax regression:  https://youtu.be/iZTeva0WSTQ?si=1cHP27fQImm027xh&t=4101", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugx9qCLFobpfSVXOqDV4AaABAg", "comment": "Does anyone have the problem sets available?", "votes": "1", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgxXN4NEcfqaICwUMs14AaABAg", "comment": "42:00 \"Given an x,we get an exponential family distribution, and the mean of that distribution will be the prediction that we make for a given new x\"!!!!!", "votes": "1", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugx4ILiHBZR6DDmHR4Z4AaABAg", "comment": "I think this lecture is well-organized and easy to get, which helps me immensely. I started reading the Notes first, but I still don't understand GLMs. After checking out the comments here, I decided to watch Ng's video (2008 version).   Unfortunately, it was pretty much like the Notes.   Then I went back to this video and found it amazing! Like, the conclusion of the \"learning update rule\" is handy but got missed in Notes. Also, the explanation of \"assumptions/design choices\" is clearer than the notes, which gives me a more concrete feel.   The examples in 59 minutes are also incredibly great. I hope you dig this video and stop getting swayed by negative comments.", "votes": "5", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgyOOYrjed95BF6fr3l4AaABAg", "comment": "how do i get the updated lecture notes? it gives 404 page on the standford website", "votes": "6", "replies": "1", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugx3YiuLo4caJRd-McR4AaABAg", "comment": "For anyone who needs it the updated link for the notes are here: https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf", "votes": "20", "replies": "3", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwJPZiQwHnvlMDX_oB4AaABAg", "comment": "Him writing an expression saying \" sum of class triangle, square, circle\" is comedic gold. I died. 1:21:00", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwCbD2ULwT6d-iy7_x4AaABAg", "comment": "at  9:14 it should be theta transpose that is perpendicular to line:face-red-smiling-live:", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzMaQGUHeoaI0_IlEN4AaABAg", "comment": "What is bro waffling about", "votes": "1", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwZiCPbMI5YkDVOJm54AaABAg", "comment": "People are too harsh on this lecturer. Even if he's a senior student, he's still learning. He hasn't got decades of experience like Dr. Ng. I think he did a fine job delivering this lecture.", "votes": "36", "replies": "1", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgymlaFaKj4xw5o7EVd4AaABAg", "comment": "How can we find lecture notes ? Is there chance to I get ? Your lecture note page says 404 not found.", "votes": "4", "replies": "1", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwI8WkuX1ukGVXG-O54AaABAg", "comment": "At time 26:36 in the video you made a mistake in the expression of phi where the numerator should be e to the power phi and not 1. just do cross product fraction to check it.", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugxp1tVzY3kH6Nklio54AaABAg", "comment": "wowwwww lecture", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzvDaHEz0b2hvfSKTJ4AaABAg", "comment": "great lectures:face-blue-smiling:", "votes": "1", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgyenTeVQTREubwp4lN4AaABAg", "comment": "omg this course Lectures 1-3: easy breezy positivity with Andrew Ng Lecture 4: getting hit in the head with a textbook hope it doesn't keep escalating like this...", "votes": "10", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgznoAxiF91bXxpysUR4AaABAg.A5WKXYd8Yh3A7NZ3Bwj7Vf", "comment": "rofl", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgznoAxiF91bXxpysUR4AaABAg.A5WKXYd8Yh3A7WI7zylgAE", "comment": "\u00a0@soychriscampos\u00a0  wtf, I said exactly the same thing before I read your comment. Made it twice as funny \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgznoAxiF91bXxpysUR4AaABAg.A5WKXYd8Yh3A7gs2KMO4x1", "comment": "lol", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgzS3EIxyoYNwdVoVxR4AaABAg.A5TVyR-2vSIA7-nf3i8dmn", "comment": "i think the Introduction to Probability by  Joseph K. Blitzstein , Jessica Hwang will be helpful", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgyOOYrjed95BF6fr3l4AaABAg.A0KESFGMQQHA3W1BKL38bj", "comment": "https://cs229.stanford.edu/main_notes.pdf", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugx3YiuLo4caJRd-McR4AaABAg.A01qP1Gxl5NA0UkhHDPbB9", "comment": "have you seen the PS 1 homework they have to do anywhere? the programming and math that they upload on scope?", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugx3YiuLo4caJRd-McR4AaABAg.A01qP1Gxl5NA3vtlUM-LyW", "comment": "Thank you very much :)", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugx3YiuLo4caJRd-McR4AaABAg.A01qP1Gxl5NA5OKJH84hMu", "comment": "Thank you very much, I was following Anands lectures for ML 2019 and I felt lost sometimes and needed the structured notes to revise after the lecture. Once again thanks a lot!", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwZiCPbMI5YkDVOJm54AaABAg.A-V4cOOXOLWA-nfib_nHC-", "comment": "He was actually quite clear 2/3 of the interview except maybe the start.", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgymlaFaKj4xw5o7EVd4AaABAg.A-EiPnwJa_7A58r27rrqQx", "comment": "https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwDjCysqOG3Mf32-Np4AaABAg", "comment": "Hopefully in the last 5 years someone at Stanford took it upon themselves to attach some magnets to the bottom of these panes.", "votes": "11", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgyUF-u5Gd9tNgJ1KvF4AaABAg", "comment": "27:18 Wouldn't the \"a(n)\" function (log-partition) be log(1+e^-n) + n, instead of just log(1+e^-n)?", "votes": "3", "replies": "1", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugzh7XDHxgaLNx9UIf94AaABAg", "comment": "lovely  <3", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugz5jd3BPAaRf1Axdd54AaABAg", "comment": "1:00:35", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgxJvhMBuhAvNAMmYUV4AaABAg", "comment": "Kind of....", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugyn2GJshFs5Dm-_CPd4AaABAg", "comment": "How can i get problem sets", "votes": "6", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzHpRDSh6QVR68YKEh4AaABAg", "comment": "This dude obviously didn't have the same level of the in-depth knowledge on this important topic as his professor, but just wrote down whatever on the lecture note. He couldn't provide insightful comments on what he wrote down, which I guess is mainly because he hadn't done any real-world project/research on the topics thus didn't deeply understand the stuff he was lecturing. I mean, he should know the stuff thus what he lectured was right, but he didn't fully understand it thus his audience would feel confused and bored. Sorry for being too harsh on him, but this topic deserves a much better lecture.", "votes": "20", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugxsh_iy-pUCIXgOKp94AaABAg", "comment": "Great lecture, really helped clarify to me GLMs.", "votes": "5", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgxtCeAHvYKlwt8oI2R4AaABAg", "comment": "At about 1:07, \"These \"Ys\" and \"xs\" would have been sampled\".  I thought for Sufficient Statistics, the Bernoulli distribution would not need to be sampled, it is assumed to have enough data, as a GLM?", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgygEEes7F4foCRUx0t4AaABAg", "comment": "after the probablistic interpretation topic in the last lecture everything has just went over my head can anyone pls tell me a good resource to learn statistics and probability of this level ?", "votes": "6", "replies": "3", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwfYfE7hxdXYgp0AiJ4AaABAg", "comment": "What is h(theta) for the last example of softmax regression?", "votes": "0", "replies": "6", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwFM-TAoqYHR0PSazZ4AaABAg", "comment": "The course schedule link and syllabus link provided have the notes links that are not working. Can anybody provide the correct link?", "votes": "0", "replies": "5", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgySX8T5pLQiKrUmy0J4AaABAg", "comment": "As per me -  real examples were missing in this lecture.  Examples help in clarity of thoughts.", "votes": "48", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugyzxf43LmW8tS0LHN94AaABAg", "comment": "Man, this guy's lecture was really disorganised and confusing. Why didn't he just follow Andrew Ng's notes?", "votes": "31", "replies": "1", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwauuKSxgUBbjMeVwF4AaABAg", "comment": "This lecture sure does dissappoint \ud83d\ude22", "votes": "41", "replies": "6", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugw451PACYdnAFb5_9Z4AaABAg", "comment": "there was a student that was asked to write one sentence again (\"more bigger\"), and it was waste of my time by 10 secend. Do you realize that the total amount of wasting the time of all the viewers in this video is about 45 days    O-:   this man need to go to jail!", "votes": "10", "replies": "4", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzbtI6wed2ekW9zznd4AaABAg", "comment": "What is the practical use of the properties explained in exponential families?", "votes": "5", "replies": "2", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgzW2ZCpxm5Zzb9W5j94AaABAg", "comment": "A great lecture!  Thank you!", "votes": "6", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgyFfHYul6E6q9LnLz54AaABAg", "comment": "This was really good, it did take a while compared to the previous lectures with Andrew", "votes": "11", "replies": "3", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgwJ45-YTjUeG6CIFtx4AaABAg", "comment": "59:30 good question to sums up what he's been explaining in the lecture", "votes": "12", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgyUF-u5Gd9tNgJ1KvF4AaABAg.9uWpco2Hx_x9uaGu_Xt4U8", "comment": "exactly my question! \ud83d\ude35\u200d\ud83d\udcab", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgygEEes7F4foCRUx0t4AaABAg.9qci7juQDbL9tPVVkq1pbc", "comment": "lookup some books used in first year probability and statistic courses.", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgygEEes7F4foCRUx0t4AaABAg.9qci7juQDbL9zNOojx9uEv", "comment": "It's a Masters level course so it makes sense that it assumes you know undergrad statistics. Probably go through some undergrad stats courses", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgygEEes7F4foCRUx0t4AaABAg.9qci7juQDbL9zNP1layZEF", "comment": "Will add they have prerequisites on the course website with specific courses mentioned so go through that, that'll help.", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwfYfE7hxdXYgp0AiJ4AaABAg.9qaAJe1744l9qasVAMoUbW", "comment": "it's the matrix of all c different logits, normalized, i.e. the thing he writes on the board at 1:17:21\r search up softmax regression and click the first stanford edu link for a better explanation", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwfYfE7hxdXYgp0AiJ4AaABAg.9qaAJe1744l9qcBRkoWWSy", "comment": "\u00a0@rijrya\u00a0 correct. I\u2019m also wondering why wouldn\u2019t we train k different binary logistic classifiers instead of the softmax, especially that we can\u2019t train the model to take input that is not in any of the k classes (say we want to classify the input as either dog, cat, mouse, and we input a horse); in a binary classifier it would output 0 for each of the dog, cat and mouse classifiers, but for softmax p(y)=0 which makes the likelihood 0 no matter what, so we can\u2019t train.", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwfYfE7hxdXYgp0AiJ4AaABAg.9qaAJe1744l9qcKf4NhIr-", "comment": "\u00a0@creativeuser9086\u00a0 it probably comes down to an efficiency issue, as creating a binary classification model for each class would be very inefficient especially as the number of classes increases. also since there would be a lot of redundancy in the data used to train each model i.e. the same data is used multiple times for separate models, I think you might run into overfitting issues. for the example you suggested, I think the solution that still incorporates softmax regression would be to have the classes dog, cat, mouse, and none of the above, then this would classify a horse with better results", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwfYfE7hxdXYgp0AiJ4AaABAg.9qaAJe1744l9qcLZWk_fuk", "comment": "I searched it up and it seems that k binary classifiers are typically only preferred over softmax when the classes aren\u2019t mutually exclusive, e.g {dog, cat, animal}, in this case softmax would not work very well", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwfYfE7hxdXYgp0AiJ4AaABAg.9qaAJe1744l9qeZ2EuyWQB", "comment": "\u00a0@rijrya\u00a0 I see. Regarding efficiency, there shouldn\u2019t be a difference between K-binary classifiers and softmax since we use the data once to train all k-classifiers in parallel. The number of parameters and gradient computations are the same.", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwfYfE7hxdXYgp0AiJ4AaABAg.9qaAJe1744l9qeZGvLdFw4", "comment": "\u00a0@rijrya\u00a0 so in the case when there is both a dog and a cat in the same image, we will need a k-binary classifier.", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwFM-TAoqYHR0PSazZ4AaABAg.9olW_y6MeOa9owUCbIKPIp", "comment": "Do you still need it?", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwFM-TAoqYHR0PSazZ4AaABAg.9olW_y6MeOa9p1vrInXgBR", "comment": "\u00a0@bernarddanice1294\u00a0 yes definitely for my exams I need it.", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwFM-TAoqYHR0PSazZ4AaABAg.9olW_y6MeOa9rvA7VzmHc2", "comment": "\u00a0@bernarddanice1294\u00a0 sorry, do you still have this links?", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwFM-TAoqYHR0PSazZ4AaABAg.9olW_y6MeOa9s5jUY4ajgF", "comment": "\u00a0@bernarddanice1294\u00a0 yes if you have", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwFM-TAoqYHR0PSazZ4AaABAg.9olW_y6MeOa9s5jYZ-w9qg", "comment": "if you get it from somewhere please send it", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugyzxf43LmW8tS0LHN94AaABAg.9ncdrCHi7nDA0b-pc0U9ek", "comment": "Disagree! I think this lecture is well-organized and clear. For example, the conclusion of the \"learning update rule\" is particularly useful but unfortunately miss in Notes. Also, the explanation of \"assumptions/design choices\" is more clear than Notes, which gives me a more concrete sense.", "votes": "4", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwauuKSxgUBbjMeVwF4AaABAg.9lu50rhUcST9nuR9zYHsGu", "comment": "I disagree from your comment. Professor has done a good job. Explained algorithms very well.  You got free lectures from a reputed university who has best people.  Show some respect !!", "votes": "27", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwauuKSxgUBbjMeVwF4AaABAg.9lu50rhUcST9nu_UNfXEC3", "comment": "\u00a0@badassopenpolling\u00a0 you are right! I got overwhelmed in the beginning when i commented also the topic he is teaching is very mathematical.........but i personally preferred other profs! This guy knows his stuff but i have seen better explanations to the same content :/\ud83e\udee0", "votes": "6", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwauuKSxgUBbjMeVwF4AaABAg.9lu50rhUcST9nudSJD7jlr", "comment": "\u00a0@badassopenpolling\u00a0 He's entitled to not being thrilled with the content delivery. Just because it's free, reputable, and in depth doesnt mean there is not room for improvement. I can 100% assure you the instructor would agree, theres always room for growth. A perfect message means nothing if it is not received by its audience.", "votes": "14", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwauuKSxgUBbjMeVwF4AaABAg.9lu50rhUcST9qaAQIG7wEq", "comment": "\u00a0@badassopenpolling\u00a0 what is h(theta) for the last example of softmax regression?", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwauuKSxgUBbjMeVwF4AaABAg.9lu50rhUcST9qmqy4hlfsj", "comment": "\u200b\u00a0@creativeuser9086\u00a0 thetha is the set of parameters (here it is 2D plane because he has considered two features x1 and x2) which will draw a straight line thetha1 * x1 + thetha 2 * x2 + constant (or a plane for n-dimensions). This straight line (or plane) will help us to decide where a point belongs to the one class or not. IF NOT, then if we put the value of a point X (or here x1 and x2) to this plane equation, then the output value will be less than zero.. Else value will be greater than zero if that point is a possible candidate of that class..", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgwauuKSxgUBbjMeVwF4AaABAg.9lu50rhUcSTA5xQJ83H2q2", "comment": "Why does it disapoints", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugw451PACYdnAFb5_9Z4AaABAg.9kn7_fS3_CQ9uXGuriZxA9", "comment": "\ud83e\udd23", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugw451PACYdnAFb5_9Z4AaABAg.9kn7_fS3_CQ9xYmICJ3C8C", "comment": "\ud83e\udd23 \ud83d\udc4f", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugw451PACYdnAFb5_9Z4AaABAg.9kn7_fS3_CQA-ZoiNIyeD7", "comment": "dude seriously? you wasted your valuable 10 seconds by commenting here.", "votes": "8", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugw451PACYdnAFb5_9Z4AaABAg.9kn7_fS3_CQA3oTFtehg9t", "comment": "\u00a0@vishnumahesh5988\u00a0 right ? AHAHHAH", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgzbtI6wed2ekW9zznd4AaABAg.9kSgq_Zn3d_9qnHESCiW_t", "comment": "finding the expected value and variance. duh", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgzbtI6wed2ekW9zznd4AaABAg.9kSgq_Zn3d_9zNQZ2-I5NJ", "comment": "Optimising the likelihood is much easier in exponential families (that is you train the model more easily), expectation (that is our hypothesis/prediction) and variance are also much easier found computationally (because derivatives in general are less computationally expensive than integrals).", "votes": "4", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgyFfHYul6E6q9LnLz54AaABAg.9hSqTeketvc9ogU-Zktrv0", "comment": "How? It's duration is within five minutes of the other lectures.", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgyFfHYul6E6q9LnLz54AaABAg.9hSqTeketvc9qmr3wSm2Rz", "comment": "\u00a0@calebvantassel1936\u00a0 what the hell r u talkign about", "votes": "5", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgyFfHYul6E6q9LnLz54AaABAg.9hSqTeketvc9txeFKhLVcD", "comment": "\u00a0@fahyen6557\u00a0 the duration of the lecture is almost the same", "votes": "3", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgzKUbBdUUjlAP46q114AaABAg", "comment": "51:40 Memo.  In conclusion, just pick which pdf method you use depending on the types of models(Gaussian, Bernoulli, and so on) and plug in the value for h theta(x) for the function to train.", "votes": "12", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugypc_uHZ6lDgqy6Sj54AaABAg", "comment": "Thank you!", "votes": "0", "replies": "", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgykdDqZgb680iPoOS94AaABAg", "comment": "23:02 Sir, It's PMF not PDF", "votes": "8", "replies": "3", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "Ugx513M0ixtF-Rxzw7t4AaABAg", "comment": "We begin by learning about Perceptrons. This is motivated by the previous discussions on logistic regression, where we use the sigmoid function. In case of perceptrons, we use a modified function in place of the sigmoid.  Next, we look at what exponential families are and some related examples. This is more a statistics thing.  Next, we learn about GLMs (Generalised Linear Models). The appearance of the sigmoid function in logistic regression becomes apparent from this discussion.  Finally, we study Softmax regression via the use of Cross-Entropy (defined therein.)", "votes": "39", "replies": "1", "reply": false}, {"vid": "iZTeva0WSTQ", "cid": "UgykdDqZgb680iPoOS94AaABAg.9czs9jKJIyc9iXIKiu2dzg", "comment": "probability density function= PDF", "votes": "1", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgykdDqZgb680iPoOS94AaABAg.9czs9jKJIyc9iXj8td0bc7", "comment": "\u00a0@antonyprinz4744\u00a0 Bernoulli distribution is for discrete random variable,  PMF is defined for Discrete random variable", "votes": "5", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "UgykdDqZgb680iPoOS94AaABAg.9czs9jKJIyc9yj_hBQ7ZK4", "comment": "The distinction between PMF and PDF is entirely artificial. They are both Radon Nikodym derivatives.", "votes": "0", "replies": "", "reply": true}, {"vid": "iZTeva0WSTQ", "cid": "Ugx513M0ixtF-Rxzw7t4AaABAg.9cVcD4loj_W9wOuyAoWMOS", "comment": "Perceptron is one of my favorite autobots.", "votes": "2", "replies": "", "reply": true}]