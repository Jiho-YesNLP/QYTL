[{"vid": "TX_vooSnhm8", "cid": "UgyHQ_lyvxZkG6bfVsh4AaABAg", "comment": "For the issue at 26:38, basically the conclusion that eigenvectors of A^TA and AA^T form columns of V and U is a necessary but not a sufficient condition. This is because we \"squared\" the matrix A to form AA^T, A^TA and hence the square of the signs gets cancelled. That is why we have to go back to the \"linear form\" AV = U\\Sigma in order to determine the signs correctly. The second example at 34:48 has no such problem as the null vectors multiplying 0 in \\Sigma and hence takes no effect.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugw-hzNsEV_1cL_BXY54AaABAg", "comment": "kind of a bad lecture compared to the previous ones tbh", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwwEAn2RSOLC-XdHcF4AaABAg", "comment": "What's wrong with the camera man on this lecture?", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgyrWoONwREHCWRZalR4AaABAg", "comment": "The cameraman would make a use of some coffee here", "votes": "2", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgxRJl9KkzmPJz0ig9h4AaABAg", "comment": "Linear Algebra is just a wonderful subject!!!!", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwXOP83ca8mxhFRRCV4AaABAg", "comment": "Camera man has ruined this best part of linear algebra.", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwE6SRnqEseAb5cgf14AaABAg", "comment": "@38:51, if A is a matrix of m x n, (m rows and n columns) Each row vector is in Rn  space. There are m rows. Each column vector is in Rm space. There are n columns.  Then shouldn't Vi be from v1 to vm ? and not vn? Since there are m rows?", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzN4eZ7T6BToetIvrJ4AaABAg", "comment": "looks like in this particular camera day the camera guy is lost in his mind a few times. There are several times that the camera hasn't followed the teacher immediately.", "votes": "1", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugw-K6TpUqTxdhkfq9J4AaABAg", "comment": "What on earth can stop the T(A)A\ud83d\ude02", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugw5vAYwUdm7LSmCd6x4AaABAg", "comment": "worst camera man in the history of MIT opencourseware, doesn't even cover the prof properly during the lecture", "votes": "0", "replies": "2", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgycZmO4j7SnsVIdnCl4AaABAg", "comment": "Can we solve the problem by setting the n-th number of the n-th eigenvector as 1, so that we can get [1,1] and [-1,1] in the first eample? I tried another 2x2 case and it seems right, and this idea just comes like some innocent idea but I can't prove it.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzNW3oUl77P52cUey94AaABAg", "comment": "Genial.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugzbt7Tefp8HF4cFtO54AaABAg", "comment": "AA' isn't always positive definite. It's PD only when A is invertible. It is always positive-semi-definite though, but that's different. Mentioning it because he said it's positive definite at one point I think.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzzUg2RXbP5mc2Q3Lp4AaABAg", "comment": "Nice Lecture. I watched all over again and again, I don't get it completely though. When he finds the eigenvalues and eigenvectors for A'A which is symmetric positive definite, how he transfers them in A which isn't symmetric positive definite? A' is A transpose.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzvfdA1A7D_U5tT-5N4AaABAg", "comment": "I hate this camera men. Gosh, please just follow Gilbert. He ruined Gilbert's lecture.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugysl5OSmkgAPceQoKZ4AaABAg", "comment": "My godness, stop moving the camera :<", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgxjWmmAa2Cm1N2ICfd4AaABAg", "comment": "Note1) (26:02) It can be solved by 'calculating' like u2 = 1/sigma2*A*v2, but the essence is that [the sigmas don't have to be positive, it's just that WE CHOOSE them to be positive].\r [u2 / sigma2 / v2] - ANY one of them can have different sign. It's just our choice, like -p=q*r and p=-q*r and p=q*-r are all equivalent.\r (of course the order of the columns and sigmas are our choice as well - that's how the sigmas are ordered like that)  Note2) In the 2nd example, the professor doesn't do the SVD in typical general way, but using the fact that A is rank 1 matrix (we don't have to find U,V in typical SVD way because we have no choice since the A's rank is 1). Related to this, it would be helpful to think about the \"4 fundamental subspaces of linear algebra\". Also in the 2nd example, the sign(+/-) could have been a problem again - we can't just simply say the sigma is positive root of 125. If we wanna make the sign of the sigma positive, we should modify the sign of U or V accordingly.  Note3) (15:43) A_t*A is positive \"semi\"-definite, in general. If A is non-singular(if all columns are independent), then A_t*A is positive definite.", "votes": "2", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgxpdT1l635_qZ94VpJ4AaABAg", "comment": "I love how confident and spontaneous Professor Strang is. He is not afraid to make mistakes in front of his students and term them as \u201cto finish\u201d examples for later examination as he moves forward and tries another example in hope of \u201cdoing it right\u201d the second try. His hesitation which is a result of high brain activity may confuses you sometimes and throws you off tangent, but it emphasizes the need for continuous examination and pondering while you are presenting the material. He could to the naive critic have prepared better for his lectures to have a smoother sail, but he seems on purpose to present himself like a student who is just doing it for the first time, which is really quite sly and entertaining if you don\u2019t find it confusing. You may for that reason have to wind back his lectures and watch it a second or even third time to get a full appreciation of his style. Thank a bunch for having such a brilliant instructor with decades of teaching and research experience!", "votes": "7", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwaDtBrVTwc_sQfc_Z4AaABAg", "comment": "After understanding and enjoying all the lecture videos (1-27), this one and Jordan form one (lecture 28) disappointed me.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwzIIznS4nmN595XeR4AaABAg", "comment": "The eigenvector u_2 related problem in Example 1 is about the scaling factor.   Dr. Strang said that all the scaling factors should be larger than 0. But if you set u_2 as [0;1], like in this lecture, sign decision issue arises.  Av_2 = [ 4 4 ; -3 3 ] [ 1/sqrt(2) ; -1/sqrt(2)]  = [ 0 ; - sqrt(18) ] = - sqrt(18) [ 0 ; 1 ] Incorrect -> sigma can't be negative sign  if we change sigma_2 to have positive sign, Av_2 = [ 4 4 ; -3 3 ] [ 1/sqrt(2) ; -1/sqrt(2)]  = [ 0 ; - sqrt(18) ] = sqrt(18) [ 0 ; -1 ] Correct! and obviously, u_2 we've got is [ 0 ; -1 ]", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzN4eZ7T6BToetIvrJ4AaABAg.9vRYWqg-C8s9vRY_mzKEVr", "comment": "such as 10:55", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugw5vAYwUdm7LSmCd6x4AaABAg.9tZ8lGEO7NA9tZJpBi0No9", "comment": "Trust us... this isn't the worst camera man in the history of MIT OpenCourseWare... we've seen worse. If we are lucky, we can hide it by cutting to the slides or a still frame.", "votes": "2", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugw5vAYwUdm7LSmCd6x4AaABAg.9tZ8lGEO7NA9tZM9Cb9Kom", "comment": "\u00a0@mitocw\u00a0 All right MIT open courseware, never mind. ... Always grateful to you all\ud83d\ude4f Prof. Strang's way of teaching compensates everything", "votes": "2", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugwr2nj0yJ7qmo5t7sJ4AaABAg", "comment": "09:30 Example 1: Non-Singular Matrix 28:00 Example 2: Singular Matrix 37:40 Describes components u, v in words", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgyZ7U7wsUjmpGfnhPR4AaABAg", "comment": "No words can describe how good Mr. Strang is.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugyi2OPtv_D2DO9cb-d4AaABAg", "comment": "\uc2dc\ub300\uc758 \uba85\uac15", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgxOjOKTPdu3jAUTW214AaABAg", "comment": "What I am inferring from the comments is it is ideal to work from right to left when determining the decomposition", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzRTTJFhr8dWv40c154AaABAg", "comment": "Im sorry but i think this is a very poor lecture compared to the others", "votes": "2", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugx1IXPSQWcf9A1e93B4AaABAg", "comment": "how did we get 32 and 18 as squares of sigma1 and sigma2 ?", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgybafJYNiLayAv2F294AaABAg", "comment": "Hi, can anyone explain why 10:20 sigma_1 and sigma_2 greater than 0? Thanks!", "votes": "0", "replies": "6", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugwa-E-ceYGcQkXiprR4AaABAg", "comment": "From this lecture,  I understand Singular Value  Decomposition in linear algebra. Dr. Strang really   explained this topic  and the examples very well.", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgxfQdBplJHlMZJyC3N4AaABAg", "comment": "mvp", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwQDucw68TgaWO1tMN4AaABAg", "comment": "If i ever do graduate, it\u2019ll be 100% thanks to this guy.", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugzh3WyNNYFT5K60jcR4AaABAg", "comment": "27:17 bottom left corner  that girl cracked his neck", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugx-ZXm_O0rJZkfWjNZ4AaABAg", "comment": "love this course", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugxt-Gh5UxYNejHC_2Z4AaABAg", "comment": "Professor Strang mentions that U and V form bases for the four fundamental subspaces of A, but it's not clear to me how C(A) = C(Ur) and C(A') = C (Vr'). I know that U and V were determined by the eigenvectors of AA' and A'A, respectively, but how are these related to the column and row spaces of A?", "votes": "2", "replies": "2", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgyHCDDT2nbbHqsieYB4AaABAg", "comment": "The most important concept and ---the camera man decided not to focus correctly!!", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzZybI0hEgLBFXIyhh4AaABAg", "comment": "This lecture is gonna be a little ambiguous at first BUT once you have a firm grip on the previous lectures from 18.06, you\u2019ll surprisingly realise it is the most beautiful lecture on SVD available in all of YouTube.", "votes": "1", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgxLYP_WPuOtHw4CQJ14AaABAg", "comment": "I found it very helpful to first go through Chapter 7.1 - Image Processing by Linear Algebra, from the Introduction to Linear Algebra by Strang, Fifth Edition. At first, I could not catch on with the lecture even though I have seen most of his past lectures and read the book. 7.1 really helped me.", "votes": "7", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwgcXbp2SnIa9i5aGV4AaABAg", "comment": "whoever's working the camera is a fucking idiot", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzVfIC95iJ8MYnLbsZ4AaABAg", "comment": "After three or more years of studying linear algebra, I finally understood the fundamental meaning of SVD ... really took me a long long way to get here... Thank you Dr. Strang.", "votes": "60", "replies": "2", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgyshOA2ywdWzbLN6qt4AaABAg", "comment": "I just have to comment about this: I love how Prof Strang has this hierarchy of good matrices and not so good matrices and superior ways of decomposing them and so on. It's like every lecture he introduces another type of matrix and goes \"oh yeah and this type is a really good one. I mean, it's a special case of this other type of matrix, but this one is better than the rest, it's wonderful\"", "votes": "16", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugzb_t1c2ygSLbu5eM54AaABAg", "comment": "For anyone watching this who doesn't feel like they are completely getting the concept, Prof Strang has an updated lecture in 18.065 on the SVD, which I think lays it out in a cleaner way: https://youtu.be/rYz83XPxiZo", "votes": "53", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgybafJYNiLayAv2F294AaABAg.9RjJ6CykjrD9VS7OlEqhoO", "comment": "Positive definite matrices have positive eigenvalues", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgybafJYNiLayAv2F294AaABAg.9RjJ6CykjrD9VTkssOe7hc", "comment": "\u00a0@sunritroykarmakar4406\u00a0 Thanks for replying! however it's not positive definite matrix yet  up to there. A is not necessary a positive definite matrix in SVD. If so why sigma1 & 2 still > 0 ?", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgybafJYNiLayAv2F294AaABAg.9RjJ6CykjrD9VUCpi0qfA3", "comment": "\u00a0@Tyokok\u00a0 sigma 1 and sigma 2 squared are eigen values of A(transpose)A which is a square symmetric matrix", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgybafJYNiLayAv2F294AaABAg.9RjJ6CykjrD9VYD3Ax7aZx", "comment": "\u00a0@sunritroykarmakar4406\u00a0 that's right. but that can only show sigma1&2 squared. unless SVD by define take the positive square root. right?", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgybafJYNiLayAv2F294AaABAg.9RjJ6CykjrD9VYo-jBnIaq", "comment": "\u00a0@Tyokok\u00a0 yeah he's taking the positive square root onoy", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgybafJYNiLayAv2F294AaABAg.9RjJ6CykjrD9VYpVOjL2Po", "comment": "\u00a0@sunritroykarmakar4406\u00a0 I see. Thank you so much for your kind responding and explaining!", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugxt-Gh5UxYNejHC_2Z4AaABAg.9LsgHlpqO8g9M4EZoNSyLV", "comment": "This is how I see it. Suppose A is m by n, it means that row vectors are n-dimensional. When we write Ax = b, x is also an n-dimensional vector, and it lives either in a row space of A or in a null space of A, if exists (Fundamental Theorem of Linear Algebra). On the other hand, b lives in the column space of A (or left null space of A, if exists). So, when we start from A*v = sigma*u (in the matrix form: A = U * Sigma * V'), v is in the row space, and u is in the column space. Then come the clever steps to determine what are u and v with the use of A'A and AA'. Does it help?", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugxt-Gh5UxYNejHC_2Z4AaABAg.9LsgHlpqO8g9VroOfVxDrX", "comment": "\u00a0@szymontuzel8182\u00a0  its a nice way but ur argument is not fully correct. x need not lie in row space or null space of A.Fundamental theorem of linear algebra states that dimension of image + dimension of kernel = dimesion of vector space(rank nullity th). But instead what is correct is that the kernel is the orthogonal complement of row space. which implies given any vector x it can be written as v+w(v in row space and w in kernel).Now Ax=Av+Aw=Av. So u can think of it as only the row space contributes to the column space(indeed it an isomorphism as both are vector spaces with equal dimension) and hence u only care about basis vectors of row space and extend it with a basis of kernel.", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzZybI0hEgLBFXIyhh4AaABAg.9KMN1xXXuna9cd68nGjYH6", "comment": "Do you care to give a little explanation of why SVD is so important? My main interests for application of linear algebra are quantum physics and number theory, but I'm not really sure why I this subject is so important. It feels silly, because I was following the course up until this lecture, and I see a lot of people claiming it is the best one yet. Prof Strang even says it is the \"climax of linear algebra\" is his previous lecture...", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzVfIC95iJ8MYnLbsZ4AaABAg.9GEEgeItizo9GUi5S9a7sZ", "comment": "So did I !  \uc5ec\uae30\uc11c \ubcf4\ub2c8\uae4c \ubc18\uac11\ub124\uc694 \uc120\uc0dd\ub2d8 \u314e\u314e", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzVfIC95iJ8MYnLbsZ4AaABAg.9GEEgeItizo9GVSiKuNE8g", "comment": "\u00a0@minoh1543\u00a0 \uc624\uc6b0 \u314e\u314e \uc5ed\uc2dc \uc2a4\ud2b8\ub791 \uac15\uc758\ub294 \uc120\ud615\ub300\uc218\uc758 \uc131\uc9c0\ub124\uc694 \u314b\u314b", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugzb_t1c2ygSLbu5eM54AaABAg.9E4FX4d88SA9KJ_2RuY2Uf", "comment": "Also, I found it very helpful to first go through the Chapter 7.1 - Image Processing by Linear Algebra, from the Introduction to Linear Algebra by Strang, Fifth Edition. At first, I could not catch on with the lecture even though I have seen most of his past lectures and read the book. 7.1 really helped me.", "votes": "5", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgwTsG-ag8c1XupOHlB4AaABAg", "comment": "The problem u not agreeing with the equation is that, after sigma and V have been determined, we no longer have freedom in constructing u. The u obtained with AA^T is still valid, but require different arrangement of sigma and V to accommodate. u has to equal [1 0; 0 -1] to agree with the sigma and V pair.", "votes": "5", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzSUZpjynu9vGDKnbd4AaABAg", "comment": "Is the camera-man sleeping?", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgylxOrw9anU4xnKLBR4AaABAg", "comment": "01:38 that girl in left corner of video having breakfast in classroom reminds me of elementary school", "votes": "9", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugy7qamL8qi-eNTRYo94AaABAg", "comment": "9:38 - MIT - Massachusetts Institute of Technology 9:40 - MIT - Mexico Institute of Technology", "votes": "125", "replies": "4", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwInTMRpVGR5pbrf5R4AaABAg", "comment": "\ubaa8\ub4e0 MIT \uac15\uc758\uac00 \uc774\ub7f4 \uac83\uc774\ub77c\uace0 \uc0dd\uac01\ud558\uc9c0\ub294 \uc54a\uc9c0\ub9cc \uc5f0\uc138\uac00 80 \uac00\ub7c9\uc778 \ub178\uad50\uc218\uac00 \uc790\uc2e0\uc758 \uba38\ub9ac \uc18d \uc0dd\uac01\uc744 \ud22c\uba85\ud558\uac8c \ud3bc\uccd0\ubcf4\uc774\uba70 \uc218\ubc31 \ubc88\uc740 \uc774\ubbf8 \uac15\uc758\ud558\uc168\uc744 \ub0b4\uc6a9\uc744 \uc0dd\uc0dd\ud558\uace0\ub3c4 \uc5f4\uc815\uc801\uc73c\ub85c \ud559\uc0dd\ub4e4\uc5d0\uac8c \ub9c8\uce58 \ucc98\uc74c \uc124\uba85\ud558\uc2dc\ub294 \uac83\ucc98\ub7fc \uc804\ub2ec\ud558\uc2dc\ub294 \uac83\uc744 \ubcf4\uba70 \ucda9\uaca9\uc744 \ubc1b\uc2b5\ub2c8\ub2e4. \uacfc\uc789 \uc77c\ubc18\ud654\ud558\ub294 \uac83\uc77c \uc218 \uc788\uace0 \ud639\uc790\uc5d0\uac8c\ub294 \ud3b8\ud611\ud558\uace0\ub3c4 \ubd80\ub2f9\ud55c \ud3c9\uac00\ub85c \ud3c4\ud558\ub420 \uc218 \uc788\uc744 \ub9d0\uc774\uc9c0\ub9cc \uc6a9\uae30\ub0b4 \ubcfc\uba58 \uc18c\ub9ac\ub97c \ud558\uc790\uba74 \ud55c\uad6d \ub300\ud559\uc740 \uacfc\uc5f0 \ub300\ud559\uc774\ub77c\ub294 \uc815\uc758\uc5d0 \ud3ec\uc12d\uc774\ub77c\ub3c4 \ub418\uace0 \uc788\ub294 \uac83\uc77c\uae4c \ud68c\uc758\ub97c \ud558\uac8c \ub41c\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4. 60\ub9cc \ub118\uc5b4\ub3c4 \ubb34\uc2a8 \ub300\uac00\ub77c\ub3c4 \ub418\uc11c \uac15\uc758\uc870\ucc28 \ucd08\ud0c8\ud558\uac8c \ub300\ud574\ubc84\ub9ac\uba70 \uc815\ubd80\ub098 \uc0bc\uc131\ub9cc\uc744 \ubc14\ub77c\ub294, \ud559\uc0dd\ub4e4\uc5d0\uac8c \ub9ce\uc740 \uace0\ud1b5\uc744 \uc8fc\ub294 \ub9ce\uc740 \uc774 \ub545\uc758 \ud559\uc790\uc5f0\ud558\ub294 \uc790\ub4e4\uc5d0\uac8c \uc774 \uac15\uc758\ub97c \ubcf4\uc5ec\uc8fc\uace0 \uc2f6\uc2b5\ub2c8\ub2e4.", "votes": "8", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugzk7-mzhJVXgwvEYQB4AaABAg", "comment": "I didn\u2019t really got this now but I will review previous material to finally understand this lecture!!", "votes": "6", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugw2G0_JfqR-0VHH_Ol4AaABAg", "comment": "Gilbert Strang is a FREAK", "votes": "2", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwRwaKeDl0sUpyQZLZ4AaABAg", "comment": "Why so few people at the lecture?", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzF3BHySCZL0q8wyvd4AaABAg", "comment": "Regarding the problem at 26:28 It would be solved if the matrix U was [1 0; 0 -1]. (Replace the 1 at the bottom right of the 2x2 identity with -1). This can be found by following the argument that Prof Strang makes in this video: https://youtu.be/rYz83XPxiZo?t=1177 (Skip to 19:37).   The problem is that here the eigenvectors of U that we found are [1, 0]' and [0, 1]', but they should be [1, 0]' and [0, -1]'. The negative in the 2nd eigenvector allows the scaling term (sigma) to be strictly positive.    Let S = Sigma (for ease of typing). I think the main problem is that the general form A = U*S*V' does not mathematically enforce that S should be a strictly positive matrix. So even though A'A and AA' will output the squares of the eigenvalues, simply choosing the positive roots is not enough. We would need to choose the right sign for the eigenvector that corresponds to the positive root. E.g. [1,0] and [-1,0] can both have the same eigenvalue, so we have to decide which to use. Hence, we need to check the cases and manually negate the vectors in U or V so that S can be positive. However, if we follow what Prof Strang does in the video whose URL ive included in the earlier part of this comment, then this is accounted for by the computation.", "votes": "76", "replies": "6", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwCF3PWKhI9nvGmTJN4AaABAg", "comment": "We can have infinite possible set of Eigen vectors. But in this problem,  we know from the definitions  Sigma\u00d7u =  A v. So we have to choose u according to the v chosen. So in this case that u2 = [0, 1] is not corresponds to v2 chosen.  The corresponding  Sigma2 \u00d7u2 =  A v2 ==>  u2 = [0, -1].", "votes": "6", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwtQMO7JHjSqhnOiS54AaABAg", "comment": "A lot of examples in this video that show why the cameraman would be better if he/she could follow the subject matter - the camera is left showing the wrong part of the blackboard.", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzgQIETCgXLSEUanWJ4AaABAg", "comment": "The camera person was really defocused that day.", "votes": "32", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugx3x1fzzGuo5FeS9b94AaABAg", "comment": "1st Example:  U = [[0, 1], [1, 0]] Sigma = [[sqrt(18), 0], [0, sqrt(32)]] V = V^T = [[-sqrt(2)/2, sqrt(2)/2], [sqrt(2)/2, sqrt(2)/2]]  where [a, b] is interpreted as a row vector. A = [[4, 4], [-3, 3]] = U * Sigma * V^T .... try it.  We know what we're doing, but we're not computers...we make little errors once in a while that we can't track successfully. The core concept was brilliantly delivered, and Professor Strang did an exceptional job making us understand SVD. I didn't bother to find his computational error \u263a\ufe0f", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwW_JnGyh-b-PEYC7d4AaABAg", "comment": "I tried to ignore it, but what the heck is wrong with the camera-man?", "votes": "112", "replies": "3", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwpbdwCQPHlB_KRIA54AaABAg", "comment": "The camera man in this one drank some vodka.", "votes": "11", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgwSOvAxRibIvXRSKuV4AaABAg", "comment": "You can tell SVD is Professor Strang's favorite topic. This is the only lecture in 9:4 HD and audio channels upgraded.", "votes": "8", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgykCsvfviR9QyavMTt4AaABAg", "comment": "Thank you Professor Strang for showing us the beauty of math!", "votes": "2", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugx8TOyHTpxPakIa-yZ4AaABAg", "comment": "https://youtu.be/HgC1l_6ySkc where he corrects the error in this lecture.", "votes": "0", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgxXEvHlMwzfasWVzNZ4AaABAg", "comment": "Excuse me, why the camera didn't follow Strang?", "votes": "22", "replies": "1", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgyUrPLtqFJ4QZXmHWt4AaABAg", "comment": "\"Fundamental Theorem of Linear Algebra\" ~ Wolfram http://mathworld.wolfram.com/FundamentalTheoremofLinearAlgebra.html  Application of this theorem is the underlying theme of these lectures.", "votes": "1", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugy7qamL8qi-eNTRYo94AaABAg.9BT7yKoGre49CIN4gquPbl", "comment": "HAHA", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugy7qamL8qi-eNTRYo94AaABAg.9BT7yKoGre49iUyvxR-yMP", "comment": "Took me a minute, Haha!", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugy7qamL8qi-eNTRYo94AaABAg.9BT7yKoGre49lxS9U70ZdJ", "comment": "underrated", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugy7qamL8qi-eNTRYo94AaABAg.9BT7yKoGre4A74x68DOCI7", "comment": "LOL hahahahaha", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugzk7-mzhJVXgwvEYQB4AaABAg.9AK-Ix7LkuM9AOEEI2iLC9", "comment": "Now I got this. Tried to understand what he says sentence by sentence. Paused it and thought it over and now in 2 hours I finally got this.", "votes": "8", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzF3BHySCZL0q8wyvd4AaABAg.99pwHuMFMn099vUjX-_WYl", "comment": "Prof Strang mentions the correction to this in lecture 32 Quiz 3 Review at 28:51 (https://youtu.be/HgC1l_6ySkc?t=1731)", "votes": "21", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzF3BHySCZL0q8wyvd4AaABAg.99pwHuMFMn09A7EtVb90JK", "comment": "\u00a0@archidar1\u00a0 thanks!", "votes": "3", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzF3BHySCZL0q8wyvd4AaABAg.99pwHuMFMn09LeSUMvNZGa", "comment": "I think the main reason is that for choosing u2 and v2, it is also important to make sure A*v2 = sigma2*u2.   It could be easily verify that if u2= [0,1], the above equation does NOT true but with a difference of sign.   It is very important to keep in mind u2 should be evaluated by using u2 = 1/sigma2*A*v2, which yields 'the' particular unit eigenvector of A*A^t.", "votes": "6", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzF3BHySCZL0q8wyvd4AaABAg.99pwHuMFMn09XfyF9I3Xcq", "comment": "The problem actually is that v2 should have been [-1;1] and not [1;-1].  u2 then would have correctly been [0;1].", "votes": "2", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzF3BHySCZL0q8wyvd4AaABAg.99pwHuMFMn09iyzkGcoxYH", "comment": "Douglas is correct.\r I mean, yes it can be solved by 'calcualting' like SulinWang said, but the essence is that [the sigmas don't have to be positive, it's just that WE CHOOSE them to be positive].\r [u2 / sigma2 / v2] - ANY one of them can have different sign. It's just our choice, like -p=q*r and p=-q*r and p=q*-r are all equivalent.\r (the order of the columns and sigmas are also our choice.)   @babyboo: it's just the same thing, as mentioned above.", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzF3BHySCZL0q8wyvd4AaABAg.99pwHuMFMn09mcBzMerqi4", "comment": "Great Thanks all the replies in the thread!", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgwCF3PWKhI9nvGmTJN4AaABAg.99EbPLPxV9u9IKCjdRNNBX", "comment": "I Agree that!", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgwW_JnGyh-b-PEYC7d4AaABAg.96mxXqA1R6W9EEVQ4blGgA", "comment": "lol imagine a world where the camera is controlled by computer vision and we didn't have to deal with these incompetent cameramen", "votes": "13", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgwW_JnGyh-b-PEYC7d4AaABAg.96mxXqA1R6W9I0s8e-0JPw", "comment": "I think he's high!!", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgwW_JnGyh-b-PEYC7d4AaABAg.96mxXqA1R6W9NBc6e4CWyW", "comment": "I think it's fine", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgwpbdwCQPHlB_KRIA54AaABAg.96LxKf-ttGB9Ezyah-DpbS", "comment": "He thought that SVD might stand for \"Some Vodka Drinking\"", "votes": "2", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgwSOvAxRibIvXRSKuV4AaABAg.94uHVC1ln6S99i0td2ObuE", "comment": "but sadly the lecture with the worst camera work...", "votes": "2", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgxXEvHlMwzfasWVzNZ4AaABAg.92nTHsF6wj39NBcZbxJuaD", "comment": "Doesn't really matters lol", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugzn95c-m-d2WC2AdKZ4AaABAg", "comment": "at 20:35, why use the positive square roots instead of negative ones?", "votes": "4", "replies": "2", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgyYaniGFw8DMQ_8u7x4AaABAg", "comment": "Hats off! The best teacher I would want to be.", "votes": "9", "replies": "", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg", "comment": "The problem of that calculation is given eigenvalues, the choice of orthonormal eigenvector matrix is not unique (we can multiply -1!). If we choose U not as identical, but as [[1,0],[0,-1]], the calculation will be alright.", "votes": "11", "replies": "8", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "UgyQZhRPbaal_OnFhDJ4AaABAg", "comment": "Audio channels, resolution, and aspect ratio fixed!", "votes": "74", "replies": "3", "reply": false}, {"vid": "TX_vooSnhm8", "cid": "Ugzn95c-m-d2WC2AdKZ4AaABAg.92GE5Q4RXBD92cLKwwelu6", "comment": "Positive definite, eigenvalues are always positive", "votes": "9", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "Ugzn95c-m-d2WC2AdKZ4AaABAg.92GE5Q4RXBD92cZl4XNoRF", "comment": "\u00a0@ir0nt0ad\u00a0 aha yeah, thought that was only mentioned later of the course though", "votes": "3", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz5891r5NLUPrSw", "comment": "but it shuld've work, i also get this weird result when i calculating by myself, math shuld work independly of the choices you do if these choices was right", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz5892VITJBu9PA", "comment": "He fixes this in a later video", "votes": "1", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz5892WBC58ct2X", "comment": "\u00a0@tdchayes\u00a0 Where?", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz5892cWjbqvOhG", "comment": "\u00a0@fqj2lkeajfsdl\u00a0 Lecture 32, around 30 minutes in", "votes": "4", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz589720bTk5yZ-", "comment": "In video 32 at 31:38 he says \u201ca sign went wrong...\u201d and explains it. Takes about 3 minutes. If you work it out, (he doesn\u2019t) the EigVcs for U are [1;0] and [0;-1] (where originally he got [1;0] and [0;1])", "votes": "6", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz5898-TsYwkpH4", "comment": "\u00a0@aaronpaulhughes\u00a0 How to decide then which one is the right eigenvector?", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz589884HA5l7Hf", "comment": "\u00a0@blakceyedpeas\u00a0 Once you have calculated either U or V, You should then plug it into the main equation (AV=SIGMA*U) and then you calculate the other one", "votes": "5", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgzsHLKQcSEBRFd1OUd4AaABAg.91HlofjGz58995M69qGkqu", "comment": "\u00a0@khashayarrahanama817\u00a0 thank you", "votes": "0", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgyQZhRPbaal_OnFhDJ4AaABAg.9-H9WQtLD_M9-g2xOtMkHA", "comment": "Thank you!", "votes": "2", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgyQZhRPbaal_OnFhDJ4AaABAg.9-H9WQtLD_M97FJFS1eAF0", "comment": "You should fix the cameraman as well", "votes": "14", "replies": "", "reply": true}, {"vid": "TX_vooSnhm8", "cid": "UgyQZhRPbaal_OnFhDJ4AaABAg.9-H9WQtLD_M9Bc1BjYBXZQ", "comment": "Thank you!", "votes": "1", "replies": "", "reply": true}]